根据[小林 Coding](https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzUxODAzNDg4NQ==&action=getalbum&album_id=1790401816640225283#wechat_redirect) 整理的 Redis 八股，主要是起到大纲的作用。

## 一、缓存异常

> reference: 
>
> * [再也不怕，缓存雪崩、击穿、穿透！](https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&mid=2247490008&idx=1&sn=8f576e69ec63e02a8b42a00ae6754f0a&chksm=f98e5d72cef9d464710c891c4c0537c20e4949b39ee70c97c44c3f6f95df83fc406f52fc161b&scene=178&cur_album_id=1790401816640225283&search_click_id=#rd)

缓存雪崩、缓存击穿、缓存穿透

* 概念
* 解决方案

> 如何设计一个缓存策略，可以动态缓存热点数据呢？

由于数据存储受限，系统并不是将所有数据都需要存放到缓存中的，而**只是将其中一部分热点数据缓存起来**，所以我们要设计一个热点数据动态缓存的策略。

热点数据动态缓存的策略总体思路：**通过数据最新访问时间来做排名，并过滤掉不常访问的数据，只留下经常访问的数据**。

以电商平台场景中的例子，现在要求只缓存用户经常访问的 Top 1000 的商品。具体细节如下：

- 先通过缓存系统做一个排序队列（比如存放 1000 个商品），系统会根据商品的访问时间，更新队列信息，越是最近访问的商品排名越靠前；
- 同时系统会定期过滤掉队列中排名最后的 200 个商品，然后再从数据库中随机读取出 200 个商品加入队列中；
- 这样当请求每次到达的时候，会先从队列中获取商品 ID，如果命中，就根据 ID 再从另一个缓存数据结构中读取实际的商品信息，并返回。

在 Redis 中可以用 zadd 方法和 zrange 方法来完成排序队列和获取 200 个商品的操作。

## 二、Redis 持久化

> reference: 
>
> * [宕机了，缓存数据没了。。。](https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&mid=2247493808&idx=1&sn=588d318ec6e72844841d566f16acaf30&chksm=f98dac1acefa250ce40060899a4030bb7678c45befea408162360db4ef4fa2785feb1544e719&scene=178&cur_album_id=1790401816640225283&search_click_id=#rd)
> * [咔擦，不就是快照嘛](https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&mid=2247494677&idx=1&sn=53f60870b66c731aa6ec5b6e70697eff&chksm=f98da8bfcefa21a9ad7b4d564238931f8457bafb08698301e9672dbc366a034890429fdc1ff1&scene=178&cur_album_id=1790401816640225283&search_click_id=#rd)

Redis 虽然是内存数据库，但是也可以持久化存储：

* AOF（Append only File）
* RDB（Redis DataBase）

## 三、单线程

> reference：
>
> * [快问快答！](https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&mid=2247495027&idx=1&sn=217af306b07ed0f2a064773541d46721&chksm=f98da9d9cefa20cf7ce2ef0ebf60cf378b79958a2e34559c9da7922be4a946a800ff815f950f&scene=178&cur_album_id=1790401816640225283&search_click_id=#rd)

Redis 确实是以单线程架构被大家所知，但是这个单线程指的是「**从网络 IO 处理到实际的读写命令处理**」都是由单个线程完成的，并不是说整个 Redis 里只有一个主线程。

有些命令操作可以用后台子进程执行（比如快照生成、AOF 重写）。

严格意义上说的话，Redis 4.0 之后并不是单线程架构了，除了主线程外，它也有后台线程在处理一些耗时比较长的操作，例如清理脏数据、无用连接的释放、大 Key 的删除等等。

你可能听到 Redis 6.0 版本支持了多线程技术，不过这个并不是指多个线程同时在处理读写命令，而是使用多线程来处理 Socket 的读写，**最终执行读写命令的过程还是只在主线程里**。

之所以采用多线程 IO 是因为Redis 处理请求时，网络处理经常是瓶颈，通过多个 IO 线程并行处理网络操作，可以提升整体处理性能。

那为什么处理操作命令的过程只在单线程里呢？

因为 Redis 不存在 CPU 成为瓶颈的情况，**主要受限于内存和网络**。

而且使用单线程的好处在于，可维护性高、实现简单。

如果采用多线程模型来处理读写命令，虽然能提升并发性能，但是它却引入了程序执行顺序的不确定性，带来了并发读写的一系列问题，增加了系统复杂度、同时可能存在线程切换、甚至加锁解锁、死锁造成的性能损耗。

## 四、主从复制

> reference：
>
> * [小林差点崩溃了，还好有主从复制](https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&mid=2247495237&idx=1&sn=8302585810958567a57bda3df6c5d036&chksm=f98daaefcefa23f95e9f4ef083bbf6b8ce80794bb00c68d9070f158e6de9a0265ea39b12e560&scene=178&cur_album_id=1790401816640225283&search_click_id=#rd)

主从复制模式可以保证多态服务器的数据一致性，且主从服务器之间采用的是 **读写分离** 的方式。

主从复制的三种写命令传播模式：

1. 全量复制
2. 基于长 TCO 连接的命令传播
3. 增量复制

主从服务器第一次同步的时候，就是采用全量复制，此时主服务器会两个耗时的地方，分别是生成 RDB 文件和传输 RDB 文件。为了避免过多的从服务器和主服务器进行全量复制，可以把一部分从服务器升级为「经理角色」，让它也有自己的从服务器，通过这样可以分摊主服务器的压力。

第一次同步完成后，主从服务器都会维护着一个长连接，主服务器在接收到写操作命令后，就会通过这个连接将写命令传播给从服务器，来保证主从服务器的数据一致性。

如果遇到网络断开，增量复制就可以上场了，不过这个还跟 `repl_backlog_size `这个大小有关系。

如果它配置的过小，主从服务器网络恢复时，可能发生「从服务器」想读的数据已经被覆盖了，那么这时就会导致主服务器采用全量复制的方式。所以为了避免这种情况的频繁发生，要调大这个参数的值，以降低主从服务器断开后全量同步的概率。

## 五、三种缓存更新策略

> reference：
>
> * [面试官：3 种缓存更新策略是怎样的？](https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&mid=2247516371&idx=2&sn=1976ef550b5b0a1d52f7ca09ec9d5d80&chksm=f98dc479cefa4d6fd74412c99f12b21ed3cee4b8e74c005710ce5bc575d0832e96e6184126c5&scene=178&cur_album_id=1790401816640225283&search_click_id=#rd)

对于每一种策略，在读模式或写模式下是怎样的？在读模式下，主要考虑的是数据不在缓存时，由谁加载数据？

1.Cache Aside（旁路缓存）策略

* 应用程序与缓存和数据库交互

* Cache Aside 需要先写入数据库，再删除缓存，而不能先删除缓存，再更新数据库

* 对于先删除缓存，再写入数据库导致的数据不一致，可以使用延迟双删策略：

  ``` shell
  #删除缓存
  redis.delKey(X)
  #更新数据库
  db.update(X)
  #睡眠
  Thread.sleep(N)
  #再删除缓存
  redis.delKey(X)
  ```

  加了个睡眠时间，主要是为了确保请求 A 在睡眠的时候，请求 B 能够在这这一段时间完成「从数据库读取数据，再把缺失的缓存写入缓存」的操作，然后请求 A 睡眠完，再删除缓存。

  所以，请求 A 的睡眠时间就需要大于请求 B 「从数据库读取数据 + 写入缓存」的时间。

  但是具体睡眠多久其实是个**玄学**，很难评估出来，所以这个方案也只是**尽可能**保证一致性而已，极端情况下，依然也会出现缓存不一致的现象。

  因此，还是比较建议用「先更新数据库，再删除缓存」的方案。

2.Read/Write Through（读穿/写穿）策略

* 应用程序与缓存交互，缓存和数据库交互
* 搭配写不分配
* 相较于 Cache Aside 比较少见，因为例如 Redis 等内存数据库都不提供写入数据库和自动加载数据库中的数据的能力

3.Write Back（写回）策略

* 应用程序与缓存交互，缓存和数据库交互
* 搭配写分配
* 对于脏数据的刷盘，缓存会通过批量异步更新的方式进行
* 和 Write Through 一样，Write Back 也很少应用到数据库和缓存的场景中，因为 Redis 没有异步更新数据库的能力

## 六、数据库和缓存如何保持一致性

> reference:
>
> * [老板真爱画大饼！](https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&mid=2247497782&idx=1&sn=89fd676bbe63a819ad1e32976a0755ee&chksm=f98dbc9ccefa358ab0379e4e7799f53668cb31d401ed329658d05e9aea83949a6898b46279e5&scene=178&cur_album_id=1790401816640225283&search_click_id=#rd)
> * [趣说 ｜ 数据库和缓存如何保证一致性？](https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&mid=2247508038&idx=2&sn=50a5d4a4b88f9572976753562aeb1b52&chksm=f98de4eccefa6dfaf9c48451685b51a7be62f237cb5ab13efb75a83b814437a370b2f8abfa88&scene=178&cur_album_id=1790401816640225283&search_click_id=#rd)

### 1. 先更新数据库，还是先更新缓存？

注意这里是更新缓存而不是删除缓存，不同于 Cache Aside，这里无论是先更新数据库，还是先更新缓存，都会出现并发问题。

* 考虑两条并发执行的指令，分别将 val 的值设置为 1,2，由于指令的交叉执行，无论先更新数据库还是先更新缓存，都会出现并发问题。

如何解决该问题，参考 Cache Aside，修改更新缓存操作为删除缓存，就可以保证数据的一致性。

此外，为了万无一失，还可以给数据加上过期时间，这样即使缓存数据不一致，也有过期时间来兜底，不会造成太大影响。

不过，虽然 Cache Aside 有效解决了一致性问题，但是它粗暴的删除缓存会导致缓存命中率下降，特别是业务是写多读少的情况，对性能的影响比较大。

如果我们不能接受缓存的频繁 miss，只能是更新缓存而不是删除缓存，此时为了保证数据库和缓存的一致性，有以下两种解决方案：

1. 在更新缓存前加个分布式锁，但是锁会影响 redis 的访问。
2. 在更新完缓存之后，加上一个较短的过期时间，降低数据不一致时的损失。

### 2. 删除缓存的时候失败了

在先更新数据库再删除缓存的方案中，如果在删除缓存的时候失败了，导致缓存中的数据依然是旧值怎么办？

有以下两种方案：

* 重试机制

  我们可以引入**消息队列**，将第二个操作（删除缓存）要操作的数据加入到消息队列，由消费者来操作数据。

  - 如果应用**删除缓存失败**，可以从消息队列中重新读取数据，然后再次删除缓存，这个就是**重试机制**。当然，如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。
  - 如果**删除缓存成功**，就要把数据从消息队列中移除，避免重复操作，否则就继续重试。

* 订阅 Mysql binlog，再操作缓存

  「**先更新数据库，再删缓存**」的策略的第一步是更新数据库，那么更新数据库成功，就会产生一条变更日志，记录在 binlog 里。

  于是我们就可以通过订阅 binlog 日志，拿到具体要操作的数据，然后再执行缓存删除，阿里巴巴开源的 Canal 中间件就是基于这个实现的。

所以，如果要想保证「先更新数据库，再删缓存」策略第二个操作能执行成功，我们可以使用「消息队列来重试缓存的删除」，或者「订阅 MySQL binlog 再操作缓存」，这两种方法有一个共同的特点，都是采用 **异步操作** 缓存。

## 七、过期删除策略

### 1. Redis 的过期删除策略

每当我们对一个 key 设置了过期时间时，Redis  会把该 key 带上过期时间存储到一个**过期字典**（expires dict）中，也就是说「过期字典」保存了数据库中所有 key 的过期时间。

当我们查询一个 key 时，Redis 首先检查该 key 是否存在于过期字典中：

- 如果不在，则正常读取键值；
- 如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期。

常见的三种过期删除策略：

- 定时删除：cpu 不友好，内存友好
- 惰性删除：cpu 友好，内存不友好
- 定期删除：折中吗。**每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。**

前面介绍了三种过期删除策略，每一种都有优缺点，仅使用某一个策略都不能满足实际需求。

所以， **Redis 选择「惰性删除+定期删除」这两种策略配和使用**，以求在合理使用 CPU 时间和避免内存浪费之间取得平衡。

### 2. Redis 持久化对过期键的处理

Redis 持久化文件有两种格式：RDB（Redis Database）和 AOF（Append Only File），下面我们分别来看过期键在这两种格式中的呈现状态。

RDB 文件分为两个阶段，RDB 文件生成阶段和加载阶段。

- **RDB 文件生成阶段**：从内存状态持久化成 RDB（文件）的时候，会对 key 进行过期检查，**过期的键「不会」被保存到新的 RDB 文件中**，因此 Redis 中的过期键不会对生成新 RDB 文件产生任何影响。

- **RDB 加载阶段**：RDB 加载阶段时，要看服务器是主服务器还是从服务器，分别对应以下两种情况：

- - **如果 Redis 是「主服务器」运行模式的话，在载入 RDB 文件时，程序会对文件中保存的键进行检查，过期键「不会」被载入到数据库中**。所以过期键不会对载入 RDB 文件的主服务器造成影响；
  - **如果 Redis 是「从服务器」运行模式的话，在载入 RDB 文件时，不论键是否过期都会被载入到数据库中**。但由于主从服务器在进行数据同步时，从服务器的数据会被清空。所以一般来说，过期键对载入 RDB 文件的从服务器也不会造成影响。

AOF 文件分为两个阶段，AOF 文件写入阶段和 AOF 重写阶段。

- **AOF 文件写入阶段**：当 Redis 以 AOF 模式持久化时，**如果数据库某个过期键还没被删除，那么 AOF 文件会保留此过期键，当此过期键被删除后，Redis 会向 AOF 文件追加一条 DEL 命令来显式地删除该键值**。
- **AOF 重写阶段**：执行 AOF 重写时，会对 Redis 中的键值对进行检查，**已过期的键不会被保存到重写后的 AOF 文件中**，因此不会对 AOF 重写造成任何影响。

### 3. Redis 主从模式中，对过期键会如何处理

当 Redis 运行在主从模式下时，**从库不会进行过期扫描，从库对过期的处理是被动的**。也就是即使从库中的 key 过期了，如果有客户端访问从库时，依然可以得到 key 对应的值，像未过期的键值对一样返回。

从库的过期键处理依靠主服务器控制，**主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库**，从库通过执行这条 del 指令来删除过期的 key。

## 八、内存淘汰策略

前面说的过期删除策略，是删除已过期的 key，而当 Redis 的运行内存已经超过 Redis 设置的最大内存之后，则会使用内存淘汰策略删除符合条件的 key，以此来保障 Redis 高效的运行。

在配置文件 `redis.conf` 中，可以通过参数 `maxmemory <bytes>` 来设定最大运行内存，只有在 Redis 的运行内存达到了我们设置的最大运行内存，才会触发内存淘汰策略。

不同位数的操作系统，maxmemory 的默认值是不同的：

- 在 64 位操作系统中，maxmemory 的默认值是 0，表示没有内存大小限制，那么不管用户存放多少数据到 Redis 中，Redis 也不会对可用内存进行检查，直到 Redis 实例因内存不足而崩溃也无作为。
- 在 32 位操作系统中，maxmemory 的默认值是 3G，因为 32 位的机器最大只支持 4GB 的内存，而系统本身就需要一定的内存资源来支持运行，所以 32 位操作系统限制最大 3 GB 的可用内存是非常合理的，这样可以避免因为内存不足而导致 Redis 实例崩溃。

Redis 内存淘汰策略共有八种，这八种策略大体分为「不进行数据淘汰」和「进行数据淘汰」两类策略。其中，「进行数据淘汰」又分为 「只淘汰过期数据」和「可以淘汰任意数据」。

***1、不进行数据淘汰的策略***

* **noeviction**（Redis3.0之后，默认的内存淘汰策略） ：它表示当运行内存超过最大设置内存时，不淘汰任何数据，而是不再提供服务，直接返回错误。

***2、进行数据淘汰的策略***

针对「进行数据淘汰」这一类策略，又可以细分为「在设置了过期时间的数据中进行淘汰」和「在所有数据范围内进行淘汰」这两类策略。

***2.1、在设置了过期时间的数据中进行淘汰：***

- **volatile-random**：随机淘汰设置了过期时间的任意键值；
- **volatile-ttl**：优先淘汰更早过期的键值。
- **volatile-lru**（Redis3.0 之前，默认的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最久未使用的键值；
- **volatile-lfu**（Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最少使用频率的键值；

***2.2、在所有数据范围内进行淘汰：***

- **allkeys-random**：随机淘汰任意键值;
- **allkeys-lru**：淘汰整个键值中最久未使用的键值；
- **allkeys-lfu**（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。

---

值得注意的是，Redis 实现的并不是传统的基于链表的 LRU，因为传统的 LRU 算法存在两个问题：

1. 需要用链表管理所有的缓存数据，这会带来额外的空间开销；
2. 当有数据被访问时，需要在链表上把该数据移动到头端，如果有大量数据被访问，就会带来很多链表移动操作，会很耗时，进而会降低 Redis 缓存性能。

Redis 实现的是一种**近似 LRU 算法**，目的是为了更好的节约内存，它的**实现方式是在 Redis 的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间**。

当 Redis 进行内存淘汰时，会使用**随机采样的方式来淘汰数据**，它是随机取 5 个值（此值可配置），然后**淘汰最久没有使用的那个**。

Redis 实现的 LRU 算法的优点：

- 不用为所有的数据维护一个大链表，节省了空间占用；
- 不用在每次数据访问时都移动链表项，提升了缓存的性能；

但是 LRU 算法有一个问题，**无法解决缓存污染问题**，比如应用一次读取了大量的数据，而这些数据只会被读取这一次，那么这些数据会留存在 Redis 缓存中很长一段时间，造成缓存污染。

因此，在 Redis 4.0 之后引入了 LFU 算法来解决这个问题。

LFU 全称是 Least Frequently Used 翻译为**最近最不常用的，**LFU 算法是根据数据访问次数来淘汰数据的，它的核心思想是“如果数据过去被访问多次，那么将来被访问的频率也更高”。

所以， LFU 算法会记录每个数据的访问次数。当一个数据被再次访问时，就会增加该数据的访问次数。这样就解决了偶尔被访问一次之后，数据留存在缓存中很长一段时间的问题，相比于 LRU 算法也更合理一些。

LFU 算法相比于  LRU 算法的实现，多记录了「数据的访问频次」的信息。

Redis 对象的结构如下：

```cpp
typedef struct redisObject {
    ...
      
    // 24 bits，用于记录对象的访问信息
    unsigned lru:24;  
    ...
} robj;
```

Redis 对象头中的 lru 字段，在 LRU 算法下和 LFU 算法下使用方式并不相同。

在 LRU 算法中，Redis 对象头的 24 bits 的 lru 字段是用来记录 key 的访问时间戳，因此在 LRU 模式下，Redis可以根据对象头中的 lru 字段记录的值，来比较最后一次 key 的访问时间长，从而淘汰最久未被使用的 key。

在 LFU 算法中，Redis对象头的 24 bits 的 lru 字段被分成两段来存储，高 16bit 存储 ldt(Last Decrement Time)，低 8bit 存储 logc(Logistic Counter)。

- ldt 是用来记录 key 的访问时间戳；
- logc 是用来记录 key 的访问频次，它的值越小表示使用频率越低，越容易淘汰，每个新加入的 key 的logc 初始值为 5。

注意，logc 并不是单纯的访问次数，而是访问频次（访问频率），因为 **logc  会随时间推移而衰减的**。

在每次 key 被访问时，会先对 logc 做一个衰减操作，衰减的值跟前后访问时间的差距有关系，如果上一次访问的时间与这一次访问的时间差距很大，那么衰减的值就越大，这样实现的 LFU 算法是根据**访问频率**来淘汰数据的，而不只是访问次数。访问频率需要考虑 key 的访问是多长时间段内发生的。key 的先前访问距离当前时间越长，那么这个 key 的访问频率相应地也就会降低，这样被淘汰的概率也会更大。

对 logc 做完衰减操作后，就开始对 logc  进行增加操作，增加操作并不是单纯直接 + 1，而是根据概率增加，如果 logc 越大的 key，它的 logc 就越难再增加。

所以，Redis 在访问 key 时，对于 logc  是这样变化的：

1. 先按照上次访问距离当前的时长，来对 logc 进行衰减；
2. 然后，再按照一定概率增加 logc 的值

redis.conf 提供了两个配置项，用于调整 LFU 算法从而控制 logc 的增长和衰减：

- `lfu-decay-time` 用于调整 logc 的衰减速度，它是一个以分钟为单位的数值，默认值为1，lfu-decay-time 值越大，衰减越慢；
- `lfu-log-factor` 用于调整 logc 的增长速度，lfu-log-factor 值越大，logc 增长越慢。

## 九、你确定 Redis 是单线程的进程吗

> reference:
>
> * [为什么单线程的 Redis 如何做到每秒数万 QPS ？](https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&mid=2247511819&idx=2&sn=b6c533071625d9f11c019f8a6c0f1b63&scene=21#wechat_redirect)
> * [面试官：你确定 Redis 是单线程的进程吗？](https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&mid=2247516338&idx=2&sn=481c0c5ba605eddbc4824056d941a261&chksm=f98dc418cefa4d0ec4e8e3e2a1c1badc6cb66b5c20775ff785b8ef0da708cf8eb0a1c42c236f&scene=178&cur_album_id=1790401816640225283&search_click_id=#rd)

### 1. Redis 是单线程吗

**Redis 单线程指的是「接收客户端请求->解析请求 ->进行数据读写等操作->发生数据给客户端」这个过程是由一个线程（主线程）来完成的**，这也是我们常说 Redis 是单线程的原因。

这种单线程模型，结合高效的  **I/O 多路复用机制**（如 epoll/kqueue），使得 Redis 能够避免多线程带来的上下文切换和锁竞争开销，尤其对于其内存中的数据结构操作，能实现非常高的性能。

但是，**Redis 程序并不是单线程的**，Redis 在启动的时候，是会**启动后台线程（BIO）**的：

- **Redis 在 2.6 版本**，会启动 2 个后台线程，分别处理关闭文件、AOF 刷盘这两个任务；
- **Redis 在 4.0 版本之后**，新增了一个新的后台线程，用来异步释放 Redis 内存，也就是 lazyfree 线程。例如执行 unlink key / flushdb async / flushall async 等命令，会把这些删除操作交给后台线程来执行，好处是不会导致 Redis 主线程卡顿。因此，当我们要删除一个大 key 的时候，不要使用 del 命令删除，因为 del 是在主线程处理的，这样会导致 Redis 主线程卡顿，因此我们应该使用 unlink 命令来异步删除大key。

之所以 Redis 为「关闭文件、AOF 刷盘、释放内存」这些任务创建单独的线程来处理，是因为这些任务的操作都是很耗时的，如果把这些任务都放在主线程来处理，那么 Redis 主线程就很容易发生阻塞，这样就无法处理后续的请求了。

后台线程相当于一个消费者，生产者把耗时任务丢到任务队列中，消费者（BIO）不停轮询这个队列，拿出任务就去执行对应的方法即可。

关闭文件、AOF 刷盘、释放内存这三个任务都有各自的任务队列：

- BIO_CLOSE_FILE，关闭文件任务队列：当队列有任务后，后台线程会调用 close(fd) ，将文件关闭；
- BIO_AOF_FSYNC，AOF刷盘任务队列：当 AOF 日志配置成 everysec 选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到队列中。当发现队列有任务后，后台线程会调用 fsync(fd)，将 AOF 文件刷盘，
- BIO_LAZY_FREE，lazy free 任务队列：当队列有任务后，后台线程会 free(obj) 释放对象 / free(dict) 删除数据库所有对象 / free(skiplist) 释放跳表对象；

### 2. Redis 单线程模式是怎样的

Redis 6.0 版本之前的单线模式如下图：

![redis_single_thread_before_v6.0](https://github.com/QaQOwOQaQ/picx-images-hosting/raw/master/image.8adihgi3ru.png)

### 3. Redis 采用单线程为什么还这么快

官方使用基准测试的结果是，**单线程的 Redis 吞吐量可以达到 10W/每秒**。

之所以 Redis 采用单线程（网络 I/O 和执行命令）那么快，有如下几个原因：

- Redis 的大部分操作**都在内存中完成**，并且采用了高效的数据结构，因此 Redis 瓶颈可能是机器的内存或者网络带宽，而并非 CPU，既然 CPU 不是瓶颈，那么自然就采用单线程的解决方案了；
- Redis 采用单线程模型可以**避免了多线程之间的竞争**，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。
- Redis 采用了 **I/O 多路复用机制**处理大量的客户端 Socket 请求，IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。

### 4. Redis 6.0 之前为什么使用单线程

我们都知道单线程的程序是无法利用服务器的多核 CPU 的，那么早期 Redis 版本的主要工作（网络 I/O 和执行命令）为什么还要使用单线程呢？我们不妨先看一下Redis官方给出的FAQ。

![why_single_thread_before_v6.0](https://github.com/QaQOwOQaQ/picx-images-hosting/raw/master/image.51eekt0lh8.webp)

核心意思是：**CPU 并不是制约 Redis 性能表现的瓶颈所在**，更多情况下是受到内存大小和网络I/O的限制，所以 Redis 核心网络模型使用单线程并没有什么问题，如果你想要使用服务的多核CPU，可以在一台服务器上启动多个节点或者采用分片集群的方式。

除了上面的官方回答，选择单线程的原因也有下面的考虑。

使用了单线程后，可维护性高，多线程模型虽然在某些方面表现优异，但是它却引入了程序执行顺序的不确定性，带来了并发读写的一系列问题，**增加了系统复杂度、同时可能存在线程切换、甚至加锁解锁、死锁造成的性能损耗**。

### 5. Redis 6.0 之后为什么引入了多线程?

虽然 Redis 的主要工作（网络 I/O 和执行命令）一直是单线程模型，但是在 Redis 6.0 版本之后，也采用了多个 I/O 线程来处理网络请求，这是因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在 **网络 I/O 的处理** 上。

> 在 Redis 的语境中，**网络 I/O (Input/Output)** 主要指以下两个核心环节：
>
> 1. **从客户端读取数据 (Input)：**
>    - **接收原始字节流：** 当客户端向 Redis 发送命令时，数据通过网络传输到达 Redis 服务器。这涉及底层的 TCP/IP 协议栈，Redis 需要从操作系统的网络缓冲区中读取这些原始字节。
>    - **协议解析：** 读取到的原始字节流是按照 Redis 自己的通信协议 (RESP, Redis Serialization Protocol) 进行编码的。Redis 需要解析这些字节流，将其还原成客户端发送的命令（例如 `SET key value`、`GET key` 等），并提取出命令参数。
> 2. **向客户端写入数据 (Output)：**
>    - **构建响应：** 在 Redis 主线程执行完命令（例如 `GET key` 后获取到 `value`）之后，它需要将结果按照 RESP 协议编码成字节流。
>    - **发送数据到网络：** 编码好的字节流需要通过网络发送回客户端。这同样涉及底层的 TCP/IP 协议栈，Redis 需要将这些数据写入操作系统的网络缓冲区，最终通过网络传输到客户端。
>
> **在 Redis 6.0 之前，这两个过程（读取、解析、构建响应、写入）都是由唯一的“主线程”来完成的。** 尽管 Redis 使用了 **I/O 多路复用** (如 epoll/kqueue) 技术来高效地监听多个客户端连接的读写事件，避免了阻塞，但当某个连接有数据可读或可写时，具体的读写和协议解析工作仍然由主线程亲自完成。
>
> **Redis 6.0 引入多线程后，这里的“网络 I/O”具体是指将上述步骤中的：**
>
> - **从客户端读取原始字节流**
> - **对读取到的原始字节流进行协议解析**
> - **将执行结果编码成字节流**
> - **将编码后的字节流写入网络**
>
> 这部分**耗时的网络数据处理和协议编解码工作**，从主线程中剥离出来，交由多个 **I/O 线程**（通常配置为 `io-threads` 数量）来并行处理。
>
> **职责划分大致如下：**
>
> - **主线程 (Main Thread):**
>   - 负责监听客户端连接的接入（`accept`）。
>   - **核心命令的执行：** 所有的 Redis 命令（如 `GET`、`SET`、`LPUSH` 等）仍然由主线程串行执行，这保证了 Redis 单命令操作的原子性。
>   - 将解析好的命令放入执行队列。
>   - 从 I/O 线程获取命令执行结果，并准备待写入的数据。
> - **I/O 线程 (IO Threads):**
>   - **并行读取客户端数据：** 从网络 socket 中读取原始字节流。
>   - **并行解析客户端命令：** 将读取到的字节流按照 RESP 协议解析成 Redis 命令结构。
>   - **并行编码响应数据：** 将主线程执行后的结果，编码成 RESP 协议的字节流。
>   - **并行写入响应数据：** 将编码好的字节流写入到网络 socket，发送回客户端。
>
> 通过这种方式，Redis 6.0 的多线程 I/O 模块有效地将网络 I/O 的阻塞和计算密集型任务（协议解析和编码）分散到多个 CPU 核上，从而减少了主线程在这些任务上的等待时间，显著提升了在高并发网络流量下的吞吐量。

所以为了提高网络请求处理的并行度，Redis 6.0 对于网络请求采用多线程来处理。**但是对于命令执行，Redis 仍然使用单线程来处理，**所以大家**不要误解** Redis 有多线程同时执行命令。

Redis 官方表示，**Redis 6.0 版本引入的多线程 I/O 特性对性能提升至少是一倍以上**。

Redis 6.0 版本支持的 I/O  多线程特性，默认是 I/O 多线程只处理写操作（write client socket），并不会以多线程的方式处理读操作（read client socket）。要想开启多线程处理客户端读请求，就需要把  Redis.conf  配置文件中的 io-threads-do-reads 配置项设为 yes。

```
//读请求也使用io多线程
io-threads-do-reads yes 
```

同时， Redis.conf  配置文件中提供了  IO 多线程个数的配置项。

```
// io-threads N，表示启用 N-1 个 I/O 多线程（主线程也算一个 I/O 线程）
io-threads 4 
```

关于线程数的设置，官方的建议是如果为 4 核的 CPU，建议线程数设置为 2 或 3，如果为 8 核 CPU 建议线程数设置为 6，线程数一定要小于机器核数，线程数并不是越大越好。因此， **Redis 6.0 版本之后，**Redis 在启动的时候，默认情况下会有 6 个线程：

- Redis-server ：Redis的主线程，主要负责执行命令；
- bio_close_file、bio_aof_fsync、bio_lazy_free：三个后台线程，分别异步处理关闭文件任务、AOF刷盘任务、释放内存任务；
- io_thd_1、io_thd_2、io_thd_3：三个 I/O 线程，io-threads 默认是 4 ，所以会启动 3（4-1）个 I/O 多线程，用来分担 Redis 网络 I/O 的压力。

## 十、用 Redis 实现分布式锁

> reference:
>
> * [面试官：如何用 Redis 实现分布式锁？](https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&mid=2247517757&idx=2&sn=67d56ebc0accd449c75ec6c36fca8645&chksm=f98dc297cefa4b811a2cf04d60b5f28f8e2d59e1281cf3e433579bb164767342b0499f6f689a&scene=178&cur_album_id=1790401816640225283&search_click_id=#rd)
> * [Is Redlock Safe? 一场关于 Redlock 的辩论](https://juejin.cn/post/7049588479025479717)
> * [Distributed Locks with Redis](https://redis.io/docs/latest/develop/use/patterns/distributed-locks/)

### 1. 为什么 Redis 可以实现分布式锁

分布式锁是用于分布式环境下并发控制的一种机制，用于控制某个资源在同一时刻只能被一个应用所使用。

Redis 本身可以被多个客户端共享访问，正好就是一个共享存储系统，可以用来保存分布式锁，而且 Redis 的读写性能高，可以应对高并发的锁操作场景。

Redis 的 SET 命令有个 NX 参数可以实现「key不存在才插入」，所以可以用它来实现分布式锁：

- 如果 key 不存在，则显示插入成功，可以用来表示加锁成功；
- 如果 key 存在，则会显示插入失败，可以用来表示加锁失败。

基于 Redis 节点实现分布式锁时，对于加锁操作，我们需要满足三个条件。

- 加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以原子操作的方式完成，所以，我们使用 SET 命令带上 NX 选项来实现加锁；
- 锁变量需要设置过期时间，以免客户端拿到锁后发生异常，导致锁一直无法释放，所以，我们在 SET 命令执行时加上 EX/PX 选项，设置其过期时间；
- 锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以，我们使用 SET 命令设置锁变量值时，每个客户端设置的值是一个唯一值，用于标识客户端；

满足这三个条件的分布式命令如下：

```shell
SET lock_key unique_value NX PX 10000 
```

- lock_key 就是 key 键；
- unique_value 是客户端生成的唯一的标识，区分来自不同客户端的锁操作；
- NX 代表只在 lock_key 不存在时，才对 lock_key 进行设置操作；
- PX 10000 表示设置 lock_key 的过期时间为 10s，这是为了避免客户端发生异常而无法释放锁。

而解锁的过程就是将 lock_key 键删除（del lock_key），但不能乱删，要保证执行操作的客户端就是加锁的客户端。所以，解锁的时候，我们要先判断锁的 unique_value 是否为加锁客户端，是的话，才将 lock_key 键删除。

可以看到，解锁是有两个操作，这时就需要 **Lua 脚本** 来保证解锁的原子性，因为 Redis 在执行 Lua 脚本时，可以以原子性的方式执行，保证了锁释放操作的原子性。

```lua
// 释放锁时，先比较 unique_value 是否相等，避免锁的误释放
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
```

这样一来，就通过使用 SET 命令和 Lua 脚本在 Redis 单节点上完成了分布式锁的加锁和解锁。

### 2. 基于 Redis 实现的分布式锁有什么优缺点

基于 Redis 实现分布式锁的**优点**：

1. 性能高效（这是选择缓存实现分布式锁最核心的出发点，Redis 是缓存数据库，对 key 的访问很高效）。
2. 实现方便。很多研发工程师选择使用 Redis 来实现分布式锁，很大成分上是因为 Redis 提供了 setnx 方法，实现分布式锁很方便。
3. 避免单点故障（因为 Redis 是跨集群部署的，自然就避免了单点故障）。

基于 Redis 实现分布式锁的**缺点**：

- **超时时间不好设置**。如果锁的超时时间设置过长，会影响性能，如果设置的超时时间过短会保护不到共享资源。比如在有些场景中，一个线程 A 获取到了锁之后，由于业务代码执行时间可能比较长，导致超过了锁的超时时间，自动失效，注意 A 线程没执行完，后续线程 B 又意外的持有了锁，意味着可以操作共享资源，那么两个线程之间的共享资源就没办法进行保护了。

- - **那么如何合理设置超时时间呢？** 我们可以基于 **续约** 的方式设置超时时间：先给锁设置一个超时时间，然后启动一个守护线程，让守护线程在一段时间后，重新设置这个锁的超时时间。实现方式就是：写一个守护线程，然后去判断锁的情况，当锁快失效的时候，再次进行续约加锁，当主线程执行完成后，销毁续约锁即可，不过这种方式实现起来相对复杂。

- **Redis 主从复制模式中的数据是异步复制的，这样导致分布式锁的不可靠性**。如果在 Redis 主节点获取到锁后，在没有同步到其他节点时，Redis 主节点宕机了，此时新的 Redis 主节点依然可以获取锁，所以多个应用服务就可以同时获取到锁。

### 3. 如何解决集群情况下 Redis 分布式锁的可靠性

为了保证集群环境下分布式锁的可靠性，Redis 官方已经设计了一个分布式锁算法 Redlock（红锁）。

它是基于多个 Redis 节点的分布式锁，即使有节点发生了故障，锁变量仍然是存在的，客户端还是可以完成锁操作。

Redlock 算法的基本思路，**是让客户端和多个独立的 Redis 节点依次请求申请加锁，如果客户端能够和半数以上的节点成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁，否则加锁失败**。

这样一来，即使有某个 Redis 节点发生故障，因为锁的数据在其他节点上也有保存，所以客户端仍然可以正常地进行锁操作，锁的数据也不会丢失。

Redlock 算法加锁三个过程：

- 第一步是，客户端获取当前时间。

- 第二步是，客户端按顺序依次向 N 个 Redis 节点执行加锁操作：

- - 加锁操作使用 SET 命令，带上 NX，EX/PX 选项，以及带上客户端的唯一标识。
  - 如果某个 Redis 节点发生故障了，为了保证在这种情况下，Redlock 算法能够继续运行，我们需要给「加锁操作」设置一个超时时间（不是对「锁」设置超时时间，而是对「加锁操作」设置超时时间）。

- 第三步是，一旦客户端完成了和所有 Redis 节点的加锁操作，客户端就要计算整个加锁过程的总耗时（t1）。

加锁成功要同时满足两个条件（*简述：如果有超过半数的 Redis 节点成功的获取到了锁，并且总耗时没有超过锁的有效时间，那么就是加锁成功*）：

- 条件一：客户端从超过半数（大于等于 N/2+1）的 Redis 节点上成功获取到了锁；
- 条件二：客户端获取锁的总耗时（t1）没有超过锁的有效时间。

加锁成功后，客户端需要重新计算这把锁的有效时间，计算的结果是「锁的最初有效时间」减去「客户端为获取锁的总耗时（t1）」。

加锁失败后，客户端向所有 Redis 节点发起释放锁的操作，释放锁的操作和在单节点上释放锁的操作一样，只要执行释放锁的 Lua 脚本就可以了。

## 十一、为什么 Redis 要有哨兵

> reference:
>
> * [面试官：为什么 Redis 要有哨兵？监控，选主，通知](https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&mid=2247515688&idx=2&sn=9680569edd01c327253c7eb87a75ab94&chksm=f98dfa82cefa73943fa320a1debda7c7d461c675a41cbf4c9808009f6c082588ab194344f4f0&scene=178&cur_album_id=1790401816640225283&search_click_id=#rd)

### 1. 什么是哨兵

在 Redis 中，**哨兵 (Sentinel)** 是一个用于实现 **高可用性 (High Availability)** 的分布式系统。它不是一个数据存储服务，而是一个特殊的 Redis 进程，主要职责是监控 Redis 主从集群的健康状况，并在主节点发生故障时自动进行故障转移，从而确保 Redis 服务的持续可用性。

**哨兵的主要作用和概念总结如下：**

1. **监控 (Monitoring)**：
   - 哨兵会持续地监控 Redis 主节点和从节点（以及其他哨兵节点）的运行状态。
   - 它会定期发送 PING 命令，检查各个节点是否在线、响应是否正常。
   - 如果发现某个节点长时间没有响应，哨兵会将其标记为下线。
2. **故障检测与通知 (Failure Detection and Notification)**：
   - 当一个主节点被某个哨兵判断为下线时，它会向其他哨兵节点询问，看其他哨兵是否也认为该主节点下线。
   - 如果达到一定数量（**法定数量 Quorum**）的哨兵都认为主节点下线了，那么主节点就被正式标记为“客观下线” (Objectively Down)。
   - 一旦主节点被标记为客观下线，哨兵可以向系统管理员或其他应用程序发送通知（例如通过 API）。
3. **自动故障转移 (Automatic Failover)**：
   - 当主节点客观下线后，哨兵集群会进行一次 **领头哨兵选举 (Leader Election)**，选出一个哨兵来负责故障转移。
   - 被选中的领头哨兵会在现有从节点中，根据一定的规则（如数据完整性、复制偏移量等）选择一个最合适的从节点，将其提升为新的主节点。
   - 然后，它会通知其他从节点，让它们去复制新的主节点的数据。
   - 最后，它会通知客户端，告知新的主节点地址，以便客户端能够连接到新的主节点继续操作，从而实现服务的无缝切换，最大限度地减少停机时间。
4. **配置提供者 (Configuration Provider)**：
   - 客户端不需要直接知道主节点的地址。它们可以连接到哨兵节点，向哨兵查询当前哪个节点是主节点。
   - 当发生故障转移时，哨兵会自动更新内部配置，并向客户端报告新的主节点地址，这样客户端就可以自动重新连接到新的主节点，无需人工干预。

**为什么需要多个哨兵节点？**

Redis Sentinel 本身也是一个分布式系统，通常建议部署至少三个哨兵实例。这是为了避免“单点故障”和“脑裂”问题：

- **避免误判：** 单个哨兵可能会因为网络问题或自身故障而误判主节点下线。多个哨兵通过投票机制（Quorum）来达成共识，可以大大降低误判的风险。
- **提高健壮性：** 如果一个或几个哨兵节点发生故障，只要还有足够多的哨兵节点正常运行，整个哨兵系统仍然可以正常工作。

总之，Redis 哨兵机制是实现 Redis 高可用性的核心组件，它通过自动化监控、故障检测和故障转移，大大简化了 Redis 集群的运维，并确保了即使在主节点发生故障时也能提供不间断的服务。

### 2. 为什么要有哨兵机制

在 Redis 的主从架构中，由于主从模式是读写分离的，如果主节点（master）挂了，那么将没有主节点来服务客户端的写操作请求，也没有主节点给从节点（slave）进行数据同步了。

这时如果要恢复服务的话，需要人工介入，选择一个「从节点」切换为「主节点」，然后让其他从节点指向新的主节点，同时还需要通知上游那些连接 Redis 主节点的客户端，将其配置中的主节点 IP 地址更新为「新主节点」的 IP 地址。

这样也不太“智能”了，要是有一个节点能监控「主节点」的状态，当发现主节点挂了 ，它自动将一个「从节点」切换为「主节点」的话，那么可以节省我们很多事情啊！

Redis 在 2.8 版本以后提供的**哨兵（\*Sentinel\*）机制**，它的作用是实现**主从节点故障转移**。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。

### 3. 哨兵机制是如何工作的

哨兵其实是一个运行在特殊模式下的 **Redis 进程**，所以它也是一个节点。从“哨兵”这个名字也可以看得出来，它相当于是 **“观察者节点”**，观察的对象是 **主从节点**。

当然，它不仅仅是观察那么简单，在它观察到有异常的状况下，会做出一些“动作”，来修复异常状态。

哨兵节点主要负责三件事情：<font color=blue>**监控、选主、通知**</font>。

所以，我们重点要学习这三件事情：

- 哨兵节点是如何监控节点的？又是如何判断主节点是否真的故障了？
- 根据什么规则选择一个从节点切换为主节点？
- 怎么把新主节点的相关信息通知给从节点和客户端呢？

### 4. 如何判断主节点真的故障了

哨兵会每隔 1 秒给所有主从节点发送 PING 命令，当主从节点收到 PING 命令后，会发送一个响应命令给哨兵，这样就可以判断它们是否在正常运行。

如果主节点或者从节点没有在规定的时间内响应哨兵的 PING 命令，哨兵就会将它们标记为「**主观下线**」。这个「规定的时间」是配置项  `down-after-milliseconds` 参数设定的，单位是毫秒。

客观下线只适用于主节点。

之所以针对「主节点」设计「主观下线」和「客观下线」两个状态，是因为有可能「主节点」其实并没有故障，可能只是因为主节点的系统压力比较大或者网络发送了拥塞，导致主节点没有在规定时间内响应哨兵的 PING 命令。

所以，为了减少误判的情况，哨兵在部署的时候不会只部署一个节点，而是用多个节点部署成**哨兵集群**（*最好是奇数，最少需要三台机器来部署哨兵集群*），**通过多个哨兵节点一起判断，就可以就可以避免单个哨兵因为自身网络状况不好，而误判主节点下线的情况**。同时，多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低。

当一个哨兵判断主节点为「主观下线」后，就会向其他哨兵发起命令，其他哨兵收到这个命令后，就会根据自身和主节点的网络状况，做出赞成投票或者拒绝投票的响应。

当这个哨兵的赞同票数达到哨兵配置文件中的 quorum 配置项设定的值后，这时主节点就会被该哨兵标记为「客观下线」。

例如，现在有 3 个哨兵，quorum 配置的是 2，那么一个哨兵需要 2 张赞成票，就可以标记主节点为“客观下线”了。这 2 张赞成票包括哨兵自己的一张赞成票和另外两个哨兵的赞成票。

> quorum 的值一般设置为哨兵个数的二分之一加1，例如 3 个哨兵就设置 2。

哨兵判断完主节点客观下线后，哨兵就要开始在多个「从节点」中，选出一个从节点来做新主节点。

### 5. 由哪个哨兵进行故障转移

前面说过，为了更加“客观”的判断主节点故障了，一般不会只由单个哨兵的检测结果来判断，而是多个哨兵一起判断，这样可以减少误判概率，所以**哨兵是以哨兵集群的方式存在的**。

问题来了，由哨兵集群中的哪个节点进行主从故障转移呢？

所以这时候，还需要在哨兵集群中选出一个 leeder，让 leeder 来执行主从切换。

选举 leeder 的过程其实是一个投票的过程，在投票开始前，肯定得有个「候选者」。

> 那谁来作为候选者呢？

哪个哨兵节点判断主节点为「客观下线」，这个哨兵节点就是候选者，所谓的候选者就是想当 Leader 的哨兵。

举个例子，假设有三个哨兵。当哨兵 B 先判断到主节点「主观下线后」，就会给其他实例发送 is-master-down-by-addr 命令。接着，其他哨兵会根据自己和主节点的网络连接情况，做出赞成投票或者拒绝投票的响应。

当哨兵 B 收到赞成票数达到哨兵配置文件中的 quorum 配置项设定的值后，就会将主节点标记为「客观下线」，此时的哨兵 B 就是一个Leader 候选者。

> 候选者如何选举成为 Leader？

候选者会向其他哨兵发送命令，表明希望成为 Leader 来执行主从切换，并让所有其他哨兵对它进行投票。

每个哨兵只有一次投票机会，如果用完后就不能参与投票了，可以投给自己或投给别人，但是只有候选者才能把票投给自己。

那么在投票过程中，任何一个「候选者」，要满足两个条件：

- 第一，拿到半数以上的赞成票；
- 第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。

> 注意，对于第一条，得到半数以上的赞成票，是不考虑某些哨兵掉线的情况的。例如，有 5 个哨兵，但是 2 个哨兵掉线，那么依然需要 (5+1)/2=3 张赞成票。

举个例子，假设哨兵节点有  3 个，quorum 设置为 2，那么任何一个想成为 Leader 的哨兵只要拿到 2 张赞成票，就可以选举成功了。如果没有满足条件，就需要重新进行选举。

这时候有的同学就会问了，如果某个时间点，刚好有两个哨兵节点判断到主节点为客观下线，那这时不就有两个候选者了？这时该如何决定谁是 Leader 呢？

每位候选者都会先给自己投一票，然后向其他哨兵发起投票请求。如果投票者先收到「候选者 A」的投票请求，就会先投票给它，如果投票者用完投票机会后，收到「候选者 B」的投票请求后，就会拒绝投票。这时，候选者 A 先满足了上面的那两个条件，所以「候选者 A」就会被选举为 Leader。

> 为什么哨兵节点至少要有 3 个？

如果哨兵集群中只有 2 个哨兵节点，此时如果一个哨兵想要成功成为 Leader，必须获得 2 票，而不是 1 票。

所以，如果哨兵集群中有个哨兵挂掉了，那么就只剩一个哨兵了，如果这个哨兵想要成为 Leader，这时票数就没办法达到 2 票，就无法成功成为 Leader，这时是无法进行主从节点切换的。

因此，通常我们至少会配置 3 个哨兵节点。这时，如果哨兵集群中有个哨兵挂掉了，那么还剩下两个个哨兵，如果这个哨兵想要成为 Leader，这时还是有机会达到 2 票的，所以还是可以选举成功的，不会导致无法进行主从节点切换。

当然，你要问，如果 3 个哨兵节点，挂了 2 个怎么办？这个时候得人为介入了，或者增加多一点哨兵节点。

- **哨兵集群可以判定主节点“客观下线”**。哨兵集群还剩下 3 个哨兵，当一个哨兵判断主节点“主观下线”后，询问另外 2 个哨兵后，有可能能拿到 3 张赞同票，这时就达到了 quorum 的值，因此，哨兵集群可以判定主节点为“客观下线”。
- **哨兵集群可以完成主从切换**。当有个哨兵标记主节点为「客观下线」后，就会进行选举 Leader 的过程，因为此时哨兵集群还剩下 3 个哨兵，那么还是可以拿到半数以上（5/2+1=3）的票，而且也达到了 quorum 值，满足了选举 Leader 的两个条件， 所以就能选举成功，因此哨兵集群可以完成主从切换。

如果 quorum 设置为 2 ，并且如果有 3 个哨兵故障的话。此时哨兵集群还是可以判定主节点为“客观下线”，但是哨兵不能完成主从切换了，大家可以自己推演下。

如果 quorum 设置为 3，并且如果有 3 个哨兵故障的话，哨兵集群即不能判定主节点为“客观下线”，也不能完成主从切换了。

可以看到，quorum 为 2 的时候，并且如果有 3 个哨兵故障的话，虽然可以判定主节点为“客观下线”，但是不能完成主从切换，这样感觉「判定主节点为客观下线」这件事情白做了一样，既然这样，还不如不要做，quorum 为 3 的时候，就可以避免这种无用功。

所以，**quorum 的值建议设置为哨兵个数的二分之一加1**，例如 3 个哨兵就设置 2，5 个哨兵设置为 3，而且**哨兵节点的数量应该是奇数**。

### 6. 主从转移的过程是怎样的

在哨兵集群中通过投票的方式，选举出了哨兵 leader 后，就可以进行主从故障转移的过程了。

主从故障转移操作包含以下四个步骤：

#### 6.1 第一步：选出新主节点

在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点。

那么多「从节点」，到底选择哪个从节点作为新主节点的？

随机的方式好吗？随机的方式，实现起来很简单，但是如果选到一个网络状态不好的从节点作为新主节点，那么可能在将来不久又要做一次主从故障迁移。

所以，我们首先要把网络状态不好的从节点给过滤掉。首先把已经下线的从节点过滤掉，然后把以往网络连接状态不好的从节点也给过滤掉。

至此，我们就把网络状态不好的从节点过滤掉了，接下来要对所有从节点进行三轮考察：**优先级、复制进度、ID 号**。在进行每一轮考察的时候，哪个从节点优先胜出，就选择其作为新主节点。

- 第一轮考察：哨兵首先会根据从节点的优先级来进行排序，优先级越小排名越靠前，
- 第二轮考察：如果优先级相同，则查看复制的下标，哪个从「主节点」接收的复制数据多，哪个就靠前。
- 第三轮考察：如果优先级和下标都相同，就选择从节点 ID 较小的那个。

在选举出从节点后，哨兵 leader  向被选中的从节点发送 `SLAVEOF no one` 命令，让这个从节点解除从节点的身份，将其变为新主节点。

在发送 `SLAVEOF no one` 命令之后，哨兵 leader 会以每秒一次的频率向被升级的从节点发送 `INFO` 命令（没进行故障转移之前，`INFO` 命令的频率是每十秒一次），并观察命令回复中的角色信息，当被升级节点的角色信息从原来的 slave 变为 master 时，哨兵 leader 就知道被选中的从节点已经顺利升级为主节点了。

#### 6.2 第二部：将从节点指向新主节点

当新主节点出现之后，哨兵 leader  下一步要做的就是，让已下线主节点属下的所有「从节点」指向「新主节点」，这一动作可以通过向「从节点」发送 `SLAVEOF` 命令来实现。

#### 6.3 第三步：通知客户的主节点已更换

经过前面一系列的操作后，哨兵集群终于完成主从切换的工作，那么新主节点的信息要如何通知给客户端呢？

这主要**通过 Redis 的发布者/订阅者机制来实现**的。每个哨兵节点提供发布者/订阅者机制，客户端可以从哨兵订阅消息。

哨兵提供的消息订阅频道有很多，不同频道包含了主从节点切换过程中的不同关键事件。几个常见的事件如下：

![图片](https://github.com/QaQOwOQaQ/picx-images-hosting/raw/master/640.70albfis6u.webp)

客户端和哨兵建立连接后，客户端会订阅哨兵提供的频道。**主从切换完成后，哨兵就会向  `+switch-master` 频道发布新主节点的 IP 地址和端口的消息，这个时候客户端就可以收到这条信息，然后用这里面的新主节点的 IP 地址和端口进行通信了**。

通过发布者/订阅者机制机制，有了这些事件通知，客户端不仅可以在主从切换后得到新主节点的连接信息，还可以监控到主从节点切换过程中发生的各个重要事件。这样，客户端就可以知道主从切换进行到哪一步了，有助于了解切换进度。

#### 6.4 将旧主节点变为从节点

故障转移操作最后要做的是，继续监视旧主节点，当旧主节点重新上线时，哨兵集群就会向它发送 `SLAVEOF` 命令，让它成为新主节点的从节点。

### 7. 哨兵集群是如何工作的

在搭建哨兵集群的时候，只需要填下面几个参数，设置设置主节点名字、主节点的 IP 地址和端口号以及 quorum 值。

```cpp
sentinel monitor <master-name> <ip> <redis-port> <quorum> 
```

而不需要填其他哨兵节点的信息，这是因为 **哨兵节点之间是通过 Redis 的发布者/订阅者机制来相互发现的**。

在主从集群中，主节点上有一个名为`__sentinel__:hello`的频道，不同哨兵就是通过它来相互发现，实现互相通信的。具体的，哨兵节点会将自己的 IP 地址和端口号发布到该频道，这样其它订阅了该频道的哨兵就可以得到该烧饼节点的 IP 地址和端口号，从而与该节点建立网络连接。

哨兵集群会对「从节点」的运行状态进行监控，那哨兵集群如何知道「从节点」的信息？

主节点知道所有「从节点」的信息，所以哨兵会每 10 秒一次的频率向主节点发送 INFO 命令来获取所有「从节点」的信息。具体的，哨兵可以给主节点发送 INFO 命令，主节点接受到这个命令后，就会把从节点列表返回给哨兵。接着，哨兵就可以根据从节点列表中的连接信息，和每个从节点建立连接，并在这个连接上持续地对从节点进行监控。

正是通过  Redis 的发布者/订阅者机制，哨兵之间可以相互感知，然后组成集群，同时，哨兵又通过 INFO 命令，在主节点里获得了所有从节点连接信息，于是就能和从节点建立连接，并进行监控了。

### 8. 总结

Redis 在 2.8 版本以后提供的**哨兵（\*Sentinel\*）机制**，它的作用是实现**主从节点故障转移**。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。

哨兵一般是以集群的方式部署，至少需要 3 个哨兵节点，哨兵集群主要负责三件事情：**监控、选主、通知**。

哨兵节点通过 Redis 的发布者/订阅者机制，哨兵之间可以相互感知，相互连接，然后组成哨兵集群，同时哨兵又通过 INFO 命令，在主节点里获得了所有从节点连接信息，于是就能和从节点建立连接，并进行监控了。

*1、第一轮投票：判断主节点下线*

当哨兵集群中的某个哨兵判定主节点下线（主观下线）后，就会向其他哨兵发起命令，其他哨兵收到这个命令后，就会根据自身和主节点的网络状况，做出赞成投票或者拒绝投票的响应。

当这个哨兵的赞同票数达到哨兵配置文件中的 quorum 配置项设定的值后，这时主节点就会被该哨兵标记为「客观下线」。

*2、第二轮投票：选出哨兵 leader*

某个哨兵判定主节点客观下线后，该哨兵就会发起投票，告诉其他哨兵，它想成为 leader，想成为 leader 的哨兵节点，要满足两个条件：

- 第一，拿到半数以上的赞成票；
- 第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。

*3、由哨兵 leader 进行主从故障转移*

选举出了哨兵 leader 后，就可以进行主从故障转移的过程了。该操作包含以下四个步骤：

- 第一步：在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点，选择的规则：

- - 过滤掉已经离线的从节点；
  - 过滤掉历史网络连接状态不好的从节点；
  - 将剩下的从节点，进行三轮考察：优先级、复制进度、ID 号。在每一轮考察过程中，如果找到了一个胜出的从节点，就将其作为新主节点。

- 第二步：让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」；

- 第三步：将新主节点的 IP 地址和信息，通过「发布者/订阅者机制」通知给客户端；

- 第四步：继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点；

## 十二、Redis 大 Key

> reference：
>
> * [面试官：Redis 大 key 要如何处理？](https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&mid=2247518433&idx=2&sn=e78f630c07f4e60fb78999eb3d742e9e&chksm=f98dcc4bcefa455d8ffde9ad6c8da9b3371a401766a55cbee7af11c87be070d823c8d5926aef&scene=178&cur_album_id=1790401816640225283&search_click_id=#rd)
> * [字节二面：Redis 的大 Key 对持久化有什么影响？](https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&mid=2247520683&idx=1&sn=f9e51d382602338d5778dd77daa7f88f&chksm=f98dd501cefa5c1769df4324e8b3cdb880c4bb8aff09ca1e4d444997dc40d585cb431ea5f2d5&scene=178&cur_album_id=1790401816640225283&search_click_id=#rd)

### 1. 什么是大 Key

大 key 并不是指 key 的值很大，而是 key 对应的 value 很大。

一般而言，下面这两种情况被称为大 key：

- String 类型的值大于 10 KB；
- Hash、List、Set、ZSet 类型的元素的个数超过 5000个；

### 2. 大 key 会造成什么影响

大 key 主要会带来以下四种影响：

- **客户端超时阻塞**。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。
- **引发网络阻塞**。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。
- **阻塞工作线程**。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。
- **内存分布不均**。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。

### 3. 如何找到大 Key

#### 3.1 redis-cli --bigkeys 查找大key

可以通过 redis-cli --bigkeys 命令查找大 key：

```
redis-cli -h 127.0.0.1 -p6379 -a "password" -- bigkeys
```

使用的时候注意事项：

- 最好选择在从节点上执行该命令。因为主节点上执行时，会阻塞主节点；
- 如果没有从节点，那么可以选择在 Redis 实例业务压力的低峰阶段进行扫描查询，以免影响到实例的正常运行；或者可以使用 -i 参数控制扫描间隔，避免长时间扫描降低 Redis 实例的性能。

该方式的不足之处：

- 这个方法只能返回 **每种类型中最大的那个 bigkey**，无法得到大小排在前 N 位的 bigkey；
- **对于集合类型来说，这个方法只统计集合元素个数的多少，而不是实际占用的内存量。**但是，一个集合中的元素个数多，并不一定占用的内存就多。因为，有可能每个元素占用的内存很小，这样的话，即使元素个数有很多，总内存开销也不大；

#### 3.2 使用 SCAN 命令查找大 key

使用 SCAN 命令对数据库扫描，然后用 TYPE 命令获取返回的每一个 key 的类型。

对于 String 类型，可以直接使用 STRLEN 命令获取字符串的长度，也就是占用的内存空间字节数。

对于集合类型来说，有两种方法可以获得它占用的内存大小：

- 如果能够预先从业务层知道集合元素的平均大小，那么，可以使用下面的命令获取集合元素的个数，然后乘以集合元素的平均大小，这样就能获得集合占用的内存大小了。List 类型：`LLEN` 命令；Hash 类型：`HLEN` 命令；Set 类型：`SCARD` 命令；Sorted Set 类型：`ZCARD` 命令；
- 如果不能提前知道写入集合的元素大小，可以使用 `MEMORY USAGE` 命令（需要 Redis 4.0 及以上版本），查询一个键值对占用的内存空间。

> 需要注意的是，`MEMORY USAGE` 命令的时间复杂度并不是 O(1) 的。
>
> 由于直接分析整个总体通常是不切实际的（比如总体太大、成本太高、耗时太长或根本无法获取所有数据），所以通过对样本进行研究，然后将从样本中得出的结论**推断到整个总体**。
>
> 它的核心思想是通过“抽样”（Sampling），以局部平均值代替整体平均值来估算集合的大小。因此，这里存在精确性和效率的冲突。
>
> * 抽样少：效率高，准确率低
> * 抽样多：效率低，准确率高

#### 3.3 使用 RdbTools 工具查找大 key

使用 RdbTools 第三方开源工具，可以用来解析 Redis 快照（RDB）文件，找到其中的大 key。

比如，下面这条命令，将大于 10 kb 的  key  输出到一个表格文件。

```
rdb dump.rdb -c memory --bytes 10240 -f redis.csv
```

### **4. Redis 大 Key 对持久化的影响**

Redis 的持久化方式有两种：AOF 日志和 RDB 快照。

所以接下来，针对这两种持久化方式具体分析分析。

#### 4.1 大 key 对 AOF 日志的影响

* AOF 缓冲区：位于内存中（快速）
* AOF：位于磁盘（慢速）

对 AOF 文件的写入和 C++ 中对文件内容的写入思想都是一样的，每次直接写入到文件中（位于磁盘）是很耗时的，所以一般是先写入到一个缓冲区，然后通过某种策略将缓冲区的内容刷新到文件（磁盘）。

Redis 提供了 3 种 AOF 日志写回硬盘的策略，分别是：

- Always，这个单词的意思是「总是」，所以它的意思是每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；
- Everysec，这个单词的意思是「每秒」，所以它的意思是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘，这个刷新操作是异步执行的；
- No，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。

这三种策略只是在控制 `fsync()` 函数（将缓冲区中的内容刷新到磁盘）的调用时机。

当应用程序向文件写入数据时，内核通常先将数据复制到内核缓冲区中，然后排入队列，然后由内核决定何时写入硬盘。

如果想要应用程序向文件写入数据后，能立马将数据同步到硬盘，就可以调用 fsync() 函数，这样内核就会将内核缓冲区的数据直接写入到硬盘，等到硬盘写操作完成后，该函数才会返回。

- Always 策略就是每次写入 AOF 文件数据后，就执行 fsync() 函数；
- Everysec 策略就会创建一个异步任务来执行 fsync() 函数；
- No 策略就是永不执行 fsync() 函数;

> 分别说说这三种策略，在持久化大 Key 的时候，会影响什么？

在使用 Always 策略的时候，主线程在执行完命令后，会把数据写入到 AOF 日志文件，然后会调用  fsync() 函数，将内核缓冲区的数据直接写入到硬盘，等到硬盘写操作完成后，该函数才会返回。

**当使用 Always 策略的时候，如果写入是一个大 Key，主线程在执行 fsync() 函数的时候，阻塞的时间会比较久，因为当写入的数据量很大的时候，数据同步到硬盘这个过程是很耗时的**。

当使用 Everysec 策略的时候，由于是 **异步** 执行 fsync() 函数，所以大 Key 持久化的过程（数据同步磁盘）不会影响主线程。

当使用 No 策略的时候，由于永不执行 fsync() 函数，所以大 Key 持久化的过程不会影响主线程。

#### 4.2 大 key 对 RDB 快照的影响

当 AOF 日志写入了很多的大 Key，AOF 日志文件的大小会很大，那么很快就会触发 **AOF 重写机制**。

AOF 重写机制和 RDB 快照（bgsave 命令）的过程，都会分别通过 `fork()` 函数创建一个子进程来处理任务。

在创建子进程的过程中，操作系统会把父进程的「页表」复制一份给子进程，这个页表记录着虚拟地址和物理地址映射关系，而不会复制物理内存，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。

这样一来，子进程就共享了父进程的物理内存数据了，这样能够节约物理内存资源，页表对应的页表项的属性会标记该物理内存的权限为**只读**。

随着 Redis 存在越来越多的大 Key，那么 Redis 就会占用很多内存，对应的页表就会越大。

在通过  `fork()` 函数创建子进程的时候，虽然不会复制父进程的物理内存，但是**内核会把父进程的页表复制一份给子进程，如果页表很大，那么这个复制过程是会很耗时的，那么在执行 fork 函数的时候就会发生阻塞现象**。

而且，fork 函数是由 Redis 主线程调用的，如果 fork 函数发生阻塞，那么意味着就会阻塞 Redis 主线程。由于 Redis 执行命令是在主线程处理的，所以当 Redis 主线程发生阻塞，就无法处理后续客户端发来的命令。

我们可以执行 `info `命令获取到 latest_fork_usec 指标，表示 Redis 最近一次 fork 操作耗时。

```
# 最近一次 fork 操作耗时
latest_fork_usec:315
```

如果 fork 耗时很大，比如超过1秒，则需要做出优化调整：

- 单个实例的内存占用控制在 10 GB 以下，这样 fork 函数就能很快返回。
- 如果 Redis 只是当作纯缓存使用，不关心 Redis 数据安全性问题，可以考虑关闭 AOF 和 AOF 重写，这样就不会调用 fork 函数了。
- 在主从架构中，要适当调大 repl-backlog-size，避免因为  repl_backlog_buffer 不够大，导致主节点频繁地使用全量同步的方式，全量同步的时候，是会创建 RDB 文件的，也就是会调用 fork 函数。

如果创建完子进程后，**父进程对共享内存中的大 Key 进行了修改，那么内核就会发生写时复制，会把物理内存复制一份，由于大 Key 占用的物理内存是比较大的，那么在复制物理内存这一过程中，也是比较耗时的，于是父进程（主线程）就会发生阻塞**。

所以，有两个阶段会导致阻塞父进程：

- 创建子进程的途中，由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长；
- 创建完子进程后，如果子进程或者父进程修改了共享数据，就会发生写时复制，这期间会拷贝物理内存，如果内存越大，自然阻塞的时间也越长；

这里额外提一下， 如果 **Linux 开启了内存大页，会影响 Redis 的性能的**。

Linux 内核从 2.6.38 开始支持内存大页机制，该机制支持 2MB 大小的内存页分配，而常规的内存页分配是按 4KB 的粒度来执行的。

如果采用了内存大页，那么即使客户端请求只修改 100B 的数据，在发生写时复制后，Redis 也需要拷贝 2MB 的大页。相反，如果是常规内存页机制，只用拷贝 4KB。

两者相比，你可以看到，每次写命令引起的**复制内存页单位放大了 512 倍，会拖慢写操作的执行时间，最终导致 Redis 性能变慢**。

那该怎么办呢？很简单，关闭内存大页（默认是关闭的）。

禁用方法如下：

```shell
echo never >  /sys/kernel/mm/transparent_hugepage/enabled
```

#### 4.3 为什么说复制页表是一个很耗时的操作

首先，如果 Redis 是 10GB，一个页表可以存储 4KB，那么一共需要 2.5M（2500000，2500w） 个页表，这个基数就很大了。

此外，每个 PTE（Page Table Entry） 都包含着重要的映射信息，例如物理页帧号、访问权限位（读/写/执行）、脏位、访问位等。当复制页表时，需要将这些大量的页表项从一个进程的页表结构复制到另一个进程的页表结构中，这会占用大量的内存并导致大量的内存复制操作。

如果页表大小为 4KB，那么每个页表项包含 12bit 的数据，复制 2.5M 个页表项，就需要传输 12*2.5M/8B=3.75MB 的数据。如果每秒有 1000 次访问请求，那么每次就需要拷贝 3750MB 的数据，这些数据需要在内存中进行传输，会消耗大量的 CPU 时间和内存带宽。

#### 4.4 总结

当 AOF 写回策略配置了 Always 策略，如果写入是一个大 Key，主线程在执行 fsync() 函数的时候，阻塞的时间会比较久，因为当写入的数据量很大的时候，数据同步到硬盘这个过程是很耗时的。

AOF 重写机制和 RDB 快照（bgsave 命令）的过程，都会分别通过 `fork()` 函数创建一个子进程来处理任务。会有两个阶段会导致阻塞父进程（主线程）：

- 创建子进程的途中，由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长；
- 创建完子进程后，如果父进程修改了共享数据中的大 Key，就会发生写时复制，这期间会拷贝物理内存，由于大 Key 占用的物理内存会很大，那么在复制物理内存这一过程，就会比较耗时，所以有可能会阻塞父进程。

大 key 除了会影响持久化之外，还会有以下的影响。

- 客户端超时阻塞。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。
- 引发网络阻塞。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。
- 阻塞工作线程。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。
- 内存分布不均。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。

如何避免大 Key 呢？

最好在设计阶段，就把大 key 拆分成一个一个小 key。或者，定时检查 Redis 是否存在大 key ，如果该大 key 是可以删除的，不要使用 DEL 命令删除，因为该命令删除过程会阻塞主线程，而是用 unlink 命令（Redis 4.0+）删除大 key，因为该命令的删除过程是异步的，不会阻塞主线程。 

### 5. 如何删除大 key

删除操作的本质是要释放键值对占用的内存空间，不要小瞧内存的释放过程。

释放内存只是第一步，为了更加高效地管理内存空间，在应用程序释放内存时，操作系统需要把释放掉的内存块插入一个空闲内存块的链表，以便后续进行管理和再分配。这个过程本身需要一定时间，而且会阻塞当前释放内存的应用程序。

**所以，如果一下子释放了大量内存，空闲内存块链表操作时间就会增加，相应地就会造成 Redis 主线程的阻塞**，如果主线程发生了阻塞，其他所有请求可能都会超时，超时越来越多，会造成 Redis 连接耗尽，产生各种异常。

因此，删除大 key 这一个动作，我们要小心。具体要怎么做呢？这里给出两种方法：

- 分批次删除
- 异步删除（Redis 4.0版本以上）

#### 5.1 分批次删除

对于**删除大 Hash**，使用 `hscan` 命令，每次获取 100 个字段，再用 `hdel` 命令，每次删除 1 个字段。

Python代码：

```python
def del_large_hash():
  r = redis.StrictRedis(host='redis-host1', port=6379)
    large_hash_key ="xxx" #要删除的大hash键名
    cursor = '0'
    while cursor != 0:
        # 使用 hscan 命令，每次获取 100 个字段
        cursor, data = r.hscan(large_hash_key, cursor=cursor, count=100)
        for item in data.items():
                # 再用 hdel 命令，每次删除1个字段
                r.hdel(large_hash_key, item[0])
```

对于**删除大 List**，通过 `ltrim` 命令，每次删除少量元素。

Python代码：

```python
def del_large_list():
  r = redis.StrictRedis(host='redis-host1', port=6379)
  large_list_key = 'xxx'  #要删除的大list的键名
  while r.llen(large_list_key)>0:
      #每次只删除最右100个元素
      r.ltrim(large_list_key, 0, -101) 
```

对于**删除大 Set**，使用 `sscan` 命令，每次扫描集合中 100 个元素，再用 `srem` 命令每次删除一个键。

Python代码：

```python
def del_large_set():
  r = redis.StrictRedis(host='redis-host1', port=6379)
  large_set_key = 'xxx'   # 要删除的大set的键名
  cursor = '0'
  while cursor != 0:
    # 使用 sscan 命令，每次扫描集合中 100 个元素
    cursor, data = r.sscan(large_set_key, cursor=cursor, count=100)
    for item in data:
      # 再用 srem 命令每次删除一个键
      r.srem(large_size_key, item)
```

对于**删除大 ZSet**，使用 `zremrangebyrank` 命令，每次删除 top 100个元素。

Python代码：

```python
def del_large_sortedset():
  r = redis.StrictRedis(host='large_sortedset_key', port=6379)
  large_sortedset_key='xxx'
  while r.zcard(large_sortedset_key)>0:
    # 使用 zremrangebyrank 命令，每次删除 top 100个元素
    r.zremrangebyrank(large_sortedset_key,0,99) 
```

### **2、异步删除**

从 Redis 4.0 版本开始，可以采用**异步删除**法，**用 unlink 命令代替 del 来删除**。

这样 Redis 会将这个 key 放入到一个异步线程中进行删除，这样不会阻塞主线程。

## 十三、Redis 为什么使用跳表，而不用平衡树

为什么 Redis 的 ZSet 对象的底层数据结构之一是跳表而不是平衡树（如红黑树、AVL 树）？

对于这个问题，Redis的作者 @antirez 是怎么说的：

> There are a few reasons:
>
> 1. They are not very ***memory intensive***. It's up to you basically. Changing parameters about the probability of a node to have a given number of levels will make then less memory intensive than btrees.
> 2. A sorted set is often target of many ZRANGE or ZREVRANGE operations, that is, traversing the skip list as a linked list. With this operation the ***cache locality*** of skip lists is at least as good as with other kind of balanced trees.
> 3. They are ***simpler*** to implement, debug, and so forth. For instance thanks to the skip list simplicity I received a patch (already in Redis master) with augmented skip lists implementing ZRANK in O(log(N)). It required little changes to the code.

简单翻译一下，主要是从内存占用、对范围查找的支持、实现难易程度这三方面总结的原因：

- 它们不是非常内存密集型的。基本上由你决定。改变关于节点具有给定级别数的概率的参数将使其比 btree 占用更少的内存。
- Zset 经常需要执行 ZRANGE 或 ZREVRANGE 的命令，即作为链表遍历跳表。通过此操作，跳表的缓存局部性至少与其他类型的平衡树一样好。
- 它们更易于实现、调试等。例如，由于跳表的简单性，我收到了一个补丁（已经在Redis master中），其中扩展了跳表，在 O(log(N) 中实现了 ZRANK。它只需要对代码进行少量修改。

我再详细补充点：

- **从内存占用上来比较，跳表比平衡树更灵活一些**。平衡树每个节点包含 2 个指针（分别指向左右子树），而跳表每个节点包含的指针数目平均为 1/(1-p)，具体取决于参数 p 的大小。如果像 Redis里的实现一样，取 p=1/4，那么平均每个节点包含 1.33 个指针，比平衡树更有优势。
- **在做范围查找的时候，跳表比平衡树操作要简单**。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在跳表上进行范围查找就非常简单，只需要在找到小值之后，对第 1 层链表进行若干步的遍历就可以实现。
- **从算法实现难度上来比较，跳表比平衡树要简单得多**。平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而跳表的插入和删除只需要修改相邻节点的指针，操作简单又快速。

## 十四、Redis 底层数据结构

> reference:
>
> * [为了拿捏 Redis 数据结构，我画了 40 张图（完整版）](https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&mid=2247501112&idx=1&sn=e42b6c61c6747e2c2f3b890ab4e4b844&chksm=f98d8192cefa0884606c5284499d76eeb3966ac2d3de9fbc4a405448313dcf79eb41b7c9501e&scene=178&cur_album_id=1790401816640225283&search_click_id=#rd)
> * [Redis源码解析](https://tech.youzan.com/redisyuan-ma-jie-xi/)
> * [redis github](https://github.com/redis/redis/tree/unstable/src)

### 1. sds

Redis 虽然使用 C 语言实现，但是它没有直接使用 C 语言的 char* 数组来实现字符串，而是自己封装了一个 SDS（Simple Dynamic String）的数据结构表示字符串。

既然 Redis 设计了 SDS 结构来表示字符串，肯定是 C 语言的 char* 字符数组存在一些缺陷。

1. C 语言获取字符串长度的时间复杂度是 O(n)
2. C 字符串里面不能含有 '\0' 字符（ASCII 码为 0），这个限制使得 C 语言的字符串只能保存文本数据，而不能保存图片、音频、视频这样的二进制数据（因为二进制数据可能包含 0x00，即对应 '\0' 字符）
3. 字符串操作函数不搞笑且不安全，比如有缓冲区溢出的风险

Redis 实现的 SDS 的结构就把上面这些问题解决了，接下来我们一起看看 Redis 是如何解决的。

``` cpp
struct __attribute__ ((__packed__)) sdshdr5 {
    unsigned char flags; /* 3 lsb of type, and 5 msb of string length */
    char buf[];
};
struct __attribute__ ((__packed__)) sdshdr8 {
    uint8_t len; /* used */
    uint8_t alloc; /* excluding the header and null terminator */
    unsigned char flags; /* 3 lsb of type, 5 unused bits */
    char buf[];
};
struct __attribute__ ((__packed__)) sdshdr16 {
    uint16_t len; /* used */
    uint16_t alloc; /* excluding the header and null terminator */
    unsigned char flags; /* 3 lsb of type, 5 unused bits */
    char buf[];
};
struct __attribute__ ((__packed__)) sdshdr32 {
    uint32_t len; /* used */
    uint32_t alloc; /* excluding the header and null terminator */
    unsigned char flags; /* 3 lsb of type, 5 unused bits */
    char buf[];
};
struct __attribute__ ((__packed__)) sdshdr64 {
    uint64_t len; /* used */
    uint64_t alloc; /* excluding the header and null terminator */
    unsigned char flags; /* 3 lsb of type, 5 unused bits */
    char buf[];
};
```

结构中的每个成员变量分别介绍下：

- **len，记录了字符串长度**。这样获取字符串长度的时候，只需要返回这个成员变量值就行，时间复杂度只需要 O（1）。
- **alloc，分配给字符数组的空间长度**。这样在修改字符串的时候，可以通过 `alloc - len` 计算出剩余的空间大小，可以用来判断空间是否满足修改需求，如果不满足的话，就会自动将 SDS  的空间扩展至执行修改所需的大小，然后才执行实际的修改操作，所以使用 SDS 既不需要手动修改 SDS 的空间大小，也不会出现前面所说的缓冲区溢出的问题。
- **flags，用来表示不同类型的 SDS**。一共设计了 5 种类型，分别是 sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64，后面在说明区别之处。
- **buf[]，字符数组，用来保存实际数据**。不仅可以保存字符串，也可以保存二进制数据。

总的来说，Redis 的 SDS 结构在原本字符数组之上，增加了三个元数据：len、alloc、flags，用来解决 C 语言字符串的缺陷。

#### 1.1 二进制安全

因为 SDS 不需要用 “\0” 字符来标识字符串结尾了，而是**有个专门的 len 成员变量来记录长度，所以可存储包含 “\0” 的数据**。但是 SDS 为了兼容部分 C 语言标准库的函数， SDS 字符串结尾还是会加上 “\0” 字符。

因此， SDS 的 API 都是以处理二进制的方式来处理 SDS 存放在 buf[] 里的数据，程序不会对其中的数据做任何限制，数据写入的时候时什么样的，它被读取时就是什么样的。

通过使用二进制安全的 SDS，而不是 C 字符串，使得 Redis 不仅可以保存文本数据，也可以保存任意格式的二进制数据。

#### 1.2 不会发生缓冲区溢出

C 语言的字符串标准库提供的字符串操作函数，大多数（比如 strcat 追加字符串函数）都是不安全的，因为这些函数把缓冲区大小是否满足操作需求的工作交由开发者来保证，程序内部并不会判断缓冲区大小是否足够用，当发生了缓冲区溢出就有可能造成程序异常结束。

所以，Redis 的 SDS 结构里引入了 alloc 和 len 成员变量，这样 SDS API 通过 `alloc - len` 计算，可以算出剩余可用的空间大小，这样在对字符串做修改操作的时候，就可以由程序内部判断缓冲区大小是否足够用。

而且，**当判断出缓冲区大小不够用时，Redis 会自动将扩大 SDS 的空间大小（小于 1MB 翻倍扩容，大于 1MB 按 1MB 扩容）**，以满足修改所需的大小。

在扩展 SDS 空间之前，SDS API 会优先检查未使用空间是否足够，如果不够的话，API 不仅会为 SDS 分配修改所必须要的空间，还会给 SDS 分配额外的「未使用空间」。

这样的好处是，下次在操作 SDS 时，如果 SDS 空间够的话，API 就会直接使用「未使用空间」，而无须执行内存分配，**有效的减少内存分配次数**。

所以，使用 SDS 即不需要手动修改 SDS 的空间大小，也不会出现缓冲区溢出的问题。

#### 1.3 节省内存空间

SDS 结构中有个 flags 成员变量，表示的是 SDS 类型。

Redos 一共设计了 5 种类型，分别是 sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64。

这 5 种类型的主要**区别就在于，它们数据结构中的 len 和 alloc 成员变量的数据类型不同**。

比如 sdshdr16 和 sdshdr32 这两个类型，它们的定义分别如下：

``` cpp
struct __attribute__ ((__packed__)) sdshdr16 {
    uint16_t len; /* used */
    uint16_t alloc; /* excluding the header and null terminator */
    unsigned char flags; /* 3 lsb of type, 5 unused bits */
    char buf[];
};

struct __attribute__ ((__packed__)) sdshdr32 {
    uint32_t len; /* used */
    uint32_t alloc; /* excluding the header and null terminator */
    unsigned char flags; /* 3 lsb of type, 5 unused bits */
    char buf[];
};
```

可以看到：

- sdshdr16 类型的 len 和 alloc 的数据类型都是 uint16_t，表示字符数组长度和分配空间大小不能超过 2 的 16 次方。
- sdshdr32 则都是 uint32_t，表示表示字符数组长度和分配空间大小不能超过 2 的 32 次方。

**之所以 SDS 设计不同类型的结构体，是为了能灵活保存不同大小的字符串，从而有效节省内存空间**。比如，在保存小字符串时，结构头占用空间也比较少。

除了设计不同类型的结构体，Redis 在编程上还**使用了专门的编译优化来节省内存空间**，即在 struct 声明了 `__attribute__ ((packed))` ，它的作用是：**告诉编译器取消结构体在编译过程中的优化对齐，按照实际占用字节数进行对齐**。

比如，sdshdr16 类型的 SDS，默认情况下，编译器会按照 16 字节对齐的方式给变量分配内存，这意味着，即使一个变量的大小不到 16 个字节，编译器也会给它分配 16 个字节。

举个例子，假设下面这个结构体，它有两个成员变量，类型分别是 char 和 int，如下所示：

``` cpp
struct test1 {
    char a;
    int b;
 } test1;
```

由于对其的影响，struct test1 的大小是 8B。

如果不想编译器使用字节对齐的方式进行分配内存，可以采用了 `__attribute__ ((packed))` 属性定义结构体，这样一来，结构体实际占用多少内存空间，编译器就分配多少空间。

``` cpp
struct test1 { // 8
    char a;
    int b;
};

struct __attribute__((packed)) test2 { // 5
    char a;
    int b;
};
```

### 2. list

Redis 中的链表是 **双向链表**：

``` cpp
/* Node, List, and Iterator are the only data structures used currently. */

typedef struct listNode {
    struct listNode *prev;
    struct listNode *next;
    void *value;
} listNode;

typedef struct listIter {
    listNode *next;
    int direction;
} listIter;

typedef struct list {
    listNode *head;
    listNode *tail;
    void *(*dup)(void *ptr);
    void (*free)(void *ptr);
    int (*match)(void *ptr, void *key);
    unsigned long len;
} list;
```

Redis 在 listNode 结构体基础上又封装了 list 这个数据结构，提供了链表长度信息和自定义实现的 dup、free 和 match 函数。

Redis 的链表实现优点如下：

- listNode 链表节点的结构里带有 prev 和 next 指针，**获取某个节点的前置节点或后置节点的时间复杂度只需O(1)，而且这两个指针都可以指向 NULL，所以链表是无环链表**；
- list 结构因为提供了表头指针 head 和表尾节点 tail，所以**获取链表的表头节点和表尾节点的时间复杂度只需O(1)**；
- list 结构因为提供了链表节点数量 len，所以**获取链表中的节点数量的时间复杂度只需O(1)**；
- listNode 链表节使用 void* 指针保存节点值，并且可以通过 list 结构的 dup、free、match 函数指针为节点设置该节点类型特定的函数，因此**链表节点可以保存各种不同类型的值**；

链表的缺陷也是有的：

- 链表每个节点之间的内存都是不连续的，意味着**无法很好利用 CPU 缓存**。能很好利用 CPU 缓存的数据结构就是数组，因为数组的内存是连续的，这样就可以充分利用 CPU 缓存来加速访问。
- 还有一点，保存一个链表节点的值都需要一个链表节点结构头的分配，**内存开销较大**。

因此，Redis 3.0 的 List 对象在数据量比较少的情况下，会采用「压缩列表」作为底层数据结构的实现，它的优势是节省内存空间，并且是内存紧凑型的数据结构。

不过，压缩列表存在性能问题（具体什么问题，下面会说），所以 Redis 在 3.2 版本设计了新的数据结构 quicklist，并将 List 对象的底层数据结构改由 quicklist 实现。

然后在  Redis 5.0 设计了新的数据结构 listpack，沿用了压缩列表紧凑型的内存布局，最终在最新的 Redis 版本，将 Hash 对象和 Zset 对象的底层数据结构实现之一的压缩列表，替换成由  listpack 实现。

### 3. ziplist

压缩列表的最大特点，就是它被设计成一种内存紧凑型的数据结构，占用一块连续的内存空间，不仅可以利用 CPU 缓存，而且会针对不同长度的数据，进行相应编码，这种方法可以有效地节省内存开销。

但是，压缩列表的缺陷也是有的：

- 不能保存过多的元素，否则查询效率就会降低；
- 新增或修改某个元素时，压缩列表占用的内存空间需要重新分配，甚至可能引发 **连锁更新** 的问题。

因此，Redis 对象（List 对象、Hash 对象、Zset 对象）包含的元素数量较少，或者元素值不大的情况才会使用压缩列表作为底层数据结构。

压缩列表是 Redis 为了节约内存而开发的，它是**由连续内存块组成的顺序型数据结构**，有点类似于数组。

#### 3.1 数据结构设计

![ziplist_struct](https://github.com/QaQOwOQaQ/picx-images-hosting/raw/master/image.8adik4ncba.png)

压缩列表在表头有三个字段：

- ***zlbytes***，记录整个压缩列表占用对内存字节数；
- ***zltail***，记录压缩列表「尾部」节点距离起始地址由多少字节，也就是列表尾的偏移量；
- ***zllen***，记录压缩列表包含的节点数量；
- ***zlend***，标记压缩列表的结束点，固定值 0xFF（十进制255）。

在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是 O(1)。而查找其他元素时，就没有这么高效了，由于**压缩列表中每个 entry 的大小（长度）是不一致的**，只能逐个查找，此时的复杂度就是 O(N) 了，因此压缩列表不适合保存过多的元素。

因此，压缩列表节点（entry）的构成如下：

![ziplist_entry_struct](https://github.com/QaQOwOQaQ/picx-images-hosting/raw/master/image.8dx4hul0w0.png)

压缩列表节点包含三部分内容：

- ***prevlen***，记录了「前一个节点」的长度；
- ***encoding***，记录了当前节点实际数据的类型以及长度；
- ***data***，记录了当前节点的实际数据；

> 通过 prevlen 我们可以 **倒序遍历** 压缩列表，通过 encoding 中的长度信息我们可以 **正序遍历**。

当我们往压缩列表中插入数据时，压缩列表就会根据数据是字符串还是整数，以及数据的大小，会使用不同空间大小的 prevlen 和 encoding 这两个元素里保存的信息，**这种根据数据大小和类型进行不同的空间大小分配的设计思想，正是 Redis 为了节省内存而采用的**。

分别说下，prevlen 和 encoding 是如何根据数据的大小和类型来进行不同的空间大小分配。

压缩列表里的每个节点中的  prevlen 属性都记录了「前一个节点的长度」，而且 prevlen 属性的空间大小跟前一个节点长度值有关，比如：

- 如果**前一个节点的长度小于 254 字节**，那么 prevlen 属性需要用 **1 字节的空间**来保存这个长度值；
- 如果**前一个节点的长度大于等于 254 字节**，那么 prevlen 属性需要用 **5 字节的空间**来保存这个长度值；

encoding 属性的空间大小跟数据是字符串还是整数，以及字符串的长度有关：

- 如果**当前节点的数据是整数**，则 encoding 会使用 **1 字节的空间**进行编码。
- 如果**当前节点的数据是字符串，根据字符串的长度大小**，encoding 会使用 **1 字节/2字节/5字节的空间**进行编码。

#### 3.2 连锁更新

压缩列表除了查找复杂度高的问题，还有一个问题。

**压缩列表新增某个元素或修改某个元素时，如果空间不不够，压缩列表占用的内存空间就需要重新分配。而当新插入的元素较大时，可能会导致后续元素的 prevlen 占用空间都发生变化，从而引起「连锁更新」问题，导致每个元素的空间都要重新分配，造成访问压缩列表性能的下降**。

前面提到，压缩列表节点的 prevlen 属性会根据前一个节点的长度进行不同的空间大小分配：

- 如果前一个**节点的长度小于 254 字节**，那么 prevlen 属性需要用 **1 字节的空间**来保存这个长度值；
- 如果前一个**节点的长度大于等于 254 字节**，那么 prevlen 属性需要用 **5 字节的空间**来保存这个长度值；

现在假设一个压缩列表中有多个连续的、长度在 250～253 之间的节点，如下图：

![ziplist](https://github.com/QaQOwOQaQ/picx-images-hosting/raw/master/image.9gwtsqrx7x.png)

因为这些节点长度值小于 254 字节，所以 prevlen 属性需要用 1 字节的空间来保存这个长度值。

这时，如果将一个长度大于等于 254 字节的新节点加入到压缩列表的表头节点，即新节点将成为 e1 的前置节点，如下图：

![ziplist](https://github.com/QaQOwOQaQ/picx-images-hosting/raw/master/image.41ybabdh5a.png)

因为 e1 节点的 prevlen 属性只有 1 个字节大小，无法保存新节点的长度，此时就需要对压缩列表的空间重分配操作，并将 e1 节点的 prevlen 属性从原来的 1 字节大小扩展为 5 字节大小。

多米诺牌的效应就此开始。

![ziplist](https://github.com/QaQOwOQaQ/picx-images-hosting/raw/master/image.86twmfbni5.png)

e1 原本的长度在 250～253 之间，因为刚才的扩展空间，此时 e1 的长度就大于等于 254 了，因此原本 e2 保存 e1 的 prevlen 属性也必须从 1 字节扩展至 5 字节大小。

正如扩展 e1 引发了对 e2 扩展一样，扩展 e2 也会引发对 e3 的扩展，而扩展 e3 又会引发对 e4 的扩展…. 一直持续到结尾。

**这种在特殊情况下产生的连续多次空间扩展操作就叫做「连锁更新」**，就像多米诺牌的效应一样，第一张牌倒下了，推动了第二张牌倒下；第二张牌倒下，又推动了第三张牌倒下….，

空间扩展操作也就是重新分配内存，因此**连锁更新一旦发生，就会导致压缩列表占用的内存空间要多次重新分配，这就会直接影响到压缩列表的访问性能**。

所以说，**虽然压缩列表紧凑型的内存布局能节省内存开销，但是如果保存的元素数量增加了，或是元素变大了，会导致内存重新分配，最糟糕的是会有「连锁更新」的问题**。

因此，**压缩列表只会用于保存的节点数量不多的场景**，只要节点数量足够小，即使发生连锁更新，也是能接受的。

虽说如此，Redis 针对压缩列表在设计上的不足，在后来的版本中，新增设计了两种数据结构：quicklist（Redis 3.2 引入） 和 listpack（Redis 5.0 引入）。这两种数据结构的设计目标，就是尽可能地保持压缩列表节省内存的优势，同时解决压缩列表的「连锁更新」的问题。

### 4. dict

哈希表中的每一个 key 都是 **独一无二** 的。

**Redis 采用了「链式哈希」来解决哈希冲突**。

Redis 的哈希表结构如下：

``` cpp
struct dict {
    dictType *type;

    dictEntry **ht_table[2];
    unsigned long ht_used[2];

    long rehashidx; /* rehashing not in progress if rehashidx == -1 */

    /* Keep small vars at end for optimal (minimal) struct padding */
    unsigned pauserehash : 15; /* If >0 rehashing is paused */

    unsigned useStoredKeyApi : 1; /* See comment of storedHashFunction above */
    signed char ht_size_exp[2]; /* exponent of size. (size = 1<<exp) */
    int16_t pauseAutoResize;  /* If >0 automatic resizing is disallowed (<0 indicates coding error) */
    void *metadata[];
};
```

可以看到，哈希表是一个数组（`dictEntry **ht_table[2];`），数组的每个元素是一个指向「哈希表节点（dictEntry）」的指针。

哈希表节点的结构如下：

``` cpp
struct dictEntry {
    void *key;
    union {
        void *val;
        uint64_t u64;
        int64_t s64;
        double d;
    } v;
    struct dictEntry *next;     /* Next entry in the same hash bucket. */
};
```

dictEntry 结构里不仅包含指向键和值的指针，还包含了指向下一个哈希表节点的指针，这个指针可以将多个哈希值相同的键值对链接起来，以此来解决哈希冲突的问题，这就是链式哈希。

另外，这里还跟你提一下，dictEntry 结构里键值对中的值是一个「联合体 v」定义的，因此，键值对中的值可以是一个指向实际值的指针，或者是一个无符号的 64 位整数或有符号的 64 位整数或double 类的值。这么做的好处是可以节省内存空间，因为当「值」是整数或浮点数时，就可以将值的数据内嵌在 dictEntry 结构里，无需再用一个指针指向实际的值，从而节省了内存空间。

#### 4.1 rehash

注意到前面的 `struct dict`，里面保存了两个哈希表：`dictEntry **ht_table[2];`。

之所以定义了 2 个哈希表，是因为进行 rehash 的时候，需要用上 2 个哈希表了。

在正常服务请求阶段，插入的数据，都会写入到「哈希表 1」，此时的「哈希表 2 」 并没有被分配空间。

随着数据逐步增多，触发了 rehash 操作，这个过程分为三步：

- 给「哈希表 2」 分配空间，一般会比「哈希表 1」 大 2 倍；
- 将「哈希表 1 」的数据迁移到「哈希表 2」 中；
- 迁移完成后，「哈希表 1 」的空间会被释放，并把「哈希表 2」 设置为「哈希表 1」，然后在「哈希表 2」 新创建一个空白的哈希表，为下次 rehash 做准备。

这个过程看起来简单，但是其实第二步很有问题，**如果「哈希表 1 」的数据量非常大，那么在迁移至「哈希表 2 」的时候，因为会涉及大量的数据拷贝，此时可能会对 Redis 造成阻塞，无法服务其他请求**。

##### 渐进式 rehash

为了避免 rehash 在数据迁移过程中，因拷贝数据的耗时，影响 Redis 性能的情况，所以 Redis 采用了**渐进式 rehash**，也就是将数据的迁移的工作不再是一次性迁移完成，而是分多次迁移。

渐进式 rehash 步骤如下：

- 给「哈希表 2」 分配空间；
- **在 rehash 进行期间，每次哈希表元素进行新增、删除、查找或者更新操作时，Redis 除了会执行对应的操作之外，还会顺序将「哈希表 1 」中索引位置上的所有 key-value 迁移到「哈希表 2」 上**；
- 随着处理客户端发起的哈希表操作请求数量越多，最终在某个时间嗲呢，会把「哈希表 1 」的所有 key-value 迁移到「哈希表 2」，从而完成 rehash 操作。

这样就巧妙地把一次性大量数据迁移工作的开销，分摊到了多次处理请求的过程中，避免了一次性 rehash 的耗时操作。

在进行渐进式 rehash 的过程中，会有两个哈希表，所以在渐进式 rehash 进行期间，哈希表元素的删除、查找、更新等操作都会在这两个哈希表进行。

比如，查找一个 key 的值的话，先会在「哈希表 1」 里面进行查找，如果没找到，就会继续到哈希表 2 里面进行找到。

另外，在渐进式 rehash 进行期间，新增一个 key-value 时，会被保存到「哈希表 2 」里面，而「哈希表 1」 则不再进行任何添加操作，这样保证了「哈希表 1 」的 key-value 数量只会减少，随着 rehash 操作的完成，最终「哈希表 1 」就会变成空表。

> 简而言之，就是插入 `key=10，value=_value` 的数据时，会把哈希表 1 中 key=10 的哈希桶（链表）中的所有键值对全部迁移到哈希表 2 中，然后再将 `key=10，value=_value` 插入到哈希表2。
>
> 由于哈希表 1 的部分数据被迁移到了哈希表 2，因此查询的时候，需要先查询哈希表 1，再查询哈希表 2。

#### 4.2 rehash 触发条件

rehash 的触发条件跟**负载因子（load factor）**有关系。

负载因子可以通过下面这个公式计算：

* 负载因子 = 哈希表已保存节点数量 / 哈希表大小

触发 rehash 操作的条件，主要有两个：

- **当负载因子大于等于 1 ，并且 Redis 没有在执行 bgsave 命令或者 bgrewiteaof 命令，也就是没有执行 RDB 快照或没有进行 AOF 重写的时候，就会进行 rehash 操作。**
- **当负载因子大于等于 5 时，此时说明哈希冲突非常严重了，不管有没有有在执行 RDB 快照或 AOF 重写，都会强制进行 rehash 操作。**

### 5. intset

整数集合是  Set 对象的底层实现之一。当一个 Set 对象只包含整数值元素，并且元素数量不多时，就会使用整数集这个数据结构作为底层实现。

整数集合本质上是一块 **连续内存** 空间，它的结构定义如下：

``` cpp
typedef struct intset {
    uint32_t encoding;
    uint32_t length;
    int8_t contents[];
} intset;

/* Note that these encodings are ordered, so:
 * INTSET_ENC_INT16 < INTSET_ENC_INT32 < INTSET_ENC_INT64. */
#define INTSET_ENC_INT16 (sizeof(int16_t))
#define INTSET_ENC_INT32 (sizeof(int32_t))
#define INTSET_ENC_INT64 (sizeof(int64_t))
```

可以看到，保存元素的容器是一个 contents 数组，虽然 contents 被声明为 int8_t 类型的数组，但是实际上 contents 数组并不保存任何 int8_t 类型的元素，contents 数组的真正类型取决于 intset 结构体里的 encoding 属性的值。比如：

- 如果 encoding 属性值为 INTSET_ENC_INT16，那么 contents 就是一个 int16_t 类型的数组，数组中每一个元素的类型都是 int16_t；
- 如果 encoding 属性值为 INTSET_ENC_INT32，那么 contents 就是一个 int32_t 类型的数组，数组中每一个元素的类型都是 int32_t；
- 如果 encoding 属性值为 INTSET_ENC_INT64，那么 contents 就是一个 int64_t 类型的数组，数组中每一个元素的类型都是 int64_t；

不同类型的 contents 数组，意味着数组的大小也会不同。

#### 5.1 整数集合的升级操作

整数集合会有一个升级规则，就是当我们将一个新元素加入到整数集合里面，如果新元素的类型（int32_t）比整数集合现有所有元素的类型（int16_t）都要长时，整数集合需要先进行升级，也就是按新元素的类型（int32_t）扩展 contents 数组的空间大小，然后才能将新元素加入到整数集合里，当然升级的过程中，也要维持整数集合的有序性。

整数集合升级的过程不会重新分配一个新类型的数组，而是在原本的数组上扩展空间，然后在将每个元素按间隔类型大小分割，如果 encoding 属性值为 INTSET_ENC_INT16，则每个元素的间隔就是 16 位。

举个例子，假设有一个整数集合里有 3 个类型为 int16_t 的元素。

![intset_upgrade](https://github.com/QaQOwOQaQ/picx-images-hosting/raw/master/image.491j5s64c2.png)

现在，往这个整数集合中加入一个新元素 65535，这个新元素需要用 int32_t 类型来保存，所以整数集合要进行升级操作，首先需要为 contents 数组扩容，**在原本空间的大小之上再扩容多 80 位（4x32-3x16=80），这样就能保存下 4 个类型为 int32_t 的元素**。

![intset_upgrade](https://github.com/QaQOwOQaQ/picx-images-hosting/raw/master/image.6wqzg5009g.png)

扩容完 contents 数组空间大小后，需要将之前的三个元素转换为 int32_t 类型，并将转换后的元素放置到正确的位上面，并且需要维持底层数组的有序性不变，整个转换过程如下：

![intset_upgrade](https://github.com/QaQOwOQaQ/picx-images-hosting/raw/master/image.41ybacmlkh.png)

另外，需要注意的是，整数集合 **不支持降级操作**。

### 6. skiplist

Redis 只有在 Zset 对象的底层实现用到了跳表，跳表的优势是能支持平均 O(logN) 复杂度的节点查找。

Zset 对象是唯一一个同时使用了两个数据结构来实现的 Redis 对象，这两个数据结构一个是跳表，一个是哈希表。这样的好处是既能进行高效的 **范围查询**，也能进行高效 **单点查询**。

``` cpp
typedef struct zset {
    dict *dict;
    zskiplist *zsl;
} zset;
```

Zset 对象能支持范围查询（如 ZRANGEBYSCORE 操作），这是因为它的数据结构设计采用了跳表，而又能以常数复杂度获取元素权重（如 ZSCORE 操作），这是因为它同时采用了哈希表进行索引。

接下来，详细的说下跳表。

#### 6.1 跳表结构设计

```cpp
/* ZSETs use a specialized version of Skiplists */
typedef struct zskiplistNode {
    sds ele;         // zset 对象的元素值
    double score;    // 元素值权重
    struct zskiplistNode *backward; // 倒序遍历
    struct zskiplistLevel {
        struct zskiplistNode *forward;
        unsigned long span;
    } level[];
} zskiplistNode;

typedef struct zskiplist {
    struct zskiplistNode *header, *tail;
    unsigned long length;
    int level;
} zskiplist;
```

Zset 对象要同时保存元素和元素的权重，对应到跳表节点结构里就是 sds 类型的 ele 变量和 double 类型的 score 变量。每个跳表节点都有一个后向指针，指向前一个节点，目的是为了方便从跳表的尾节点开始访问节点，这样倒序查找时很方便。

跳表是一个带有层级关系的链表，而且每一层级可以包含多个节点，每一个节点通过指针连接起来，实现这一特性就是靠跳表节点结构体中的**zskiplistLevel 结构体类型的 level 数组**。

level 数组中的每一个元素代表跳表的一层，也就是由 zskiplistLevel 结构体表示，比如 leve[0] 就表示第一层，leve[1] 就表示第二层。zskiplistLevel 结构体里定义了「指向下一个跳表节点的指针」和「跨度」，跨度时用来记录两个节点之间的距离。

第一眼看到跨度的时候，以为是遍历操作有关，实际上并没有任何关系，遍历操作只需要用前向指针就可以完成了。

**跨度实际上是为了计算这个节点在跳表中的排位**。具体怎么做的呢？因为跳表中的节点都是按序排列的，那么计算某个节点排位的时候，从头节点点到该结点的查询路径上，将沿途访问过的所有层的跨度累加起来，得到的结果就是目标节点在跳表中的排位。

> 例如，在 zset 中以 score 作为标准排序，查找排序第 n 的值。

#### 6.2 跳表节点的层数设置

**跳表的相邻两层的节点数量最理想的比例是 2:1，查找复杂度可以降低到 $O(log_2^N)$**。

如果采用新增节点或者删除节点时，来调整跳表节点以维持比例的方法的话，会带来额外的开销。

Redis 则采用一种巧妙的方法是，**跳表在创建节点的时候，随机生成每个节点的层数**，并没有严格维持相邻两层的节点数量比例为 2 : 1 的情况。

具体的做法是，**跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数**。

这样的做法，相当于每增加一层的概率不超过 25%，层数越高，概率越低，层高最大限制是 64。

> 具体的数学推导过程就太难了。

### 7. quicklist

在 Redis 3.0 之前，List 对象的底层数据结构是双向链表或者压缩列表。然后在  Redis 3.2 的时候，List 对象的底层改由 quicklist 数据结构实现。

其实 quicklist 就是「双向链表 + 压缩列表」组合，因为 **一个 quicklist 就是一个链表，而链表中的每个元素又是一个压缩列表。**

在前面讲压缩列表的时候，我也提到了压缩列表的不足，虽然压缩列表是通过紧凑型的内存布局节省了内存开销，但是因为它的结构设计，如果保存的元素数量增加，或者元素变大了，压缩列表会有「连锁更新」的风险，一旦发生，会造成性能下降。

quicklist 解决办法，**通过控制每个链表节点中的压缩列表的大小或者元素个数，来规避连锁更新的问题。因为压缩列表元素越少或越小，连锁更新带来的影响就越小，从而提供了更好的访问性能。**

#### 7.1 quicklist 结构设计

quicklist 的结构体跟链表的结构体类似，都包含了表头和表尾，区别在于 quicklist 的节点是 quicklistNode。

``` cpp
/* quicklist is a 40 byte struct (on 64-bit systems) describing a quicklist.
 * 'count' is the number of total entries.
 * 'len' is the number of quicklist nodes.
 * 'compress' is: 0 if compression disabled, otherwise it's the number
 *                of quicklistNodes to leave uncompressed at ends of quicklist.
 * 'fill' is the user-requested (or default) fill factor.
 * 'bookmarks are an optional feature that is used by realloc this struct,
 *      so that they don't consume memory when not used. */
typedef struct quicklist {
    quicklistNode *head;
    quicklistNode *tail;
    unsigned long count;        /* total count of all entries in all listpacks */
    unsigned long len;          /* number of quicklistNodes */
    signed int fill : QL_FILL_BITS;       /* fill factor for individual nodes */
    unsigned int compress : QL_COMP_BITS; /* depth of end nodes not to compress;0=off */
    unsigned int bookmark_count: QL_BM_BITS;
    quicklistBookmark bookmarks[];
} quicklist;
```

接下来看看，quicklistNode 的结构定义：

``` cpp
/* quicklistNode is a 32 byte struct describing a listpack for a quicklist.
 * We use bit fields keep the quicklistNode at 32 bytes.
 * count: 16 bits, max 65536 (max lp bytes is 65k, so max count actually < 32k).
 * encoding: 2 bits, RAW=1, LZF=2.
 * container: 2 bits, PLAIN=1 (a single item as char array), PACKED=2 (listpack with multiple items).
 * recompress: 1 bit, bool, true if node is temporary decompressed for usage.
 * attempted_compress: 1 bit, boolean, used for verifying during testing.
 * dont_compress: 1 bit, boolean, used for preventing compression of entry.
 * extra: 9 bits, free for future use; pads out the remainder of 32 bits */
typedef struct quicklistNode {
    struct quicklistNode *prev;
    struct quicklistNode *next;
    unsigned char *entry;
    size_t sz;             /* entry size in bytes */
    unsigned int count : 16;     /* count of items in listpack */
    unsigned int encoding : 2;   /* RAW==1 or LZF==2 */
    unsigned int container : 2;  /* PLAIN==1 or PACKED==2 */
    unsigned int recompress : 1; /* was this node previous compressed? */
    unsigned int attempted_compress : 1; /* node can't compress; too small */
    unsigned int dont_compress : 1; /* prevent compression of entry that will be used later */
    unsigned int extra : 9; /* more bits to steal for future usage */
} quicklistNode;
```

可以看到，quicklistNode 结构体里包含了前一个节点和下一个节点指针，这样每个 quicklistNode 形成了一个双向链表。但是链表节点的元素不再是单纯保存元素值，而是保存了一个压缩列表，所以 quicklistNode 结构体里有个指向压缩列表的指针 *entry。

在向 quicklist 添加一个元素的时候，不会像普通的链表那样，直接新建一个链表节点。而是会检查插入位置的压缩列表是否能容纳该元素，如果能容纳就直接保存到 quicklistNode 结构里的压缩列表，如果不能容纳，才会新建一个新的 quicklistNode 结构。

quicklist 会控制 quicklistNode 结构里的压缩列表的大小或者元素个数，来规避潜在的连锁更新的风险，但是 **这并没有完全解决连锁更新的问题**。

### 8. listpack

quicklist 虽然通过控制 quicklistNode 结构里的压缩列表的大小或者元素个数，来减少连锁更新带来的性能影响，但是并没有完全解决连锁更新的问题。

因为 quicklistNode 还是用了压缩列表来保存元素，压缩列表连锁更新的问题，来源于它的结构设计，所以要想彻底解决这个问题，需要设计一个新的数据结构。

于是，Redis 在 5.0 新设计一个数据结构叫 listpack，目的是替代压缩列表，它最大特点是 **listpack 中每个节点不再包含前一个节点的长度了**，压缩列表每个节点正因为需要保存前一个节点的长度字段，就会有连锁更新的隐患。

#### 8.1 listpack 结构设计

listpack 采用了压缩列表的很多优秀的设计，比如还是用一块 **连续的内存空间** 来紧凑地保存数据，并且为了节省内存的开销，listpack 节点会采用不同的编码方式保存不同大小的数据。

我们先看看 listpack 结构：

![listpack](https://github.com/QaQOwOQaQ/picx-images-hosting/raw/master/image.58hmizuhyt.png)

listpack 头包含两个属性，分别记录了 listpack 总字节数和元素数量，然后 listpack 末尾也有个结尾标识。图中的 listpack entry 就是 listpack 的节点了。

每个 listpack 节点结构如下：

![listpack_entry](https://github.com/QaQOwOQaQ/picx-images-hosting/raw/master/image.1sfaqwln4i.png)

主要包含三个方面内容：

- encoding，定义该元素的编码类型，会对不同长度的整数和字符串进行编码；
- data，实际存放的数据；
- len，encoding+data的总长度；

可以看到，listpack 没有压缩列表中记录前一个节点长度的字段了，listpack 只记录当前节点的长度，当我们向 listpack 加入一个新元素的时候，不会影响其他节点的长度字段的变化，从而避免了压缩列表的连锁更新问题。

### 补充1：数据结构与数据类型

首先我们要区分开来，我们所谈到的 **数据类型** 和 **底层数据结构** 的区别，在 C++ 中，int 和 set 都是数据类型，其中，set 的底层标准实现是红黑树，当我们也可以用其他平衡树，只要满足 set 的语义。这里所谈到的 set 就是数据类型，红黑树或其它平衡树就是数据结构，数据类型的底层是通过某种数据结构实现的。数据类型代表了某种语义，例如 int 表示整数以及与整数有关的操作，map 则表示字典以及相关操作，而这些操作的实现依赖于底层的数据结构。

同样的，Redis 的 **数据类型**，也叫 **Redis 对象**，和 C++ 的 int、set 一样，都是数据的保存形式（语义），这些对象的语义实现依赖于底层数据结构。

![redis data struct](https://github.com/QaQOwOQaQ/picx-images-hosting/raw/master/image.9dd7uvyfc2.png)

### 补充2：RedisObject

下面是  Redis 保存键值对所涉及的数据结构：

![redis_data_base_struct](https://github.com/QaQOwOQaQ/picx-images-hosting/raw/master/image.6bhbtpq39m.png)

- redisDb 结构，表示 Redis 数据库的结构，结构体里存放了指向了 dict 结构的指针；
- dict 结构，结构体里存放了 2 个哈希表，正常情况下都是用「哈希表1」，「哈希表2」只有在 rehash 的时候才用；
- ditctht 结构，表示哈希表的结构，结构里存放了哈希表数组，数组中的每个元素都是指向一个哈希表节点结构（dictEntry）的指针；
- dictEntry 结构，表示哈希表节点的结构，结构里存放了 **void \* key 和 void \* value 指针， \*key 指向的是 String 对象，而 \*value 则可以指向 String 对象，也可以指向集合类型的对象，比如 List 对象、Hash 对象、Set 对象和 Zset 对象**。

特别说明下，void * key 和 void * value 指针指向的是 **Redis 对象**，Redis 中的每个对象都由 redisObject 结构表示，如下图：

![redisObject](https://github.com/QaQOwOQaQ/picx-images-hosting/raw/master/image.5q7o7ex5cb.png)

对象结构里包含的成员变量：

- type，标识该对象是什么类型的对象（String 对象、 List 对象、Hash 对象、Set 对象和 Zset 对象）；
- encoding，标识该对象使用了哪种底层的数据结构；
- **ptr，指向底层数据结构的指针**。

因此，更具体的 Redis 键值对数据库的全景图应该是：

![redis_cv_overall](https://github.com/QaQOwOQaQ/picx-images-hosting/raw/master/image.2yylzcct5f.png)

## 十五、Redis 数据类型和应用场景

> reference:
>
> * [2 万字 + 20张图｜ 细说 Redis 九种数据类型和应用场景](https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&mid=2247514054&idx=2&sn=ad92fe82c3d468b97501b84d7b2f8d39&chksm=f98df36ccefa7a7ae8c22fcca7f8d5b857463fb48708b2ae90ba1856271a0bae91c975687f92&scene=178&cur_album_id=1790401816640225283&search_click_id=#rd)

### 0. redisObject

在 Redis 的内部实现中，`redisObject` 是一个非常核心的数据结构。它不仅仅代表了用户在 Redis 中存储的“值”（例如字符串、列表、哈希等），更是一个封装了类型、编码、LRU 信息和引用计数等元数据的通用对象。所有的 Redis 键值对中的“值”以及一些内部数据结构（比如有序集合的成员）都是以 `redisObject` 的形式存在的。

``` cpp
typedef struct redisObject {
    unsigned type:4;     // 4 bits: 对象类型，如 OBJ_STRING, OBJ_LIST 等
    unsigned encoding:4; // 4 bits: 对象编码，如 OBJ_ENCODING_RAW, OBJ_ENCODING_ZIPLIST 等
    unsigned lru:24;     // 24 bits: LRU 时间（或 LFU 计数），用于内存淘汰策略
    int refcount;        // 引用计数，用于内存回收
    void *ptr;           // 指向实际数据结构的指针
} robj;
```

**`type` (4 bits)**:

- 这个字段表示 `redisObject` 所存储的 **高层数据类型**。它决定了应用程序如何解释和操作这个对象。
- 可能的类型常量包括：
  - `OBJ_STRING` (字符串)
  - `OBJ_LIST` (列表)
  - `OBJ_HASH` (哈希)
  - `OBJ_SET` (集合)
  - `OBJ_ZSET` (有序集合)
  - `OBJ_STREAM` (流，Redis 5.0 引入)
  - `OBJ_MODULE` (模块类型，Redis 4.0 引入)

**`encoding` (4 bits)**:

- 这个字段表示 `redisObject` 内部实际使用的 **底层数据结构（编码方式）**。Redis 会根据存储的数据量、类型和操作模式动态地选择不同的编码方式，以优化内存使用和操作效率。
- 不同的 `type` 可以有不同的 `encoding`。
- 一些常见的编码常量包括：
  - 对于 `OBJ_STRING`:
    - `OBJ_ENCODING_RAW`: 普通动态字符串 (SDS)。
    - `OBJ_ENCODING_EMBSTR`: 嵌入式动态字符串 (SDS)，当字符串较短时，SDS 数据直接嵌入在 `redisObject` 结构中，减少内存分配次数和碎片。
    - `OBJ_ENCODING_INT`: 整数，当字符串表示一个整数时，直接存储为 `long long` 类型，更节省内存。
  - 对于 `OBJ_LIST`:
    - `OBJ_ENCODING_QUICKLIST`: Quicklist (Redis 3.2+ 的默认编码)。
    - `OBJ_ENCODING_ZIPLIST`: 压缩列表 (旧版本或某些特定条件下的编码)。
    - `OBJ_ENCODING_LINKEDLIST`: 双向链表 (旧版本或某些特定条件下的编码)。
  - 对于 `OBJ_HASH`:
    - `OBJ_ENCODING_ZIPLIST`: 压缩列表 (当键值对数量和长度较小时)。
    - `OBJ_ENCODING_HT`: 哈希表。
  - 对于 `OBJ_SET`:
    - `OBJ_ENCODING_INTSET`: 整数集合 (当所有成员都是整数且数量较小时)。
    - `OBJ_ENCODING_HT`: 哈希表。
  - 对于 `OBJ_ZSET`:
    - `OBJ_ENCODING_ZIPLIST`: 压缩列表 (当成员数量和长度较小时)。
    - `OBJ_ENCODING_SKIPLIST`: 跳跃表 (与哈希表结合)。

**`lru` (24 bits)**:

- 这个字段用于实现 **LRU (Least Recently Used) 内存淘汰策略**。它存储了对象最后一次被访问的时间（更准确地说，是一个时钟计数器）。
- 在 Redis 4.0 之后，这个字段也可以被配置为存储 **LFU (Least Frequently Used) 计数**，用于 LFU 淘汰策略。
- 当 Redis 内存不足时，会根据这个字段来选择要淘汰的对象。

**`refcount` (int)**:

- **引用计数**。这是一个非常重要的字段，用于内存管理。
- 当一个 `redisObject` 被多个地方引用时（例如，某些字符串常量被多个键共享），引用计数会增加。
- 当一个引用被移除时（例如，键被删除），引用计数会减少。
- 当引用计数降到 0 时，说明这个对象不再被任何地方使用，Redis 会自动释放其占用的内存。
- 引用计数机制有助于避免重复存储相同的、不常变化的对象（如“hello world”这样的字符串常量）。

**`ptr` (void \*)**:

- **指向实际数据结构的指针**。这个指针指向了真正存储数据内容的底层数据结构。
- 例如，如果 `type` 是 `OBJ_STRING` 且 `encoding` 是 `OBJ_ENCODING_RAW`，那么 `ptr` 会指向一个 `sds` (Simple Dynamic String) 结构体。
- 如果 `type` 是 `OBJ_LIST` 且 `encoding` 是 `OBJ_ENCODING_QUICKLIST`，那么 `ptr` 会指向一个 `quicklist` 结构体。

### 1. String

String 是最基本的 key-value 结构，key 是唯一标识，value 是具体的值，value其实不仅是字符串， 也可以是数字（整数或浮点数），value 最多可以容纳的数据长度是 `512M`。

![String](https://github.com/QaQOwOQaQ/picx-images-hosting/raw/master/image.7p3uxynnco.png)

#### 1.1 内部实现

String 类型的底层的数据结构实现主要是 int 和 SDS（简单动态字符串）。

字符串对象的内部编码（encoding）有 3 种 ：**int、raw和 embstr**。

![string](https://github.com/QaQOwOQaQ/picx-images-hosting/raw/master/image.2yylzkan9p.png)

如果一个字符串对象保存的是整数值，并且这个整数值可以用`long`类型来表示，那么字符串对象会将整数值保存在字符串对象结构的`ptr`属性里面（将`void*`转换成 long），并将字符串对象的编码设置为`int`。

![string](https://github.com/QaQOwOQaQ/picx-images-hosting/raw/master/image.45hx8602nf.png)

如果字符串对象保存的是一个字符串，并且这个字符申的长度小于等于 32 字节，那么字符串对象将使用一个简单动态字符串（SDS）来保存这个字符串，并将对象的编码设置为`embstr`， `embstr`编码是专门用于保存短字符串的一种优化编码方式：

![string](https://github.com/QaQOwOQaQ/picx-images-hosting/raw/master/image.1ziime90ai.png)

如果字符串对象保存的是一个字符串，并且这个字符串的长度大于 32 字节，那么字符串对象将使用一个简单动态字符串（SDS）来保存这个字符串，并将对象的编码设置为`raw`：

![string](https://github.com/QaQOwOQaQ/picx-images-hosting/raw/master/image.4g4r1bfzvu.png)

可以看到`embstr`和`raw`编码都会使用`SDS`来保存值，但不同之处在于`embstr`会通过一次内存分配函数来分配一块连续的内存空间来保存`redisObject`和`SDS`，而`raw`编码会通过调用两次内存分配函数来分别分配两块空间来保存`redisObject`和`SDS`。Redis这样做会有很多好处：

- `embstr`编码将创建字符串对象所需的内存分配次数从 `raw` 编码的两次降低为一次；
- 释放 `embstr`编码的字符串对象同样只需要调用一次内存释放函数；
- 因为`embstr`编码的字符串对象的所有数据都保存在一块连续的内存里面可以更好的利用 CPU 缓存提升性能。

但是 embstr 也有缺点的：

- 如果字符串的长度增加需要重新分配内存时，整个 redisObject 和 sds 都需要重新分配空间，所以**embstr编码的字符串对象实际上是只读的**，redis没有为embstr编码的字符串对象编写任何相应的修改程序。当我们对embstr编码的字符串对象执行任何修改命令（例如append）时，程序会先将对象的编码从embstr转换成raw，然后再执行修改命令。

#### 1.2 常用指令

普通字符串的基本操作：

```shell
# 设置 key-value 类型的值
> SET name lin
OK
# 根据 key 获得对应的 value
> GET name
"lin"
# 判断某个 key 是否存在
> EXISTS name
(integer) 1
# 返回 key 所储存的字符串值的长度
> STRLEN name
(integer) 3
# 删除某个 key 对应的值
> DEL name
(integer) 1
```

批量设置 :

```shell
# 批量设置 key-value 类型的值
> MSET key1 value1 key2 value2 
OK
# 批量获取多个 key 对应的 value
> MGET key1 key2 
1) "value1"
2) "value2"
```

计数器（字符串的内容为整数的时候可以使用）：

```shell
# 设置 key-value 类型的值
> SET number 0
OK
# 将 key 中储存的数字值增一
> INCR number
(integer) 1
# 将key中存储的数字值加 10
> INCRBY number 10
(integer) 11
# 将 key 中储存的数字值减一
> DECR number
(integer) 10
# 将key中存储的数字值键 10
> DECRBY number 10
(integer) 0
```

过期（默认为永不过期）：

```shell
# 设置 key 在 60 秒后过期（该方法是针对已经存在的key设置过期时间）
> EXPIRE name  60 
(integer) 1
# 查看数据还有多久过期
> TTL name 
(integer) 51

#设置 key-value 类型的值，并设置该key的过期时间为 60 秒
> SET key  value EX 60
OK
> SETEX key  60 value
OK
```

不存在就插入：

```shell
# 不存在就插入（not exists）
>SETNX key value
(integer) 1
```

#### 1.3 应用场景

#### 缓存对象

使用 String 来缓存对象有两种方式：

- 直接缓存整个对象的 JSON，命令例子：`SET user:1 '{"name":"xiaolin", "age":18}'`。
- 采用将 key 进行分离为 user:ID:属性，采用 MSET 存储，用 MGET 获取各属性值，命令例子：`MSET user:1:name xiaolin user:1:age 18 user:2:name xiaomei user:2:age 20`。

#### 常规计数

因为 Redis **处理命令是单线程**，所以 **执行命令的过程是原子的**。因此 String 数据类型适合计数场景，比如计算访问次数、点赞、转发、库存数量等等。

比如计算文章的阅读量：

```shell
# 初始化文章的阅读量
> SET aritcle:readcount:1001 0
OK
#阅读量+1
> INCR aritcle:readcount:1001
(integer) 1
#阅读量+1
> INCR aritcle:readcount:1001
(integer) 2
#阅读量+1
> INCR aritcle:readcount:1001
(integer) 3
# 获取对应文章的阅读量
> GET aritcle:readcount:1001
"3"
```

#### 分布式锁

SET 命令有个 NX 参数可以实现「key不存在才插入」，可以用它来实现分布式锁：

- 如果 key 不存在，则显示插入成功，可以用来表示加锁成功；
- 如果 key 存在，则会显示插入失败，可以用来表示加锁失败。

一般而言，还会对分布式锁加上过期时间，分布式锁的命令如下：

```shell
SET lock_key unique_value NX PX 10000
```

- lock_key 就是 key 键；
- unique_value 是客户端生成的唯一的标识；
- NX 代表只在 lock_key 不存在时，才对 lock_key 进行设置操作；
- PX 10000 表示设置 lock_key 的过期时间为 10s，这是为了避免客户端发生异常而无法释放锁。

而解锁的过程就是将 lock_key 键删除，但不能乱删，要保证执行操作的客户端就是加锁的客户端。所以，解锁的时候，我们要先判断锁的 unique_value 是否为加锁客户端，是的话，才将 lock_key 键删除。

可以看到，解锁是有两个操作，这时就需要 Lua 脚本来保证解锁的原子性，因为 Redis 在执行 Lua 脚本时，可以以原子性的方式执行，保证了锁释放操作的原子性。

```cpp
// 释放锁时，先比较 unique_value 是否相等，避免锁的误释放
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
```

这样一来，就通过使用 SET 命令和 Lua 脚本在 Redis 单节点上完成了分布式锁的加锁和解锁。

### 2. List

List 列表是简单的 **字符串列表**，**按照插入顺序排序**，可以从头部或尾部向 List 列表添加元素。

列表的最大长度为 `2^32 - 1`，也即每个列表支持超过 `40 亿`个元素。

#### 2.1 内部实现

List 类型的底层数据结构是由**双向链表或压缩列表**实现的：

- 如果列表的元素个数小于 `512` 个（默认值，可由 `list-max-ziplist-entries` 配置），列表每个元素的值都小于 `64` 字节（默认值，可由 `list-max-ziplist-value` 配置），Redis 会使用**压缩列表**作为 List 类型的底层数据结构；
- 如果列表的元素不满足上面的条件，Redis 会使用**双向链表**作为 List 类型的底层数据结构；

但是**在 Redis 3.2 版本之后，List 数据类型底层数据结构就只由 quicklist 实现了，替代了双向链表和压缩列表**。

#### 2.2 常用命令

``` shell
# 将一个或多个值value插入到key列表的表头(最左边)，最后的值在最前面
LPUSH key value [value ...] 
# 将一个或多个值value插入到key列表的表尾(最右边)
RPUSH key value [value ...]
# 移除并返回key列表的头元素
LPOP key     
# 移除并返回key列表的尾元素
RPOP key 

# 返回列表key中指定区间内的元素，区间以偏移量start和stop指定，从0开始
# -1 表示末尾
LRANGE key start stop

# 从key列表表头弹出一个元素，没有就阻塞timeout秒，如果timeout=0则一直阻塞
BLPOP key [key ...] timeout
# 从key列表表尾弹出一个元素，没有就阻塞timeout秒，如果timeout=0则一直阻塞
BRPOP key [key ...] timeout
```

#### 2.3 应用场景

##### 消息队列

消息队列在存取消息时，必须要满足三个需求，分别是**消息保序、处理重复的消息和保证消息可靠性**。

Redis 的 List 和 Stream 两种数据类型，就可以满足消息队列的这三个需求。我们先来了解下基于 List 的消息队列实现方法，后面在介绍 Stream 数据类型时候，在详细说说 Stream。

*1、如何满足消息保序需求？*

List 本身就是按先进先出的顺序对数据进行存取的，所以，如果使用 List 作为消息队列保存消息的话，就已经能满足消息保序的需求了。

List 可以使用 LPUSH + RPOP （或者反过来，RPUSH+LPOP）命令实现消息队列。

- 生产者使用 `LPUSH key value[value...]` 将消息插入到队列的头部，如果 key 不存在则会创建一个空的队列再插入消息。
- 消费者使用 `RPOP key` 依次读取队列的消息，先进先出。

不过，在消费者读取数据时，有一个潜在的性能风险点。

在生产者往 List 中写入数据时，List 并不会主动地通知消费者有新消息写入，如果消费者想要及时处理消息，就需要在程序中不停地调用 `RPOP` 命令（比如使用一个while(1)循环）。如果有新消息写入，RPOP命令就会返回结果，否则，RPOP命令返回空值，再继续循环。

所以，即使没有新消息写入List，消费者也要不停地调用 RPOP 命令，这就会导致消费者程序的 CPU 一直消耗在执行 RPOP 命令上，带来不必要的性能损失。

为了解决这个问题，Redis提供了 BRPOP 命令。**BRPOP命令也称为阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列，再开始读取新数据**。和消费者程序自己不停地调用RPOP命令相比，这种方式能节省CPU开销。

*2、如何处理重复的消息？*

消费者要实现重复消息的判断，需要 2 个方面的要求：

- 每个消息都有一个全局的 ID。
- 消费者要记录已经处理过的消息的 ID。当收到一条消息后，消费者程序就可以对比收到的消息 ID 和记录的已处理过的消息 ID，来判断当前收到的消息有没有经过处理。如果已经处理过，那么，消费者程序就不再进行处理了。

但是 **List 并不会为每个消息生成 ID 号，所以我们需要自行为每个消息生成一个全局唯一ID**，生成之后，我们在用 LPUSH 命令把消息插入 List 时，需要在消息中包含这个全局唯一 ID。

例如，我们执行以下命令，就把一条全局 ID 为 111000102、库存量为 99 的消息插入了消息队列：

```
> LPUSH mq "111000102:stock:99"
(integer) 1
```

> 在消息队列（Message Queue）中，**处理重复消息**是一个非常重要的需求，这通常是因为 **消息队列系统在分布式环境下，为了保证高可用性和数据不丢失，可能会出现消息的重复投递。**
>
> ### 为什么会出现重复消息？
>
> 主要有以下几个原因：
>
> 1. **生产者重试机制：**
>    - **网络抖动或瞬时故障：** 生产者发送消息到消息队列时，如果网络出现短暂延迟或消息队列服务瞬时不可用，生产者可能没有及时收到消息发送成功的确认（ACK）。
>    - **超时机制：** 生产者为了避免无限等待，会设置一个超时时间。如果在这个时间内没有收到确认，它会认为消息发送失败，从而进行**重试**。即使第一次发送实际上已经成功了，重试也会导致消息被再次发送到队列中。
> 2. **消费者重试机制：**
>    - **处理失败：** 消费者从消息队列中拉取消息后，在处理消息的过程中可能会遇到各种错误，例如：数据库写入失败、第三方服务调用失败、代码逻辑异常等。
>    - **未及时确认：** 为了保证消息不丢失，消息队列通常会要求消费者在成功处理消息后发送一个确认（ACK）。如果消费者在处理完消息后，但在发送 ACK 之前崩溃了，或者 ACK 在发送过程中丢失了，消息队列会认为这条消息没有被成功处理，从而在稍后**再次投递**给其他消费者或同一个消费者。
> 3. **消息队列本身的机制：**
>    - **集群模式下的数据同步：** 在高可用的消息队列集群中，为了保证消息的持久性和一致性，消息可能需要在多个节点之间同步。如果某个节点在同步完成前发生故障并恢复，可能会导致消息重复。
>    - **网络分区：** 在分布式系统中，网络分区可能导致生产者认为消息未送达而重试，或者消费者确认消息的 ACK 未送达而导致消息重投。
>
> ### 为什么需要处理重复消息？
>
> 如果不处理重复消息，可能会导致以下问题：
>
> 1. **业务数据不一致：**
>    - **重复下单：** 用户提交订单后，如果消息重复，可能导致生成多份订单。
>    - **重复扣款：** 支付系统收到重复的扣款消息，可能导致用户的账户被多次扣费。
>    - **重复发货：** 物流系统收到重复的发货指令，可能导致同一商品被多次发出。
>    - **数据统计错误：** 统计系统收到重复的日志或事件，可能导致统计数据偏高。
> 2. **资源浪费：**
>    - 重复执行业务逻辑会占用不必要的计算资源、存储资源和网络带宽。
>    - 例如，重复发送邮件或短信会增加成本。
> 3. **系统复杂性增加：**
>    - 没有幂等性保证的系统，在面对重复消息时需要额外的处理来回滚或修正错误，增加了系统设计的复杂性。
>
> ### 如何处理重复消息？（幂等性）
>
> 为了解决重复消息带来的问题，核心思想是实现**幂等性（Idempotence）**。幂等性是指一个操作，不论执行多少次，其结果都是相同的。
>
> 常见的实现方法包括：
>
> - **唯一消息 ID 机制：** 为每条消息生成一个全局唯一的 ID。消费者在处理消息时，先检查这个 ID 是否已经被处理过。如果已经处理，则直接忽略。这通常需要一个持久化的存储（如数据库、Redis）来记录已处理的消息 ID。
> - **数据库唯一约束：** 如果消息的处理结果是向数据库写入数据，可以利用数据库的唯一索引或主键约束来防止重复写入。
> - **状态机：** 对于有状态的业务流程，可以通过维护状态机来确保操作的幂等性。例如，一个订单只有在“待支付”状态才能执行“支付”操作。
> - **乐观锁/版本号：** 在更新操作中，可以通过比较版本号或时间戳来确保只有第一次操作生效。
>
> 理解消息重复投递的原因以及如何通过幂等性来处理它们，是设计健壮和可靠的分布式消息系统的关键。

*3、如何保证消息可靠性？*

当消费者程序从 List 中读取一条消息后，List 就不会再留存这条消息了。所以，如果消费者程序在处理消息的过程出现了故障或宕机，就会导致消息没有处理完成，那么，消费者程序再次启动后，就没法再次从 List 中读取消息了。

为了留存消息，List 类型提供了 `BRPOPLPUSH` 命令，这个命令的**作用是让消费者程序从一个 List 中读取消息，同时，Redis 会把这个消息再插入到另一个 List（可以叫作备份 List）留存**。

这样一来，如果消费者程序读了消息但没能正常处理，等它重启后，就可以从备份 List 中重新读取消息并进行处理了。

好了，到这里可以知道基于 List 类型的消息队列，满足消息队列的三大需求（消息保序、处理重复的消息和保证消息可靠性）。

- 消息保序：使用 LPUSH + RPOP；
- 阻塞读取：使用 BRPOP；
- 重复消息处理：生产者自行实现全局唯一 ID；
- 消息的可靠性：使用 BRPOPLPUSH

但是，**在用 List 做消息队列时，如果生产者消息发送很快，而消费者处理消息的速度比较慢，这就导致 List 中的消息越积越多，给 Redis 的内存带来很大压力**。

要解决这个问题，就要**启动多个消费者程序组成一个消费组，一起分担处理 List 中的消息**。但是，**List 类型并不支持消费组的实现**。

这就要说起 Redis 从 5.0 版本开始提供的 Stream 数据类型了，Stream 同样能够满足消息队列的三大需求，而且它还支持「消费组」形式的消息读取。

### 3. Hash

Hash 是一个键值对（key - value）集合，其中 value 的形式入：`value=[{field1，value1}，...{fieldN，valueN}]`。Hash 特别适合用于存储对象。

#### 3.1 底层实现

Hash 类型的底层数据结构是由**压缩列表或哈希表**实现的：

- 如果哈希类型元素个数小于 `512` 个（默认值，可由 `hash-max-ziplist-entries` 配置），所有值小于 `64` 字节（默认值，可由 `hash-max-ziplist-value` 配置）的话，Redis 会使用**压缩列表**作为 Hash 类型的底层数据结构；
- 如果哈希类型元素不满足上面条件，Redis 会使用**哈希表**作为 Hash 类型的 底层数据结构。

**在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了**。

#### 3.2 常用命令

``` shell
# 存储一个哈希表key的键值
HSET key field value   
# 获取哈希表key对应的field键值
HGET key field

# 在一个哈希表key中存储多个键值对
HMSET key field value [field value...] 
# 批量获取哈希表key中多个field键值
HMGET key field [field ...]       
# 删除哈希表key中的field键值
HDEL key field [field ...]    

# 返回哈希表key中field的数量
HLEN key       
# 返回哈希表key中所有的键值
HGETALL key 

# 为哈希表key中field键的值加上增量n
HINCRBY key field n                         
```

#### 3.3 应用场景

##### 缓存对象

Hash 类型的 **（key，field， value）** 的结构与对象的（对象id， 属性， 值）的结构相似，也可以用来存储对象。

我们以用户信息为例，它在关系型数据库中的结构是这样的：

| uid  | name  | age  |
| ---- | ----- | ---- |
| 1    | Alice | 18   |
| 2    | Bob   | 22   |

我们可以使用如下命令，将用户对象的信息存储到 Hash 类型：

```shell
# 存储一个哈希表uid:1的键值
> HSET uid:1 name Tom age 15
2
# 存储一个哈希表uid:2的键值
> HSET uid:2 name Jerry age 13
2
# 获取哈希表用户id为1中所有的键值
> HGETALL uid:1
1) "name"
2) "Tom"
3) "age"
4) "15"
```

在介绍 String 类型的应用场景时有所介绍，String + Json也是存储对象的一种方式，那么存储对象时，到底用 String + json 还是用 Hash 呢？

一般对象用 String + Json 存储，对象中某些频繁变化的属性可以考虑抽出来用 Hash 类型存储。

##### 购物车

以用户 id 为 key，商品 id 为 field，商品数量为 value，恰好构成了购物车的3个要素，如下图所示。

![shooping car](https://github.com/QaQOwOQaQ/picx-images-hosting/raw/master/image.175n4sff9z.png)

涉及的命令如下：

- 添加商品：`HSET cart:{用户id} {商品id} 1`
- 添加数量：`HINCRBY cart:{用户id} {商品id} 1`
- 商品总数：`HLEN cart:{用户id}`
- 删除商品：`HDEL cart:{用户id} {商品id}`
- 获取购物车所有商品：`HGETALL cart:{用户id}`

当前仅仅是将商品ID存储到了Redis 中，在回显商品具体信息的时候，还需要拿着商品 id 查询一次数据库，获取完整的商品的信息。

### 4. Set

#### 4.1 内部实现

Set 类型的底层数据结构是由**哈希表或整数集合**实现的：

- 如果集合中的元素都是整数且元素个数小于 `512` （默认值，`set-maxintset-entries`配置）个，Redis 会使用**整数集合**作为 Set 类型的底层数据结构；
- 如果集合中的元素不满足上面条件，则 Redis 使用**哈希表**作为 Set 类型的底层数据结构。

#### 4.2 常用命令

Set常用操作：

```shell
# 往集合key中存入元素，元素存在则忽略，若key不存在则新建
SADD key member [member ...]
# 从集合key中删除元素
SREM key member [member ...] 
# 获取集合key中所有元素
SMEMBERS key
# 获取集合key中的元素个数
SCARD key

# 判断member元素是否存在于集合key中
SISMEMBER key member

# 从集合key中随机选出count个元素，元素不从key中删除
SRANDMEMBER key [count]
# 从集合key中随机选出count个元素，元素从key中删除
SPOP key [count]
```

Set运算操作：

```shell
# 交集运算
SINTER key [key ...]
# 将交集结果存入新集合destination中
SINTERSTORE destination key [key ...]

# 并集运算
SUNION key [key ...]
# 将并集结果存入新集合destination中
SUNIONSTORE destination key [key ...]

# 差集运算
SDIFF key [key ...]
# 将差集结果存入新集合destination中
SDIFFSTORE destination key [key ...]
```

#### **4.3 应用场景**

集合的主要几个特性，**无序**、**不可重复**、**支持并交差** 等操作。

因此 Set 类型比较适合用来数据去重和保障数据的唯一性，还可以用来统计多个集合的交集、错集和并集等，当我们存储的数据是无序并且需要去重的情况下，比较适合使用集合类型进行存储。

但是要提醒你一下，这里有一个潜在的风险。**Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致 Redis 实例阻塞**。

在主从集群中，为了避免主库因为 Set 做聚合计算（交集、差集、并集）时导致主库被阻塞，我们可以选择一个从库完成聚合统计，或者把数据返回给客户端，由客户端来完成聚合统计。

##### 点赞

Set 类型可以保证一个用户只能点一个赞，这里举例子一个场景，key 是文章id，value 是用户id。

`uid:1` 、`uid:2`、`uid:3`  三个用户分别对 article:1 文章点赞了。

```shell
# uid:1 用户对文章 article:1 点赞
> SADD article:1 uid:1
(integer) 1
# uid:2 用户对文章 article:1 点赞
> SADD article:1 uid:2
(integer) 1
# uid:3 用户对文章 article:1 点赞
> SADD article:1 uid:3
(integer) 1
```

`uid:1` 取消了对 article:1 文章点赞。

```shell
> SREM article:1 uid:1
(integer) 1
```

获取  article:1 文章所有点赞用户 :

```shell
> SMEMBERS article:1
1) "uid:3"
2) "uid:2"
```

获取 article:1 文章的点赞用户数量：

```shell
> SCARD article:1
(integer) 2
```

判断用户 `uid:1` 是否对文章 article:1 点赞了：

```shell
> SISMEMBER article:1 uid:1
(integer) 0  # 返回0说明没点赞，返回1则说明点赞了
```

 ##### 共同关注

Set 类型支持交集运算，所以可以用来计算共同关注的好友、公众号等。

key 可以是用户id，value 则是已关注的公众号的id。

`uid:1` 用户关注公众号 id 为 5、6、7、8、9，`uid:2` 用户关注公众号 id 为 7、8、9、10、11。

```shell
# uid:1 用户关注公众号 id 为 5、6、7、8、9
> SADD uid:1 5 6 7 8 9
(integer) 5
# uid:2  用户关注公众号 id 为 7、8、9、10、11
> SADD uid:2 7 8 9 10 11
(integer) 5
```

`uid:1` 和 `uid:2` 共同关注的公众号：

```shell
# 获取共同关注
> SINTER uid:1 uid:2
1) "7"
2) "8"
3) "9"
```

给  `uid:2`  推荐 `uid:1` 关注的公众号：

```shell
> SDIFF uid:1 uid:2
1) "5"
2) "6"
```

验证某个公众号是否同时被  `uid:1`  或  `uid:2`  关注:

```shell
> SISMEMBER uid:1 5
(integer) 1 # 返回0，说明关注了
> SISMEMBER uid:2 5
(integer) 0 # 返回0，说明没关注
```

##### 抽奖活动

存储某活动中中奖的用户名 ，Set 类型因为有去重功能，可以保证同一个用户不会中奖两次。

key为抽奖活动名，value为员工名称，把所有员工名称放入抽奖箱 ：

```shell
>SADD lucky Tom Jerry John Sean Marry Lindy Sary Mark
(integer) 5
```

如果允许重复中奖，可以使用 SRANDMEMBER 命令。

```shell
# 抽取 1 个一等奖：
> SRANDMEMBER lucky 1
1) "Tom"
# 抽取 2 个二等奖：
> SRANDMEMBER lucky 2
1) "Mark"
2) "Jerry"
# 抽取 3 个三等奖：
> SRANDMEMBER lucky 3
1) "Sary"
2) "Tom"
3) "Jerry"
```

如果不允许重复中奖，可以使用 SPOP 命令。

```shell
# 抽取一等奖1个
> SPOP lucky 1
1) "Sary"
# 抽取二等奖2个
> SPOP lucky 2
1) "Jerry"
2) "Mark"
# 抽取三等奖3个
> SPOP lucky 3
1) "John"
2) "Sean"
3) "Lindy"
```

### 5. ZSet

如果说 Set 是 unordered_set，那么 ZSet 就是 set，只不过这里 ZSet 额外使用一个字段 score 来作为排序的依据。

#### 5.1 内部实现

ZSet 底层会使用 **哈希表** 来实现 O(1) 时间复杂度内的单点查询，对于范围查询，Zset 类型的底层数据结构是由 **压缩列表或跳表** 实现的：

- 如果有序集合的元素个数小于 `128` 个，并且每个元素的值小于 `64` 字节时，Redis 会使用**压缩列表**作为 Zset 类型的底层数据结构；
- 如果有序集合的元素不满足上面的条件，Redis 会使用**跳表**作为 Zset 类型的底层数据结构；

**在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。**

#### 5.2 **常用命令**

```shell
# 往有序集合key中加入带分值元素
ZADD key score member [[score member]...]   
# 往有序集合key中删除元素
ZREM key member [member...]                 
# 返回有序集合key中元素member的分值
ZSCORE key member
# 返回有序集合key中元素个数
ZCARD key 

# 为有序集合key中元素member的分值加上increment
ZINCRBY key increment member 

# 正序获取有序集合key从start下标到stop下标的元素
ZRANGE key start stop [WITHSCORES]
# 倒序获取有序集合key从start下标到stop下标的元素
ZREVRANGE key start stop [WITHSCORES]

# 返回有序集合中指定分数区间内的成员，分数由低到高排序。
ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]

# 返回指定成员区间内的成员，按字典正序排列, 分数必须相同。
# 主要用于在分数（score）相同的情况下，对成员进行字典序排序和范围查询。
ZRANGEBYLEX key min max [LIMIT offset count]
# 返回指定成员区间内的成员，按字典倒序排列, 分数必须相同
ZREVRANGEBYLEX key max min [LIMIT offset count]
```

Zset 运算操作（相比于 Set 类型，ZSet 类型没有支持差集运算）：

```shell
# 并集计算(相同元素分值相加)，numberkeys一共多少个key，WEIGHTS每个key对应的分值乘积，如果未指定，默认为 1
ZUNIONSTORE destkey numberkeys key [key...] 
# 交集计算(相同元素分值相加)，numberkeys一共多少个key，WEIGHTS每个key对应的分值乘积
ZINTERSTORE destkey numberkeys key [key...]
```

#### 5.3 **应用场景**

Zset 类型（Sorted Set，有序集合） 可以根据元素的权重来排序，我们可以自己来决定每个元素的权重值。比如说，我们可以根据元素插入 Sorted Set 的时间确定权重值，先插入的元素权重小，后插入的元素权重大。

在面对需要展示最新列表、排行榜等场景时，如果数据更新频繁或者需要分页显示，可以优先考虑使用 Sorted Set。

##### 排行榜

有序集合比较典型的使用场景就是排行榜。例如学生成绩的排名榜、游戏积分排行榜、视频播放排名、电商系统中商品的销量排名等。

我们以博文点赞排名为例，小林发表了五篇博文，分别获得赞为 200、40、100、50、150。

```shell
# arcticle:1 文章获得了200个赞
> ZADD user:xiaolin:ranking 200 arcticle:1
(integer) 1
# arcticle:2 文章获得了40个赞
> ZADD user:xiaolin:ranking 40 arcticle:2
(integer) 1
# arcticle:3 文章获得了100个赞
> ZADD user:xiaolin:ranking 100 arcticle:3
(integer) 1
# arcticle:4 文章获得了50个赞
> ZADD user:xiaolin:ranking 50 arcticle:4
(integer) 1
# arcticle:5 文章获得了150个赞
> ZADD user:xiaolin:ranking 150 arcticle:5
(integer) 1
```

文章 arcticle:4 新增一个赞，可以使用 ZINCRBY 命令（为有序集合key中元素member的分值加上increment）：

```shell
> ZINCRBY user:xiaolin:ranking 1 arcticle:4
"51"
```

查看某篇文章的赞数，可以使用 ZSCORE 命令（返回有序集合key中元素个数）：

```shell
> ZSCORE user:xiaolin:ranking arcticle:4
"50"
```

获取小林文章赞数最多的 3 篇文章，可以使用 ZREVRANGE 命令（倒序获取有序集合 key 从start下标到stop下标的元素）：

```shell
# WITHSCORES 表示把 score 也显示出来
> ZREVRANGE user:xiaolin:ranking 0 2 WITHSCORES
1) "arcticle:1"
2) "200"
3) "arcticle:5"
4) "150"
5) "arcticle:3"
6) "100"
```

获取小林 100 赞到 200 赞的文章，可以使用 ZRANGEBYSCORE 命令（返回有序集合中指定分数区间内的成员，分数由低到高排序）：

```shell
> ZRANGEBYSCORE user:xiaolin:ranking 100 200 WITHSCORES
1) "arcticle:3"
2) "100"
3) "arcticle:5"
4) "150"
5) "arcticle:1"
6) "200"
```

##### 电话、姓名排序

使用有序集合的 `ZRANGEBYLEX` 或 `ZREVRANGEBYLEX` 可以帮助我们实现电话号码或姓名的排序，我们以 `ZRANGEBYLEX` （返回指定成员区间内的成员，按 key 正序排列，分数必须相同）为例。

**注意：不要在分数不一致的 SortSet 集合中去使用 ZRANGEBYLEX和 ZREVRANGEBYLEX 指令，因为获取的结果会不准确。**

*1、电话排序*

我们可以将电话号码存储到 SortSet 中，然后根据需要来获取号段：

```shell
> ZADD phone 0 13100111100 0 13110114300 0 13132110901 
(integer) 3
> ZADD phone 0 13200111100 0 13210414300 0 13252110901 
(integer) 3
> ZADD phone 0 13300111100 0 13310414300 0 13352110901 
(integer) 3
```

获取所有号码:

```shell
> ZRANGEBYLEX phone - +
1) "13100111100"
2) "13110114300"
3) "13132110901"
4) "13200111100"
5) "13210414300"
6) "13252110901"
7) "13300111100"
8) "13310414300"
9) "13352110901"
```

获取 132 号段的号码：

```shell
> ZRANGEBYLEX phone [132 (133
1) "13200111100"
2) "13210414300"
3) "13252110901"
```

获取132、133号段的号码：

```shell
> ZRANGEBYLEX phone [132 (134
1) "13200111100"
2) "13210414300"
3) "13252110901"
4) "13300111100"
5) "13310414300"
6) "13352110901"
```

*2、姓名排序*

```shell
> zadd names 0 Toumas 0 Jake 0 Bluetuo 0 Gaodeng 0 Aimini 0 Aidehua 
(integer) 6
```

获取所有人的名字:

```shell
> ZRANGEBYLEX names - +
1) "Aidehua"
2) "Aimini"
3) "Bluetuo"
4) "Gaodeng"
5) "Jake"
6) "Toumas"
```

获取名字中大写字母A开头的所有人：

```shell
> ZRANGEBYLEX names [A (B
1) "Aidehua"
2) "Aimini"
```

获取名字中大写字母 C 到 Z 的所有人：

```shell
> ZRANGEBYLEX names [C [Z
1) "Gaodeng"
2) "Jake"
3) "Toumas"
```

### 6. BitMap

Bitmap，即位图，是一串连续的二进制数组（0和1），可以通过偏移量（offset）定位元素。BitMap通过最小的单位bit来进行`0|1`的设置，表示某个元素的值或者状态，时间复杂度为O(1)。

由于 bit 是计算机中最小的单位，使用它进行储存将非常节省空间，特别适合一些数据量大且使用**二值统计的场景**。

![bitmap](https://github.com/QaQOwOQaQ/picx-images-hosting/raw/master/image.7axf79pivl.png)

#### 6.1 内部实现

Bitmap 本身是 **用 String 类型作为底层数据结构** 实现的一种统计二值状态的数据类型。

String 类型是会保存为二进制的字节数组，所以，Redis 就把字节数组的每个 bit 位利用起来，用来表示一个元素的二值状态，你可以把 Bitmap 看作是一个 bit 数组。

#### 6.2 常用命令

bitmap 基本操作：

```shell
# 设置值，其中value只能是 0 和 1
SETBIT key offset value

# 获取值
GETBIT key offset

# 获取指定范围内值为 1 的个数
# start 和 end 以字节为单位
BITCOUNT key start end
```

bitmap 运算操作：

```shell
# BitMap间的运算
# operations 位移操作符，枚举值
  AND 与运算 &
  OR 或运算 |
  XOR 异或 ^
  NOT 取反 ~
# result 计算的结果，会存储在该key中
# key1 … keyn 参与运算的key，可以有多个，空格分割，not运算只能一个key
# 当 BITOP 处理不同长度的字符串时，较短的那个字符串所缺少的部分会被看作 0。返回值是保存到 destkey 的字符串的长度（以字节byte为单位），和输入 key 中最长的字符串长度相等。
BITOP [operations] [result] [key1] [keyn…]

# 返回指定key中第一次出现指定value(0/1)的位置
BITPOS [key] [value]
```

#### 6.3 应用

##### 签到统计

在签到打卡的场景中，我们只用记录签到（1）或未签到（0），所以它就是非常典型的二值状态。

签到统计时，每个用户一天的签到用 1 个 bit 位就能表示，一个月（假设是 31 天）的签到情况用 31 个 bit 位就可以，而一年的签到也只需要用 365 个 bit 位，根本不用太复杂的集合类型。

假设我们要统计 ID 100 的用户在 2022 年 6 月份的签到情况，就可以按照下面的步骤进行操作。

第一步，执行下面的命令，记录该用户 6 月 3 号已签到。

```
SETBIT uid:sign:100:202206 2 1
```

第二步，检查该用户 6 月 3 日是否签到。

```
GETBIT uid:sign:100:202206 2 
```

第三步，统计该用户在 6 月份的签到次数。

```
BITCOUNT uid:sign:100:202206
```

这样，我们就知道该用户在 6 月份的签到情况了。

> 如何统计这个月首次打卡时间呢？

Redis 提供了 `BITPOS key bitValue [start] [end]`指令，返回数据表示 Bitmap 中第一个值为 `bitValue` 的 offset 位置。

在默认情况下， 命令将检测整个位图， 用户可以通过可选的 `start` 参数和 `end` 参数指定要检测的范围。所以我们可以通过执行这条命令来获取 userID = 100 在 2022 年 6 月份**首次打卡**日期：

```
BITPOS uid:sign:100:202206 1
```

需要注意的是，因为 offset 从 0 开始的，所以我们需要将返回的 value + 1 。

##### 判断用户登陆态

Bitmap 提供了 `GETBIT、SETBIT` 操作，通过一个偏移值 offset 对 bit 数组的 offset 位置的 bit 位进行读写操作，需要注意的是 **offset 从 0 开始**。

只需要一个 key = login_status 表示存储用户登陆状态集合数据， 将用户 ID 作为 offset，在线就设置为 1，下线设置 0。通过 `GETBIT`判断对应的用户是否在线。50000 万 用户只需要 6 MB 的空间。

假如我们要判断 ID = 10086 的用户的登陆情况：

第一步，执行以下指令，表示用户已登录。

```
SETBIT login_status 10086 1
```

第二步，检查该用户是否登陆，返回值 1 表示已登录。

```
GETBIT login_status 10086
```

第三步，登出，将 offset 对应的 value 设置成 0。

```
SETBIT login_status 10086 0
```

#### 连续签到用户总数

如何统计出这连续 7 天连续打卡用户总数呢？

我们把每天的日期作为 Bitmap 的 key，userId 作为 offset，若是打卡则将 offset 位置的 bit 设置成 1。

key 对应的集合的每个 bit 位的数据则是一个用户在该日期的打卡记录。

一共有 7 个这样的 Bitmap，如果我们能对这 7 个 Bitmap 的对应的 bit 位做 『与』运算。同样的 UserID offset 都是一样的，当一个 userID 在 7 个 Bitmap 对应对应的 offset 位置的 bit = 1 就说明该用户 7 天连续打卡。

结果保存到一个新 Bitmap 中，我们再通过 `BITCOUNT` 统计 bit = 1 的个数便得到了连续打卡 3 天的用户总数了。

Redis 提供了 `BITOP operation destkey key [key ...]`这个指令用于对一个或者多个 key 的 Bitmap 进行位元操作。

- `opration` 可以是 `and`、`OR`、`NOT`、`XOR`。当 BITOP 处理不同长度的字符串时，较短的那个字符串所缺少的部分会被看作 `0` 。空的 `key` 也被看作是包含 `0` 的字符串序列。

举个例子，比如将三个 bitmap 进行 AND 操作，并将结果保存到 destmap 中，接着对 destmap 执行 BITCOUNT 统计。

```
# 与操作
BITOP AND destmap bitmap:01 bitmap:02 bitmap:03
# 统计 bit 位 =  1 的个数
BITCOUNT destmap
```

即使一天产生一个亿的数据，Bitmap 占用的内存也不大，大约占 12 MB 的内存（10^8/8/1024/1024），7 天的 Bitmap 的内存开销约为 84 MB。同时我们最好给 Bitmap 设置过期时间，让 Redis 删除过期的打卡数据，节省内存。

### 7. HyperLogLog

Redis HyperLogLog 是 Redis 2.8.9 版本新增的数据类型，是一种用于「统计基数」的数据集合类型，基数统计就是指 **统计一个集合中不重复的元素个数**。但要注意，HyperLogLog 是统计规则是基于概率完成的，不是非常准确，标准误算率是 0.81%。

所以，简单来说 HyperLogLog **提供不精确的去重计数**。

HyperLogLog 的特点：

1. **极低的内存占用：** 无论你要统计的独立元素数量有多大（从几百万到几十亿），一个 HyperLogLog 键的内存占用都是**固定且非常小**的，通常只有 `12KB` 左右。
2. **可接受的误差：** 作为一种估算算法，HyperLogLog 并不是 100% 精确的，它存在一个**标准错误率**。Redis 实现的 HyperLogLog 的标准错误率大约是 **0.81%**。这意味着，如果你估算的结果是 1,000,000，那么实际值可能在 991,900 到 1,008,100 之间。
3. **不能获取具体元素：** HyperLogLog 只能估算基数，你**无法从 HyperLogLog 中获取原始的独立元素列表**。
4. **增量操作：** 它可以增量地添加元素，并且支持多个 HyperLogLog 的合并。

#### 7.1 内部实现

HyperLogLog 算法基于概率计数，其核心思想是利用伯努利试验（Bernoulli Trials）和哈希函数。

当一个元素被添加到 HyperLogLog 中时：

1. 该元素首先被一个高分布性的哈希函数进行哈希处理，生成一个很长的二进制串。
2. 算法会观察这个哈希值二进制串中**最右边（或最左边）连续零的个数**（或者更复杂一点，是第一个非零位的位置）。
3. 根据概率论，哈希值末尾连续零的个数越多，说明这个元素被哈希到这个特定模式的概率越低，从而推断出集合中可能存在的独立元素越多。
4. HyperLogLog 内部维护着一个由多个“桶”（registers）组成的数组，每个桶记录它所观察到的最大连续零的个数。最终通过这些桶的统计信息，利用复杂的数学公式来估算出基数。

因为存储的不是实际元素，而是少量统计数据，所以内存占用极低。

#### 7.2 常见命令

HyperLogLog 命令很少，就三个。

```shell
# 添加指定元素到 HyperLogLog 中
PFADD key element [element ...]

# 返回给定 HyperLogLog 的基数估算值。
PFCOUNT key [key ...]

# 将多个 HyperLogLog 合并为一个 HyperLogLog
PFMERGE destkey sourcekey [sourcekey ...]
```

> **PF** 是 **HyperLogLog** 命令的前缀，它来源于 HyperLogLog 算法的发明者：**P**hillipe **F**lajolet。

#### 7.3 命名逻辑

HyperLogLog 的命名逻辑是基于其算法的演进和其关键特性，可以分解为以下几点：

1. **LogLog 算法：**
   - HyperLogLog 算法的前身是 **LogLog 算法**，由 Durand 和 Flajolet 于 2003 年提出。
   - "LogLog" 的命名由来：这个名字可能来源于算法所需的内存空间大小。LogLog 算法的内存复杂度非常低，通常是 log(logN) 级别，其中 N 是要估算的基数（独立元素数量）的最大值。
     - 例如，如果我们需要估算高达几十亿（109）的基数，那么 log2(109)≈30，而 log2(log2(109))≈log2(30)≈4.9。这意味着只需要非常少的比特位来存储每个桶（register）的信息，从而整体内存占用极低。这种“对数的对数”级别的内存效率是其命名的一个重要灵感来源。
   - LogLog 算法的核心思想是观察哈希值中**最长前导零（或最右边连续零）的长度**，并根据概率推断基数。
2. **HyperLogLog 的出现：**
   - HyperLogLog 是对 LogLog 算法的改进，由 Flajolet 等人于 2007 年提出。
   - **"Hyper" 的含义**：这个前缀表示 **"超级"** 或 **"超越"**。它强调了 HyperLogLog 在准确性上的显著提升。LogLog 算法虽然内存效率高，但在低基数估算时误差较大，且估计结果可能存在偏差。HyperLogLog 通过引入**调和平均数（Harmonic Mean）**来替代 LogLog 的几何平均数，并结合其他优化（例如稀疏表示和稠密表示的转换、偏置校正等），大大提高了估算的精度，同时保持了极低的内存占用。因此，"Hyper" 意味着它在性能和准确性上**超越**了其前身 LogLog 算法。

总结来说：

- **LogLog**：强调算法所需内存的**极低对数对数级别** (`loglog N`)。
- **HyperLogLog**：在 LogLog 的基础上，通过算法优化（尤其是使用调和平均数），**大幅提升了估算精度**，因此加上了 "Hyper" 前缀，表示其优越性。

所以，`HyperLogLog` 这个名字很好地概括了这种数据结构在**内存效率（LogLog）**和**估算精度（Hyper）**两方面的卓越性能。

#### 7.4 应用场景

#### 百万级网页 UV 计数

Redis HyperLogLog  优势在于只需要花费 12 KB 内存，就可以计算接近 2^64 个元素的基数，和元素越多就越耗费内存的 Set 和 Hash 类型相比，HyperLogLog 就非常节省空间。

所以，非常适合统计百万级以上的网页 UV 的场景。

在统计 UV 时，你可以用 PFADD 命令（用于向 HyperLogLog 中添加新元素）把访问页面的每个用户都添加到 HyperLogLog 中。

```shell
PFADD page1:uv user1 user2 user3 user4 user5
```

接下来，就可以用 PFCOUNT 命令直接获得 page1 的 UV 值了，这个命令的作用就是返回 HyperLogLog 的统计结果。

```shell
PFCOUNT page1:uv
```

不过，有一点需要你注意一下，HyperLogLog 的统计规则是基于概率完成的，所以它给出的统计结果是有一定误差的，标准误算率是 0.81%。

这也就意味着，你使用 HyperLogLog 统计的 UV 是 100 万，但实际的 UV 可能是 101 万。虽然误差率不算大，但是，如果你需要精确统计结果的话，最好还是继续用 Set 或 Hash 类型。

### 8. GEO

Redis GEO 是 Redis 3.2 版本新增的数据类型，主要用于存储地理位置信息，并对存储的信息进行操作。

在日常生活中，我们越来越依赖搜索“附近的餐馆”、在打车软件上叫车，这些都离不开基于位置信息服务（Location-Based Service，LBS）的应用。LBS 应用访问的数据是和人或物关联的一组经纬度信息，而且要能查询相邻的经纬度范围，GEO 就非常适合应用在 LBS 服务的场景中。

#### 8.1 内部实现

**GEO 本身并没有设计新的底层数据结构，而是直接使用了 Sorted Set 集合类型。**

GEO 类型使用 **GeoHash 编码方法** 实现了 **经纬度到 Sorted Set 中元素权重分数的转换**，这其中的两个关键机制就是「对二维地图做区间划分」和「对区间进行编码」。一组经纬度落在某个区间后，就用区间的编码值来表示，并把编码值作为 Sorted Set 元素的权重分数。

这样一来，我们就可以把经纬度保存到 Sorted Set 中，利用 Sorted Set 提供的“按权重进行有序范围查找”的特性，实现 LBS 服务中频繁使用的“搜索附近”的需求。

#### 8.2 常用命令

``` shell
# 存储指定的地理空间位置，可以将一个或多个经度(longitude)、纬度(latitude)、位置名称(member)添加到指定的 key 中。
GEOADD key longitude latitude member [longitude latitude member ...]

# 从给定的 key 里返回所有指定名称(member)的位置（经度和纬度），不存在的返回 nil。
GEOPOS key member [member ...]

# 返回两个给定位置之间的距离。
GEODIST key member1 member2 [m|km|ft|mi]

# 根据用户给定的经纬度坐标来获取指定范围内的地理位置集合。
GEORADIUS key longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] [ASC|DESC] [STORE key] [STOREDIST key]
```

#### 8.3 应用场景

##### 滴滴叫车

这里以滴滴叫车的场景为例，介绍下具体如何使用 GEO 命令：GEOADD 和 GEORADIUS 这两个命令。

假设车辆 ID 是 33，经纬度位置是（116.034579，39.030452），我们可以用一个 GEO 集合保存所有车辆的经纬度，集合 key 是 cars:locations。

执行下面的这个命令，就可以把 ID 号为 33 的车辆的当前经纬度位置存入 GEO 集合中：

```
GEOADD cars:locations 116.034579 39.030452 33
```

当用户想要寻找自己附近的网约车时，LBS 应用就可以使用 GEORADIUS 命令。

例如，LBS 应用执行下面的命令时，Redis 会根据输入的用户的经纬度信息（116.054579，39.030452 ），查找以这个经纬度为中心的 5 公里内的车辆信息，并返回给 LBS 应用。

```
GEORADIUS cars:locations 116.054579 39.030452 5 km ASC COUNT 10
```

### 9. Stream

#### 9.1 为什么引入 Stream

Redis Stream 是 Redis 5.0 版本新增加的数据类型，**Redis 专门为消息队列设计的数据类型**，它主要用于实现**可持久化的消息队列**。它可以被看作是一个只支持追加（append-only）的日志，非常适合构建事件流、日志收集和实时数据处理等应用。

在前面介绍 List 类型实现的消息队列，有两个问题：

1. 生产者需要自行实现全局唯一 ID；
2. 不能以消费组形式消费数据。

基于 Stream 类型的消息队列就解决上面的问题，以下是 Redis Stream 的主要特点和功能：

**1. 消息持久化：**

- Stream 中的所有消息都会被持久化到磁盘上，即使 Redis 服务器重启也不会丢失。
- 这使得 Stream 非常适合用作可靠的消息队列，确保消息不会因为服务器故障而丢失。

**2. 自动生成消息 ID：**

- 每条添加到 Stream 中的消息都会被分配一个唯一的、单调递增的 ID。这个 ID 由两部分组成：毫秒时间戳和序列号（`timestamp-sequence`）。
- 消息 ID 可以用于查询特定范围的消息，或者从某个 ID 开始消费消息。

**3. 支持多个消费者组：**

- Stream 引入了“消费者组”（Consumer Group）的概念。一个 Stream 可以有多个消费者组，每个消费者组都可以独立地消费 Stream 中的消息。
- 每个消费者组会维护一个指向其已处理消息的指针（last delivered ID），确保组内的不同消费者可以协同工作，并且不会重复处理消息。
- 这种设计非常适合实现消息的扇出（fan-out）模式，允许多个应用或服务同时消费同一个消息流。

**4. 消息确认与未确认消息列表（Pending Entries List, PEL）：**

- 当一个消费者从 Stream 中读取消息后，消息并不会立即从 Stream 中删除。消费者需要显式地通过 `XACK` 命令来确认消息已经被成功处理。
- 如果消息没有被确认，它会保留在消费者组的“未确认消息列表”（PEL，Pendling Entries List）中。
- PEL 的存在使得消息的可靠性更高，即使消费者在处理消息过程中崩溃，未确认的消息也可以被同一个消费者组的其他消费者接管并重新处理。

**5. 范围查询与消费：**

- 可以通过消息 ID 来查询特定范围的消息。
- `XRANGE` 命令用于按 ID 范围查询消息。
- `XREAD` 命令用于从 Stream 中读取新消息，或者从指定 ID 开始读取消息。

**6. 削峰填谷与流量控制：**

- Stream 可以作为生产者和消费者之间的缓冲层，在高并发场景下实现削峰填谷，平滑处理突发流量。

**7. 易于扩展和集成：**

- 由于其消息队列的特性，Stream 可以很容易地与其他系统集成，例如日志系统、实时分析系统、微服务架构中的事件驱动等。

#### 9.2 消费者组

**消费者组（Consumer Group）是 Redis Stream 为了实现分布式消费和负载均衡而引入的一个重要概念。** 简单来说，它是一组协同工作的消费者，它们共同从同一个 Stream 中读取和处理消息。

为了更好地理解它，我们可以把它想象成一个团队，这个团队共同完成一项任务：消费 Redis Stream 中的消息。

以下是消费者组的核心特点和作用：

1. **消息共享与负载均衡：**
   - 在一个消费者组内部，当有新消息到达 Stream 时，**这些消息会被公平地分发给组内的不同消费者**。这意味着，如果一个消费者组中有 A、B、C 三个消费者，到达 Stream 的消息会依次（或者根据某种策略）分配给 A、B、C，而不是每个消费者都收到所有的消息。
   - 这种机制实现了消息的**负载均衡**，避免了单个消费者处理所有消息而成为瓶颈。
2. **独占消费（Within Group）：**
   - **同一个消费者组内的不同消费者不会处理同一条消息。** 一条消息一旦被组内的某个消费者成功读取，就不会再分发给该组内的其他消费者。这确保了消息的独占性和避免重复处理。
3. **独立进度（Across Groups）：**
   - 一个 Stream 可以有多个消费者组。**每个消费者组独立地维护自己的消费进度。**
   - 这意味着，消费者组 A 可能已经处理到 Stream 的最新消息，而消费者组 B 可能还在处理较旧的消息。
   - 这种设计非常适合实现“**发布/订阅**”（pub/sub）或“**扇出**”（fan-out）模式。例如，一个订单 Stream 的消息，可能需要一个消费者组来更新库存，另一个消费者组来发送邮件通知，它们都可以独立地消费整个订单流。
4. **消费位置追踪：**
   - 每个消费者组会维护一个唯一的**“已处理消息ID”（last delivered ID）指针**。这个指针记录了该组内所有消费者已经成功读取（但不一定确认）的最后一条消息的ID。
   - 当一个新的消费者加入到消费者组时，它可以从这个共享的指针位置开始消费消息，或者从特定的历史位置开始。
5. **消息确认与故障恢复（PEL）：**
   - 消费者从消费者组读取消息后，并不会立即从 Stream 中删除，而是进入该消费者组的“**未确认消息列表（PEL - Pending Entries List）**”。
   - 只有当消费者通过 `XACK` 命令明确地确认（ACK）了消息后，这条消息才会被从 PEL 中移除。
   - 如果一个消费者在处理消息过程中崩溃或断开连接，它在 PEL 中的未确认消息并不会丢失。这些消息可以被同一个消费者组内的**其他消费者“认领”（`XCLAIM`）**并继续处理，从而实现故障恢复和消息的可靠性。
6. **消费者身份：**
   - 在消费者组内部，每个消费者都有一个唯一的名称（`consumername`）。这使得 Redis 能够区分不同的消费者，并追踪它们各自的消费状态。

**为什么需要消费者组？**

- **实现并行处理：** 允许多个消费者同时处理 Stream 中的消息，提高处理吞吐量。
- **实现消息的扇出：** 多个不同的应用或服务可以独立地消费同一个消息流，每个组可以有自己的逻辑和处理进度。
- **实现高可用和容错：** 当组内的某个消费者失败时，其未完成的消息可以被组内其他消费者接管，确保消息不丢失和持续处理。
- **简化客户端逻辑：** 客户端不需要自己去管理消费进度和消息分发，这些都由 Redis 消费者组机制来处理。

**一个简单的类比：**

想象你有一本**大日记本（Stream）**，里面记录了每天发生的事情（消息）。

- 如果你是**单独阅读（XREAD）**，那么你一个人看完所有的日记。
- 现在，你组建了一个阅读小组（消费者组）。
  - 小组成员有 小红、小明、小刚（消费者）。
  - 你告诉他们：“我们一起来看这本日记！”
  - 当有新的日记（消息）写进来时，小红可能读第1篇，小明读第2篇，小刚读第3篇，然后小红再读第4篇... 这样大家分工合作，更快地看完所有日记。
  - 如果小红看了一半，突然有事走开了，她没看完的日记，小明或小刚可以接着帮她看完。
  - 如果你又组建了**另一个阅读小组（另一个消费者组）**，比如“分析小组”，他们也可以独立地从头到尾（或者从任何地方）阅读这本日记，与第一个阅读小组的进度互不干扰。

这就是 Redis Stream 消费者组的核心思想。它极大地提升了 Redis Stream 在构建分布式消息系统时的灵活性、可靠性和扩展性。

#### 9.3 常见命令

- `XADD key ID field string [field string ...]`：向 Stream 中添加消息。ID 可以是 `*`（让 Redis 自动生成）或自定义 ID。
- `XREAD [COUNT count] [BLOCK milliseconds] STREAMS key [key ...] ID [ID ...]`：从一个或多个 Stream 中读取消息。可以阻塞等待新消息。
- `XREADGROUP GROUP groupname consumername [COUNT count] [BLOCK milliseconds] STREAMS key [key ...] ID [ID ...]`：从消费者组中读取消息。
- `XACK key groupname ID [ID ...]`：确认消息已经被成功处理。
- `XPENDING key groupname [IDLE min-idle-time] [start end count] [consumername]`：查看消费者组中未确认的消息。
- `XCLAIM key groupname consumername min-idle-time ID [ID ...]`：将未确认的消息从一个消费者转移到另一个消费者。
- `XGROUP CREATE key groupname ID`：创建一个消费者组。
- `XGROUP DESTROY key groupname`：销毁一个消费者组。
- `XDEL key ID [ID ...]`：从 Stream 中删除指定 ID 的消息（注意：这并不会释放空间，只是将消息标记为已删除）。
- `XTRIM key MAXLEN [~] count`：修剪 Stream，保留指定数量的最新消息。

#### 9.4 应用场景

##### 消息队列

生产者通过 XADD 命令插入一条消息：

```shell
# * 表示让 Redis 为插入的数据自动生成一个全局唯一的 ID
# 往名称为 mymq 的消息队列中插入一条消息，消息的键是 name，值是 xiaolin
> XADD mymq * name xiaolin
"1654254953808-0"
```

插入成功后会返回全局唯一的 ID："1654254953808-0"。消息的全局唯一 ID 由两部分组成：

- 第一部分“1654254953808”是数据插入时，以毫秒为单位计算的当前服务器时间；
- 第二部分表示插入消息在当前毫秒内的消息序号，这是从 0 开始编号的。例如，“1654254953808-0”就表示在“1654254953808”毫秒内的第 1 条消息。

消费者通过 XREAD 命令从消息队列中读取消息时，可以指定一个消息 ID，并从这个消息 ID 的下一条消息开始进行读取（注意是输入消息 ID 的下一条信息开始读取，不是查询输入ID的消息）。

```shell
# 从 ID 号为 1654254953807-0 的消息开始，读取后续的所有消息（示例中一共 1 条）。
> XREAD Stream mymq 1654254953807-0
1) 1) "mymq"
   2) 1) 1) "1654254953808-0"
         2) 1) "name"
            2) "xiaolin"
```

如果想要实现阻塞读（当没有数据时，阻塞住），可以调用 XRAED 时设定 block 配置项，实现类似于 BRPOP 的阻塞读取操作。

比如，下面这命令，设置了 block 10000 的配置项，10000 的单位是毫秒，表明 XREAD 在读取最新消息时，如果没有消息到来，XREAD 将阻塞 10000 毫秒（即 10 秒），然后再返回。

```shell
# 命令最后的“$”符号表示读取最新的消息
> XREAD block 10000 Stream mymq $
(nil)
(10.00s)
```

前面介绍的这些操作 List 也支持的，接下来看看 Stream 特有的功能。

Stream 可以以使用 XGROUP 创建消费组，创建消费组之后，Stream 可以使用 XREADGROUP 命令让消费组内的消费者读取消息。

创建一个名为 group1 的消费组，这个消费组消费的消息队列是 mymq：

```shell
# 创建一个名为 group1 的消费组
> XGROUP create mymq group1 0
OK
```

消费组 group1 内的消费者  consumer1 从 mymq 消息队列中读取所有消息的命令如下：

```shell
# 命令最后的参数“>”，表示从第一条尚未被消费的消息开始读取。
> XREADGROUP group group1 consumer1 Stream mymq >
1) 1) "mymq"
   2) 1) 1) "1654254953808-0"
         2) 1) "name"
            2) "xiaolin"
```

消息队列中的消息一旦被消费组里的一个消费者读取了，就不能再被该消费组内的其他消费者读取了。

比如说，我们执行完刚才的 XREADGROUP 命令后，再执行一次同样的命令，此时读到的就是空值了：

```shell
> XREADGROUP group group1 consumer1 Stream mymq >
(nil)
```

**使用消费组的目的是让组内的多个消费者共同分担读取消息，所以，我们通常会让每个消费者读取部分消息，从而实现消息读取负载在多个消费者间是均衡分布的**。

例如，我们执行下列命令，让 group2 中的 consumer1、2、3 各自读取一条消息。

```shell
# 让 group2 中的 consumer1 从 mymq 消息队列中消费一条消息
> XREADGROUP group group2 consumer1 count 1 Stream mymq >
1) 1) "mymq"
   2) 1) 1) "1654254953808-0"
         2) 1) "name"
            2) "xiaolin"
# 让 group2 中的 consumer2 从 mymq 消息队列中消费一条消息
> XREADGROUP group group2 consumer2 count 1 Stream mymq >
1) 1) "mymq"
   2) 1) 1) "1654256265584-0"
         2) 1) "name"
            2) "xiaolincoding"
# 让 group2 中的 consumer3 从 mymq 消息队列中消费一条消息
> XREADGROUP group group2 consumer3 count 1 Stream mymq >
1) 1) "mymq"
   2) 1) 1) "1654256271337-0"
         2) 1) "name"
            2) "Tom"
```

> 基于 Stream 实现的消息队列，如何保证消费者在发生故障或宕机再次重启后，仍然可以读取未处理完的消息？

Streams 会自动使用内部队列（也称为 PENDING List）留存消费组里每个消费者读取的消息，直到消费者使用 XACK 命令通知 Streams“消息已经处理完成”。

如果消费者没有成功处理消息，它就不会给 Streams 发送 XACK 命令，消息仍然会留存。此时，**消费者可以在重启后，用 XPENDING 命令查看已读取、但尚未确认处理完成的消息**。

例如，我们来查看一下 group2 中各个消费者已读取、但尚未确认的消息个数，命令如下：

```shell
127.0.0.1:6379> XPENDING mymq group2
1) (integer) 3
2) "1654254953808-0"  # 表示 group2 中所有消费者读取的消息最小 ID
3) "1654256271337-0"  # 表示 group2 中所有消费者读取的消息最大 ID
4) 1) 1) "consumer1"
      2) "1"
   2) 1) "consumer2"
      2) "1"
   3) 1) "consumer3"
      2) "1"
```

如果想查看某个消费者具体读取了哪些数据，可以执行下面的命令：

```shell
# 查看 group2 里 consumer2 已从 mymq 消息队列中读取了哪些消息
> XPENDING mymq group2 - + 10 consumer2
1) 1) "1654256265584-0"
   2) "consumer2"
   3) (integer) 410700
   4) (integer) 1
```

可以看到，consumer2 已读取的消息的 ID 是 1654256265584-0。

**一旦消息 1654256265584-0 被 consumer2 处理了，consumer2 就可以使用 XACK 命令通知 Streams，然后这条消息就会被删除**。

```shell
> XACK mymq group2 1654256265584-0
(integer) 1
```

当我们再使用 XPENDING 命令查看时，就可以看到，consumer2 已经没有已读取、但尚未确认处理的消息了。

```shell
> XPENDING mymq group2 - + 10 consumer2
(empty array)
```

好了，基于 Stream 实现的消息队列就说到这里了，小结一下：

- 消息保序：XADD/XREAD
- 阻塞读取：XREAD block
- 重复消息处理：Stream 在使用  XADD 命令，会自动生成全局唯一 ID；
- 消息可靠性：内部使用 PENDING List 自动保存消息，使用 XPENDING 命令查看消费组已经读取但是未被确认的消息，消费者使用 XACK 确认消息；
- 支持消费组形式消费数据

> Redis 基于 Stream 消息队列与专业的消息队列有哪些差距？

一个专业的消息队列，必须要做到两大块：

- 消息不丢。
- 消息可堆积。

*1、Redis Stream 消息会丢失吗？*

使用一个消息队列，其实就分为三大块：**生产者、队列中间件、消费者**，所以要保证消息就是保证三个环节都不能丢失数据。

![图片](https://github.com/QaQOwOQaQ/picx-images-hosting/raw/master/image.5q7o7udv0h.png)

Redis Stream 消息队列能不能保证三个环节都不丢失数据？

- Redis 生产者会不会丢消息？生产者会不会丢消息，取决于生产者对于异常情况的处理是否合理。从消息被生产出来，然后提交给 MQ 的过程中，只要能正常收到 （ MQ 中间件） 的 ack 确认响应，就表示发送成功，所以只要处理好返回值和异常，如果返回异常则进行消息重发，那么这个阶段是不会出现消息丢失的。

- Redis 消费者会不会丢消息？不会，因为 Stream （ MQ 中间件）会自动使用内部队列（也称为 PENDING List）留存消费组里每个消费者读取的消息，但是未被确认的消息。消费者可以在重启后，用 XPENDING 命令查看已读取、但尚未确认处理完成的消息。等到消费者执行完业务逻辑后，再发送消费确认 XACK 命令，也能保证消息的不丢失。

- Redis 队列中间件会不会丢消息？**会**，Redis 在以下 2 个场景下，都会导致数据丢失：

  * AOF 持久化配置为每秒写盘，但这个写盘过程是异步的，Redis 宕机时会存在数据丢失的可能

  - 主从复制也是异步的，主从切换时，也存在丢失数据的可能。

可以看到，Redis 在队列中间件环节无法保证消息不丢。像 RabbitMQ 或 Kafka 这类专业的队列中间件，在使用时是部署一个 **集群**，生产者在发布消息时，队列中间件通常会写「多个节点」，也就是有多个副本，这样一来，即便其中一个节点挂了，也能保证集群的数据不丢失。

*2、Redis Stream 消息可堆积吗？*

Redis 的数据都存储在内存中，这就意味着一旦发生消息积压，则会导致 Redis 的内存持续增长，如果超过机器内存上限，就会面临被 OOM 的风险。所以 Redis 的 Stream 提供了可以指定队列最大长度的功能，就是为了避免这种情况发生。

但 Kafka、RabbitMQ 专业的消息队列它们的数据都是存储在磁盘上，当消息积压时，无非就是多占用一些磁盘空间。

因此，把 Redis 当作队列来使用时，会面临的 2 个问题：

- Redis 本身可能会丢数据；
- 面对消息挤压，内存资源会紧张；

所以，能不能将 Redis 作为消息队列来使用，关键看你的业务场景：

- 如果你的业务场景足够简单，对于数据丢失不敏感，而且消息积压概率比较小的情况下，把 Redis 当作队列是完全可以的。
- 如果你的业务有海量消息，消息积压的概率比较大，并且不能接受数据丢失，那么还是用专业的消息队列中间件吧。

### 10. JSON

#### 10.1 为什么引入 JSON

**Redis JSON 是一个 Redis 模块，它允许 Redis 以优化的方式存储、管理和查询 JSON 文档。**

在 Redis 6.0 之前，如果你想在 Redis 中存储 JSON 数据，通常的做法是将其作为字符串（String）类型存储。但这种方式存在一些局限性：

##### 1. **原子性操作困难**

> 无法对 JSON 内部的特定字段进行原子操作，比如递增某个数字字段，或者追加一个数组元素。

**问题：** 假设你存储了一个用户信息的 JSON 字符串，例如 `SET user:1 '{"name":"Alice","age":30,"city":"New York"}'`。现在你想把 `age` 从 30 改成 31，或者添加一个 `email` 字段。

**作为字符串的实现方式：** 你必须先执行 `GET user:1` 把整个 JSON 字符串取出来。然后在客户端（你的应用程序代码中）解析这个 JSON 字符串，修改 `age` 字段（或者添加 `email`），最后再用 `SET user:1` 把修改后的整个 JSON 字符串写回 Redis。

**局限性：**

- **非原子性：** “取-改-写”这三个步骤不是一个原子操作。在并发场景下，如果在你取出数据和写回数据之间，另一个客户端也对同一个键进行了修改，那么你的修改可能会覆盖掉别人的修改，或者被别人的修改覆盖掉，导致数据不一致（典型的**竞态条件**）。
- **性能开销：** 每次修改都要进行网络 I/O（两次往返：GET 和 SET）、客户端的 JSON 解析和序列化操作，这对于频繁更新的场景会带来显著的性能开销，尤其是 JSON 文档很大的时候。

##### 2.**查询效率低** 

> 如果你想查询 JSON 内部的某个字段或者根据字段值进行过滤，你不得不取出整个 JSON 字符串，然后在应用层解析和处理，这效率很低，尤其对于大型 JSON 文档。

**问题：** 你想找出所有 `age` 大于 25 的用户，或者所有 `city` 是 "New York" 的用户。

**作为字符串的实现方式：** Redis 的 String 类型本身不提供任何 JSON 内部字段的查询能力。你无法直接告诉 Redis “给我所有 age > 25 的 JSON”。

**局限性：**

- **全量扫描和客户端处理：** 你不得不获取所有相关的 JSON 字符串（如果用 `KEYS` 命令遍历，效率更低，通常不会这么做；如果是已知 key，也只能逐个取）。然后，在客户端逐一解析每个 JSON 字符串，进行过滤判断。这对于数据量较大或需要频繁查询的场景来说，性能极差。
- **无法利用 Redis 的索引能力：** Redis 作为键值存储，其强大的地方在于通过键进行快速查找。但当 JSON 作为字符串时，它无法对 JSON 内部的字段建立索引，导致无法进行基于内容的快速检索。

##### 3.**空间效率不高** 

> 作为普通字符串存储时，Redis 无法理解 JSON 的结构，也无法进行优化存储。

**问题：** JSON 字符串中通常会包含大量的引号、逗号、括号等分隔符以及重复的键名，这些在文本表示中是必需的，但在存储时可能存在冗余。

- 考虑以下一个简单的 JSON 对象，它表示一个用户的基本信息：

  ```json
  {
    "id": "user_001",
    "name": "张三",
    "age": 30,
    "email": "zhangsan@example.com",
    "tags": ["vip", "new_user"]
  }
  ```

  当这个 JSON 对象被序列化成一个字符串并存储时，我们来看看其中哪些部分可以被认为是“冗余”的：

  1. **分隔符和结构性字符：**

     - `{}`：表示对象开始和结束的括号。
     - `[]`：表示数组开始和结束的括号。
     - `:`：键和值之间的分隔符。
     - `,`：键值对或数组元素之间的分隔符。
     - `""`：字符串值的引号，以及键名的引号。

     在上面的例子中，光是这些字符就占据了不少空间：

     - `{` 和 `}`：2个字符
     - `:`：5个字符
     - `,`：4个字符
     - `[` 和 `]`：2个字符
     - `"`：键名和字符串值的引号，总共 2 (id) + 2 (name) + 2 (age) + 2 (email) + 2 (tags) + 2 (user_001) + 2 (张三) + 2 (zhangsan@example.com) + 2 (vip) + 2 (new_user) = 20个字符。

     这些字符虽然对 JSON 的解析至关重要，但在计算机内部，这些结构信息可以用更紧凑、非文本的方式来表示。

  2. **重复的键名（针对大量相似对象）：**

     - 在单个 JSON 对象中，键名 (`"id"`, `"name"`, `"age"`, `"email"`, `"tags"`) 确实是必要的。

     - **但当你存储大量相似的 JSON 对象时，问题就出现了。** 想象一个场景，你有 100 万个用户对象，每个对象都有 `id`, `name`, `age`, `email`, `tags` 这些字段。

     - 每个用户对象在被序列化成字符串时，都会重复包含 `"id"`，`"name"`，`"age"`，`"email"`，`"tags"`  这些键名。例如：

       ```json
       // 用户 A
       {"id": "user_001", "name": "张三", "age": 30, ...}
       // 用户 B
       {"id": "user_002", "name": "李四", "age": 25, ...}
       // 用户 C
       {"id": "user_003", "name": "王五", "age": 35, ...}
       ```

     - 键名本身是固定的字符串，但它们在每个 JSON 字符串中都要被完整地存储一遍。例如，`"name"` 这个键名（包含引号）是 6 个字符，存储 100 万个用户就需要额外 6MB 的空间来存储这个重复的键名，这还不算其他键名。

- **作为字符串的实现方式：** Redis 只是按原样存储你的 JSON 字符串，不会对其进行任何结构性的优化。
- 局限性：
  - **存储空间浪费：** 即使是语义上相同的 JSON，只要格式有一点点不同（比如空格），Redis 也会当作完全不同的字符串存储。而 Redis JSON 模块可以采用更紧凑的二进制格式来存储，减少冗余，从而节省内存。
  - **传输开销：** 从 Redis 读取或写入时，你需要传输完整的 JSON 文本，即使你只关心其中的一小部分。

**Redis JSON 模块的出现正是为了解决这些问题。** 它将 JSON 视为一种原生数据类型，并提供了专门的命令集来操作和查询 JSON 数据。

#### 10.2 Redis JSON 如何优化

Redis JSON 模块通过采用**优化的二进制格式**来存储 JSON 文档，从而减少这些冗余：

##### 1. **紧凑的结构化表示：**

当我们将 JSON 字符串存储为 Redis String 类型时，它就是纯文本。而 Redis JSON 模块不会直接存储这段文本。它会解析 JSON 字符串，然后将其转换为一种**更适合计算机处理和存储的二进制格式**。

这种二进制格式的核心思想是：

- **避免文本字符的冗余：**
  - JSON 文本中的 `{` `}` `[` `]` `:` `,` `"` 等字符，在二进制表示中是不需要的。它们是人类可读的标记。
  - Redis JSON 会使用特定的**类型编码（type codes）**或**标志位（flags）**来表示这些结构。例如，一个字节可能就足以表示“这里是一个 JSON 对象的开始”或者“这是一个字符串类型的值”。
  - 对于数字类型，它会直接存储数字的二进制值（如 64 位整数或双精度浮点数），而不是它们的字符串表示（例如，数字 123456789 存储为字符串需要 9 个字符，而存储为 4 字节或 8 字节的二进制数则更紧凑）。布尔值 `true`/`false` 也可以用一个或两个位来表示。
- **更快的解析和操作：**
  - 由于数据已经转换为结构化的二进制形式，Redis 在内部操作这些 JSON 数据时，不需要进行文本解析（parsing）和序列化（serialization）过程。它可以直接通过指针和偏移量定位到特定的字段或数组元素，大大提高了读写性能。
  - 例如，要访问一个 JSON 对象的某个字段，Redis 不需要扫描字符串去查找键名，而是可以直接通过内部查找表或者结构偏移量快速定位。
- **示例：** 考虑 JSON 片段 `{"age":30}`。
  - 作为字符串：`{"age":30}` （10个字符，10字节）
  - 作为紧凑二进制：
    - 可能用一个字节表示“对象开始”
    - 用一个短整数表示键名 `"age"` 的引用 ID (假设是 ID `0x01`)
    - 用一个字节表示“整数类型”
    - 用 4 个字节存储整数 `30` 的二进制值
    - 用一个字节表示“对象结束” 理论上，这可能只需要 1 + 1 + 1 + 4 + 1 = 8 个字节（这只是一个简化示例，实际可能更复杂，但核心是去除文本冗余）。

##### 2. **键名的“字典”或“哈希”编码：**

这是针对**重复键名**的优化，特别适用于存储大量结构相似的 JSON 文档。

- **传统方式的冗余：** 当我们有多个 JSON 对象时，例如：

  ```json
  // User 1
  {"name": "Alice", "age": 30}
  // User 2
  {"name": "Bob", "age": 25}
  // User 3
  {"name": "Charlie", "age": 35}
  ```

  每个 JSON 字符串都包含完整且重复的键名 `name` 和 `age`。如果有很多这样的对象，`"name"`（6字节）和 `"age"`（5字节）会不断地重复出现，造成大量空间浪费。

- **Redis JSON 的优化策略：** Redis JSON 模块在内部维护一个**键名映射表（或称作字符串池/字典）**。

  1. 当一个 JSON 文档被添加到 Redis JSON 时，模块会提取其中的所有键名（例如 `"name"`, `"age"`）。
  2. 它会检查这些键名是否已经在内部的映射表中。
  3. 如果键名是新的，它会将其添加到映射表中，并分配一个**短的、唯一的整数 ID**给它。
  4. 如果键名已经存在，它就直接使用已分配的那个整数 ID。
  5. 在存储实际的 JSON 数据时，它不再存储完整的键名字符串，而是存储这个**短的整数 ID**。

- **示例：** 假设内部映射表为：

  - `"name"` -> `0x01`
  - `"age"` -> `0x02`

  那么上述三个用户的数据在 Redis JSON 内部存储时，键名部分可能就只存储 `0x01` 和 `0x02`，而不是 `"name"` 和 `"age"` 的完整字符串。

  - `User 1` 内部存储： `(0x01, "Alice"), (0x02, 30)`
  - `User 2` 内部存储： `(0x01, "Bob"), (0x02, 25)`
  - `User 3` 内部存储： `(0x01, "Charlie"), (0x02, 35)`

- **优点：**

  - **显著节省内存：** 对于大量具有相同结构或相似结构的 JSON 文档，键名只存储一次，大大减少了重复字符串的存储开销。
  - **更快的查找：** 通过短整数 ID 进行内部查找比字符串比较更快。

### 11. Vector Set

Vector Set 是 Redis 8.0 的一个**新数据类型**，目前处于**预览（preview）阶段**，尚未正式发布稳定版。

"Vector Set" 的设计理念是：

- **类似于 Sorted Set：** 它受到了 Redis Sorted Set 的启发。在 Sorted Set 中，每个成员有一个字符串元素和一个浮点数分数（用于排序）。

- **向量作为“分数”：** 在 Vector Set 中，每个元素也是一个字符串（通常是数据的 ID），但它不再关联一个简单的浮点数分数，而是关联一个**高维向量**。

- **原生支持向量相似度：** 核心目标是提供一个原生的 Redis 数据类型，可以直接存储向量并支持基于向量相似度的查询，而不需要依赖于复杂的模块配置。

- 命令集：

   它提供了一套新的命令来操作 Vector Set，例如：

  - `VADD`：添加元素到 Vector Set，并指定其关联的向量。
  - `VSIM`：执行向量相似度搜索，找出最相似的元素。
  - `VREM`：移除元素。
  - `VCARD`：获取集合大小。
  - 以及支持属性过滤、量化等功能。

- **底层实现：** Vector Set 内部基于 HNSW 算法，以实现高效的近似最近邻搜索。

- **目标：** 提供一个更轻量级、更“Redis-like”的方式来处理向量，尤其适用于那些主要关注向量相似度搜索而不需要 RediSearch 提供的所有高级搜索和索引功能的场景。

### 12. Bloom Filter

布隆过滤器是一种**概率型数据结构**，它用于判断一个元素**是否“可能”存在于一个集合中**。它的核心特点是**空间效率极高**，但存在一定的**误报率（False Positive）**，即它可能会错误地报告一个实际上不存在的元素“存在”。然而，它**绝对不会漏报（False Negative）**，即如果一个元素确实在集合中，它一定会被判断为“存在”。

#### 12.1 布隆过滤器的基本原理

布隆过滤器底层是一个**很长的二进制向量（位数组）** 和 **k 个哈希函数**。

- **位数组 (Bit Array / Bitmask)：** 这是一个由 `m` 个比特位组成的数组，所有的位初始值都为 `0`。
- **哈希函数 (Hash Functions)：** `k` 个独立的哈希函数，它们可以将输入的元素映射到位数组中的 `k` 个不同位置。

**工作流程：**

1. **添加元素 (Add)：**
   - 当要向布隆过滤器中添加一个元素 `x` 时，会依次使用 `k` 个哈希函数对 `x` 进行哈希计算。
   - 每个哈希函数会得到一个在 `0` 到 `m-1` 范围内的索引值。
   - 将位数组中这 `k` 个索引位置的比特位设置为 `1`。
2. **查询元素 (Query)：**
   - 当要查询一个元素 `y` 是否存在时，也会使用**同样的 `k` 个哈希函数**对 `y` 进行哈希计算。
   - 得到 `k` 个索引值。
   - 检查位数组中这 `k` 个索引位置的比特位。
   - **如果所有这 `k` 个比特位都为 `1`，那么布隆过滤器会判断元素 `y` “可能存在”于集合中。**
   - **如果其中任何一个比特位为 `0`，那么布隆过滤器会判断元素 `y` “一定不存在”于集合中。**

#### 12.2 布隆过滤器的参数选择

布隆过滤器的性能和误报率主要取决于以下几个参数：

- `m`：位数组的长度（比特位数）。`m` 越大，误报率越低，但内存消耗越大。
- `k`：哈希函数的数量。`k` 越多，误报率越低，但计算开销越大，**且当 `k` 超过最优值时，误报率反而可能上升（因为更多的位被设置为 1，导致位数组饱和）。**
- `n`：预期要添加到集合中的元素数量。这是估算 `m` 和 `k` 的重要依据。

给定期望的元素数量 `n` 和可接受的误报率 `p`，可以计算出最优的 `m` 和 `k`：

- **最优的哈希函数数量 `k`：** $k=(m/n)*ln(2)$
- **位数组长度 `m`：** $m=−(n*ln(p))/(ln(2)^2)$

#### 12.3 优缺点

**优点：**

- **空间效率极高：** 远小于直接存储所有元素所需的空间。
- **查询速度快：** 哈希计算和位操作通常非常迅速，与集合大小无关。
- **保密性好：** 不存储实际的元素，只存储元素的哈希指纹，有一定的数据隐私性。

**缺点：**

- **存在误报：** 这是最主要的缺点，需要根据应用场景评估可接受的误报率。
- **不支持删除：** 由于一个比特位可能被多个元素共享，删除一个元素可能会影响其他元素的判断，导致误删。虽然有一些变种（如**布谷鸟过滤器**）支持删除，但标准布隆过滤器不支持。
- **容量限制：** 如果添加的元素数量远超过预期容量，误报率会急剧上升，直至过滤器饱和（所有位都变为 1），此时它将失去判断能力。

#### 12.4. Redis 中的布隆过滤器

Redis 本身不原生提供布隆过滤器数据类型，但通过 **RedisBloom 模块**可以实现。RedisBloom 提供了 `BF.ADD`、`BF.EXISTS` 等命令来操作布隆过滤器。

**示例命令 (使用 RedisBloom 模块):**

1. **创建布隆过滤器：** `BF.RESERVE myfilter 0.001 100000`
   - `myfilter`: 过滤器名称。
   - `0.001`: 期望的误报率（0.1%）。
   - `100000`: 期望容量（最多存储 10 万个元素）。
2. **添加元素：** `BF.ADD myfilter "user_123"` `BF.ADD myfilter "product_abc"`
3. **检查元素是否存在：** `BF.EXISTS myfilter "user_123"`  -> 1 (存在) `BF.EXISTS myfilter "product_xyz"` -> 0 (不存在) `BF.EXISTS myfilter "user_999"`  -> 1 或 0 (如果是 1，可能是误报；如果是 0，则一定不存在)

#### 12.5 典型应用场景

- **缓存穿透：** 在访问数据库或更慢的存储层之前，先通过布隆过滤器判断请求的数据是否存在。如果过滤器说不存在，则直接返回空，避免了对底层存储的无效查询，减轻了数据库压力。
- **垃圾邮件过滤：** 将已知的垃圾邮件地址或模式加入布隆过滤器，快速识别并拦截。
- **网络爬虫去重：** 判断一个 URL 是否已经被爬取过，避免重复访问。
- **推荐系统：** 过滤掉用户已经看过或不感兴趣的内容。
- **大数据去重：** 在处理海量数据时，快速识别重复项，而无需将所有数据加载到内存。

布隆过滤器是一个非常实用的工具，在许多需要高效率和可接受误差的场景中发挥着重要作用。

### 总结

Redis 常见的五种数据类型：**String（字符串），Hash（哈希），List（列表），Set（集合）及 Zset(sorted set：有序集合)**。

这五种数据类型都由多种数据结构实现的，主要是出于时间和空间的考虑，当数据量小的时候使用更简单的数据结构，有利于节省内存，提高性能。

Redis 五种数据类型的应用场景：

- String 类型的应用场景：缓存对象、常规计数、分布式锁等。
- List 类型的应用场景：消息队列（有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等。
- Hash 类型：缓存对象、购物车等。
- Set 类型：聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等。
- Zset 类型：排序场景，比如排行榜、电话和姓名排序等。

Redis 后续版本又支持各种针对特定场景优化的数据类型，它们的应用场景如下：

- BitMap（2.2 版新增）：二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等；
- HyperLogLog（2.8 版新增）：海量数据基数统计的场景，比如百万级网页 UV 计数等；
- GEO（3.2 版新增）：存储地理位置信息的场景，比如滴滴叫车；
- Stream（5.0 版新增）：消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：自动生成全局唯一消息ID，支持以消费组形式消费数据。
- JSON

## 十六、Redis 简介

### 1. Redis 是什么

For developers, who are building **real-time data-driven applications**, Redis is the preferred, fastest, and most feature-rich **cache**, **data structure server**, and **document** and **vector query engine**.

> 向量查询引擎（Vector Query Engine）是一种专门用于存储、管理和高效检索向量数据的系统。在AI时代，它变得越来越重要，特别是对于处理非结构化数据（如文本、图像、音频、视频等）的应用。
>
> 以下是关于向量查询引擎的一些关键点：
>
> 1. **什么是向量？**
>    - 在向量查询引擎的上下文中，向量是数据的一种数值表示。通过机器学习模型（如嵌入模型或深度学习网络），各种类型的数据（文字、图像、声音等）可以被转换成一系列数字，形成一个 **高维度的向量**。
>    - 这些向量捕获了 **原始数据的语义和上下文信息**。如果两个数据点在 **语义上相似**，那么它们对应的向量在**多维空间中的距离就会很近**。
> 2. **工作原理：**
>    - **向量化（Vectorization/Embedding）：** 首先，原始数据（例如一段文本、一张图片）会通过一个预训练的机器学习模型转换成高维度的数值向量（也称为**嵌入**，embeddings）。
>    - **存储与索引：** 这些向量被存储在向量数据库或向量索引中。为了实现高效的检索，向量查询引擎会使用特定的索引技术（如ANN算法，Approximate Nearest Neighbor，近似最近邻算法），来组织和索引这些向量。
>    - **查询：** 当用户发起查询时，查询本身也会被转换成一个向量。然后，向量查询引擎会在存储的向量集合中查找与查询向量最“接近”的向量。这种“接近”通常通过计算 **向量之间的距离**（如余弦相似度或欧几里得距离）来衡量。
>    - **返回结果：** 引擎会返回那些与查询向量最相似的数据对应的原始内容。
> 3. **为什么重要？**
>    - **处理非结构化数据：** 传统的数据库和查询方法在处理非结构化数据时效率低下。向量查询引擎能够理解数据的“含义”，而不仅仅是关键词匹配，因此能够更好地处理图像、音频和文本等复杂数据类型。
>    - **语义搜索：** 实现了语义搜索，即理解用户查询的意图，而不仅仅是字面上的关键词。例如，搜索“智能手机”也可能返回“手机”或“移动设备”的结果。
>    - **推荐系统：** 通过比较用户行为或商品特征的 **向量相似度**，可以实现更精准的推荐。
>    - **问答系统和生成式AI (LLMs/RAG)：** 在大型语言模型（LLMs）的应用中，向量查询引擎是实现检索增强生成（RAG）的关键。它可以从大量文档中快速检索相关信息，并将其提供给LLM以生成更准确、更具上下文的回答。
>    - **多模态搜索：** 可以实现跨不同数据类型（例如，用文字搜索图片，或用图片搜索类似图片）的搜索。
> 4. **Redis作为向量查询引擎：**
>    - 正如你提到的，Redis 正在被开发者广泛用于构建实时数据驱动应用，并作为一种功能丰富的缓存、数据结构服务器和文档/向量查询引擎。
>    - Redis 能够存储向量数据，并提供高效的查询功能，特别是对于实时、低延迟的相似性搜索场景，这使得它在构建AI应用时非常有吸引力。

![REDIS_INTRODUCE](https://github.com/QaQOwOQaQ/picx-images-hosting/raw/master/image.3d51s908ah.png)

Redis 是一种基于内存的数据库，对数据的读写操作都是在内存中完成，因此**读写速度非常快**，常用于**缓存，消息队列、分布式锁等场景**。

Redis 提供了多种数据类型来支持不同的业务场景，比如 String(字符串)、Hash(哈希)、 List (列表)、Set(集合)、Zset(有序集合)、Bitmaps（位图）、HyperLogLog（基数统计）、GEO（地理信息）、Stream（流），并且对数据类型的操作都是**原子性**的，因为执行命令由单线程负责的，不存在并发竞争的问题。

除此之外，Redis 还支持**事务 、持久化、Lua 脚本、多种集群方案（主从复制模式、哨兵模式、切片机群模式）、发布/订阅模式，内存淘汰机制、过期删除机制**等等。

### 2. Redis 和 Memcached 有什么区别

很多人都说用 Redis 作为缓存，但是 Memcached 也是基于内存的数据库，为什么不选择它作为缓存呢？要解答这个问题，我们就要弄清楚 Redis 和 Memcached 的区别。 Redis 与 Memcached **共同点**：

1. 都是基于内存的数据库，一般都用来当做缓存使用。
2. 都有过期策略。
3. 两者的性能都非常高。

Redis 与 Memcached **区别**：

- Redis 支持的数据类型更丰富（String、Hash、List、Set、ZSet），而 Memcached 只支持最简单的 key-value 数据类型；
- Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用，而 Memcached 没有持久化功能，数据全部存在内存之中，Memcached 重启或者挂掉后，数据就没了；
- Redis 原生支持集群模式，Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；
- Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持；

## 十七、切片集群

当 Redis 缓存数据量大到一台服务器无法缓存时，就需要使用 **Redis 切片集群**（Redis Cluster ）方案，它将数据分布在不同的服务器上，以此来降低系统对单主节点的依赖，从而提高 Redis 服务的读写性能。

Redis Cluster 方案采用哈希槽（Hash Slot），来处理数据和节点之间的映射关系。在 Redis Cluster 方案中，**一个切片集群共有 16384 个哈希槽**，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中，具体执行过程分为两大步：

- 根据键值对的 key，按照 CRC16 算法计算一个 16 bit 的值。
- 再用 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。

接下来的问题就是，这些哈希槽怎么被映射到具体的 Redis 节点上的呢？有两种方案：

- **平均分配：** 在使用 cluster create 命令创建 Redis 集群时，Redis 会自动把所有哈希槽平均分布到集群节点上。比如集群中有 9 个节点，则每个节点上槽的个数为 16384/9 个。
- **手动分配：** 可以使用 cluster meet 命令手动建立节点间的连接，组成集群，再使用 cluster addslots 命令，指定每个节点上的哈希槽个数。

### 1. 集群脑裂

先来理解集群的脑裂现象，这就好比一个人有两个大脑，那么到底受谁控制呢？

那么在 Redis 中，集群脑裂产生数据丢失的现象是怎样的呢？

在 Redis 主从架构中，部署方式一般是「一主多从」，主节点提供写操作，从节点提供读操作。 如果主节点的网络突然发生了问题，它与所有的从节点都失联了，但是此时的主节点和客户端的网络是正常的，这个客户端并不知道 Redis 内部已经出现了问题，还在照样的向这个失联的主节点写数据（过程A），此时这些数据被旧主节点缓存到了缓冲区里，因为主从节点之间的网络问题，这些数据都是无法同步给从节点的。

这时，哨兵也发现主节点失联了，它就认为主节点挂了（但实际上主节点正常运行，只是网络出问题了），于是哨兵就会在「从节点」中选举出一个 leader 作为主节点，这时集群就有两个主节点了 —— **脑裂出现了**。

然后，网络突然好了，哨兵因为之前已经选举出一个新主节点了，它就会把旧主节点降级为从节点（A），然后从节点（A）会向新主节点请求数据同步，**因为第一次同步是全量同步的方式，此时的从节点（A）会清空掉自己本地的数据，然后再做全量同步。所以，之前客户端在过程 A 写入的数据就会丢失了，也就是集群产生脑裂数据丢失的问题**。

总结一句话就是：由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于会从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。

> 解决方案

当主节点发现从节点下线或者通信超时的总数量大于阈值时，那么禁止主节点进行写数据，直接把错误返回给客户端。

在 Redis 的配置文件中有两个参数我们可以设置：

- min-slaves-to-write x，主节点必须要有至少 x 个从节点连接，如果小于这个数，主节点会禁止写数据。
- min-slaves-max-lag x，主从数据复制和同步的延迟不能超过 x 秒，如果超过，主节点会禁止写数据。

我们可以把 min-slaves-to-write 和 min-slaves-max-lag 这两个配置项搭配起来使用，分别给它们设置一定的阈值，假设为 N 和 T。

这两个配置项组合后的要求是，主库连接的从库中至少有 N 个从库，和主库进行数据复制时的 ACK 消息延迟不能超过 T 秒，否则，主库就不会再接收客户端的写请求了。

即使原主库是假故障，它在假故障期间也无法响应哨兵心跳，也不能和从库进行同步，自然也就无法和从库进行 ACK 确认了。这样一来，min-slaves-to-write 和 min-slaves-max-lag 的组合要求就无法得到满足，**原主库就会被限制接收客户端写请求，客户端也就不能在原主库中写入新数据了**。

**等到新主库上线时，就只有新主库能接收和处理客户端请求，此时，新写的数据会被直接写到新主库中。而原主库会被哨兵降为从库，即使它的数据被清空了，也不会有新数据丢失。**

> 举个例子

假设我们将 min-slaves-to-write 设置为 1，把 min-slaves-max-lag 设置为 12s，把哨兵的 down-after-milliseconds 设置为 10s，主库因为某些原因卡住了 15s，导致哨兵判断主库客观下线，开始进行主从切换。

同时，因为原主库卡住了 15s，没有一个从库能和原主库在 12s 内进行数据复制，原主库也无法接收客户端请求了。

这样一来，主从切换完成后，也只有新主库能接收请求，不会发生脑裂，也就不会发生数据丢失的问题了。

## 十八、LFU 算法

LFU 算法通过频率思想，解决了 LRU 以下问题：

1. 某个时间段经常访问但之后不活跃的数据不会因为计数器增加的太多而 “永远不会被淘汰”
2. 一次读取了大量数据时，这些数据不会在缓存中长期存在

Redis 的 LFU 算法主要通过以下几个关键点实现：

1. **访问频率计数器 (`lfu_freq`)：**
   - 每个 Redis 对象（`robj`）内部都包含一个 `lru` 字段，当使用 LFU 策略时，这个字段的一部分被用来存储一个8位的频率计数器（`lfu_freq`）。
   - 这个计数器记录了键被访问的近似频率。
2. **计数器衰减 (Decrementation):**
   - 为了防止那些很久以前很热门但现在不活跃的键一直霸占缓存，Redis 会周期性地对所有键的 `lfu_freq` 进行衰减。
   - 衰减的频率和幅度由 `lfu-decay-time` 配置项控制。当一个键很长时间未被访问时，它的 `lfu_freq` 值会逐渐下降。
3. **计数器增长 (Incrementation):**
   - 当一个键被访问时，它的 `lfu_freq` 计数器会增加。
   - 增加的幅度并不是简单的 +1，而是采用了一种 **对数增长** 的策略。这意味着，从低频率到高频率的增长速度会更快，而从高频率到更高频率的增长速度会变慢。这是为了避免那些被频繁访问的键的计数器增长过快，导致它们几乎永远不会被淘汰。这种增长策略由 `LFU_INIT_VAL` 和 `LFU_MAX_UPPER_BOUND` 结合随机性实现，使得低频率的计数器更容易达到较高值。
4. **淘汰策略：**
   - 当需要淘汰键时（例如，内存达到上限），Redis 会遍历一部分随机选择的键（由 `maxmemory-samples` 配置项控制）。
   - 在这些样本键中，它会选择 `lfu_freq` 值最小的键进行淘汰。如果 `lfu_freq` 相同，则选择 `lru` 时间戳更早（即更久没有访问）的键进行淘汰。

### 源码分析 (简化和关键部分)

Redis 的 LFU 实现主要涉及到 `object.c` (对象管理)、`db.c` (数据库操作)、`evict.c` (淘汰策略) 等文件。

为了更好地理解，我们主要关注以下几个关键函数和宏定义：

**1. `lfu_freq` 的管理 (在 `object.c` 和 `server.h` 中)**

在 `server.h` 中，`robj` 结构体：

```cpp
// server.h
typedef struct redisObject {
    unsigned type:4;        /* Object type. */
    unsigned encoding:4;    /* Object encoding. */
    unsigned lru:24;        /* LRU time (relative to server.lruclock) or
                                LFU data (least significant 8 bits frequency
                                and most significant 16 bits access time). */
    int refcount;           /* Reference count. */
    void *ptr;              /* Pointer to the actual data structure. */
} robj;

// lru 字段在高位存储 lru_clock，在 LFU 模式下低位存储 lfu_freq
// LFU_FRQ_BITS 是 8， LFU_LRU_BITS 是 16
#define LFU_FRQ_BITS 8
#define LFU_LRU_BITS 16
#define LFU_MAX_LOG_COUNT ((1<<LFU_FRQ_BITS)-1) // 最大频率计数器值 255
#define LFU_DECAY_TIME_BITS 16 // 衰减时间在lru字段中占据的位数

// 用于获取 LFU 频率和访问时间
#define LFU_FREQ(o) ((o)->lru & LFU_MAX_LOG_COUNT)
#define LFU_TIME(o) (((o)->lru >> LFU_FRQ_BITS) & ((1<<LFU_LRU_BITS)-1))

// 用于设置 LFU 频率和访问时间
#define LFU_SET_FREQ(o,freq) do { \
    (o)->lru = (((o)->lru & (~LFU_MAX_LOG_COUNT)) | freq); \
} while(0)
#define LFU_SET_TIME(o,lfu_time) do { \
    (o)->lru = ((o)->lru & ~( ((1<<LFU_LRU_BITS)-1) << LFU_FRQ_BITS )) | \
                ( (lfu_time) << LFU_FRQ_BITS ); \
} while(0)
```

**2. 计数器增长函数 (`server.h` 或 `db.c` 中)**

这个函数是 LFU 算法的核心，它控制了 `lfu_freq` 的增长逻辑。

```cpp
// server.h 或 db.c
/* LFU parameters */
#define LFU_INIT_VAL 5
#define LFU_MAX_UPPER_BOUND 255 // lfu_freq 的最大值

/* LFU logarithmic counter.
 * We use a logarithmic counter with an 8 bit field.
 * The value is incremented using probabilities, so the chance of incrementing
 * a counter with a higher value is lower.
 * The approximate probabilities are:
 * 100% at 0, 1/2 at 1, 1/4 at 2, 1/8 at 3 ... 1/128 at 7.
 * and so on.
 *
 * This function is used to update the LFU counter of a Redis object.
 * It takes the old counter value and increments it according to the
 * LFU_LOG_FACTOR server configuration.
 * The maximum value of the counter is 255.
 */
uint8_t LFUIncr(uint8_t counter) {
    if (counter == LFU_MAX_LOG_COUNT) return LFU_MAX_LOG_COUNT; // 达到最大值不再增加
    unsigned long r = random() & 0xFF; // 获取一个随机数
    // server.lfu_log_factor 默认为 10
    // log(counter * server.lfu_log_factor / 255) / log(2)
    // 这是 Redis LFU 计数器增长的核心逻辑
    // 越大的 counter，越难通过随机数判断，因此增长越慢
    if (r < server.lfu_log_factor) { // 小概率增加，保证高频率增长慢
        counter++;
    }
    return counter;
}
```

**3. 访问时更新 LFU (在 `db.c` 的 `lookupKey` 等函数中)**

当键被访问时，会调用 `LFUIncr` 更新其 LFU 计数。

```cpp
// db.c (简化后的伪代码)
robj *lookupKey(redisDb *db, sds key, int flags) {
    dictEntry *de = dictFind(db->dict,key);
    if (de) {
        robj *val = dictGetVal(de);
        // 如果启用了 LFU 策略
        if (server.maxmemory_policy & MAXMEMORY_FLAG_LFU) {
            unsigned long lfu_time = server.lru_clock & LFU_LRU_BITS_MASK;
            unsigned long lfu_freq = LFU_FREQ(val);

            // 更新 LFU 频率
            LFU_SET_FREQ(val, LFUIncr(lfu_freq));
            // 更新 LFU 访问时间戳
            LFU_SET_TIME(val, lfu_time);
        }
        return val;
    } else {
        return NULL;
    }
}
```

**4. 衰减 LFU 计数器 (`evict.c` 中的 `estimateObjectIdleTime` 和 `freeMemoryIfNeeded` 相关逻辑)**

Redis 会在每次执行内存淘汰或者周期性任务时，对 LFU 计数器进行衰减。

```cpp
// evict.c (伪代码，表示衰减逻辑)
// 计算一个键的近似空闲时间，并根据这个时间衰减 LFU 频率
unsigned long LFUDecrAndGetFreq(robj *o) {
    unsigned long lfu_time = LFU_TIME(o);
    unsigned long now = server.lru_clock & LFU_LRU_BITS_MASK; // 当前时间戳

    // 计算上次访问至今的“空闲时间”
    // 注意：这里的 LFU_LRU_BITS 是 16 位，所以时间是循环的
    if (now < lfu_time) now += (1<<LFU_LRU_BITS); // 处理时间戳溢出
    unsigned long idle_time = (now - lfu_time);

    // 根据 idle_time 和 lfu_decay_time 配置计算衰减步长
    // 比如 server.lfu_decay_time 默认为 1 (天)
    // 如果 idle_time 超过 lfu_decay_time，则每次衰减 1
    // 具体的衰减逻辑比这复杂，涉及到 server.lfu_decay_time 和 log(idle_time / decay_time)
    long num_decay_steps = (idle_time / server.lfu_decay_time);
    if (num_decay_steps > 0) {
        unsigned long old_freq = LFU_FREQ(o);
        unsigned long new_freq = old_freq - num_decay_steps; // 简单表示衰减
        if (new_freq < LFU_INIT_VAL) new_freq = LFU_INIT_VAL; // 频率不会低于初始值

        LFU_SET_FREQ(o, new_freq);
        return new_freq;
    } else {
        return LFU_FREQ(o); // 不需要衰减
    }
}
```

在 `freeMemoryIfNeeded()` 中进行淘汰时，会调用上述逻辑：

```cpp
// evict.c (简化伪代码)
int freeMemoryIfNeeded(void) {
    // ...
    // 在选择淘汰的键时，会对样本进行 LFUDecrAndGetFreq 计算
    // 选出 LFU 频率最低的键
    // ...
    dictEntry *de = NULL;
    long best_lfu_freq = -1;
    mstime_t best_idle_time = -1; // 用于频率相同时的 LRU 辅助判断

    // 随机采样若干键
    for (int i = 0; i < server.maxmemory_samples; i++) {
        // ... 获取一个随机键 val
        robj *val = dictGetVal(de_sample);
        long this_freq = LFUDecrAndGetFreq(val); // 获取衰减后的频率
        mstime_t this_idle = estimateObjectIdleTime(val); // 获取 LRU 辅助判断的空闲时间

        if (de == NULL || this_freq < best_lfu_freq ||
            (this_freq == best_lfu_freq && this_idle > best_idle_time))
        {
            // 如果找到 LFU 频率更低的，或者 LFU 频率相同但更久未访问的
            best_lfu_freq = this_freq;
            best_idle_time = this_idle;
            de = de_sample;
        }
    }
    // 淘汰选出的 de 键
    // ...
}
```

### 总结 Redis LFU 的特点

- **近似性：** Redis 的 LFU 并不是严格意义上的 LFU，它通过概率性计数器增长和周期性衰减来近似模拟真实访问频率，以在性能和准确性之间取得平衡。
- **内存效率：** 每个键只需要额外8位来存储频率计数器，以及16位来存储最后访问时间，非常节省内存。
- **随机采样：** 淘汰时不是遍历所有键，而是随机选择一部分键进行比较，大大降低了淘汰操作的开销，尤其是在大型数据集中。
- **衰减机制：** 有效地解决了纯 LFU 算法中“历史热门”键可能长期霸占缓存的问题，使得缓存能够适应数据访问模式的变化。

## 十九、Redis 如何实现延迟队列

延迟队列是指把当前要做的事情，往后推迟一段时间再做。延迟队列的常见使用场景有以下几种：

- 在淘宝、京东等购物平台上下单，超过一定时间未付款，订单会自动取消；
- 打车的时候，在规定时间没有车主接单，平台会取消你的单并提醒你暂时没有车主接单；
- 点外卖的时候，如果商家在10分钟还没接单，就会自动取消订单；

在 Redis 可以使用有序集合（ZSet）的方式来实现延迟消息队列的，ZSet 有一个 Score 属性可以用来存储延迟执行的时间。

使用 zadd score1 value1 命令就可以一直往内存中生产消息。再利用 zrangebysocre 查询符合条件的所有待处理的任务， 通过循环执行队列任务即可。

![img](https://github.com/QaQOwOQaQ/picx-images-hosting/raw/master/image.4xussgcez9.png)

## 二十、Pileline

Redis 的管道技术是 Redis 客户端优化与 Redis 服务器通信效率的一种机制。它的核心思想是**批量发送命令，批量接收响应**，从而显著减少网络往返时间（RTT）对性能的影响。

### 为什么需要管道技术？

Redis 是一个基于内存的键值存储，其单命令的执行速度非常快，通常在微秒级别。然而，即使命令执行再快，客户端与服务器之间的网络通信也会引入延迟。这个延迟主要来自：

1. **网络往返时间 (RTT - Round Trip Time)：** 数据包从客户端发送到服务器，再从服务器返回到客户端所花费的时间。即使在局域网内，这个时间也可能是毫秒级别的。
2. **系统调用开销：** 客户端发送命令和接收响应时，需要进行多次系统调用（如 `send()` 和 `recv()`），这也会带来额外的开销。

如果没有管道，每次客户端发送一个命令，都需要等待服务器返回响应后才能发送下一个命令。这个过程是串行的，每次命令执行都会包含一个 RTT。

**示例（没有管道）：**

假设你要执行 100 个 `SET` 命令：

1. 客户端发送 `SET key1 value1`
2. 等待服务器响应 `OK` (1 RTT)
3. 客户端发送 `SET key2 value2`
4. 等待服务器响应 `OK` (1 RTT) ... (重复 100 次)

总共需要 100 次 RTT。如果每个 RTT 是 1 毫秒，那么仅仅网络延迟就会消耗 100 毫秒，而实际命令执行时间可能只有几微秒。

### 管道的工作原理

管道技术改变了这种串行模式，使其变为批处理模式：

1. **客户端缓冲区：** 客户端并不立即发送每个命令到网络，而是将多个命令暂时放入一个内存缓冲区。
2. **一次性发送：** 当缓冲区达到一定数量（或客户端显式调用 flush 操作）时，客户端将缓冲区中的所有命令一次性打包发送给 Redis 服务器。
3. **服务器处理：** Redis 服务器接收到这一批命令后，会按照接收的顺序，**逐个执行**这些命令。Redis 是单线程的，所以这些命令的执行仍然是串行的，但对客户端来说是透明的。
4. **一次性返回响应：** 服务器在执行完所有命令后，会将所有命令的执行结果按顺序打包，一次性返回给客户端。
5. **客户端解析：** 客户端接收到所有响应后，再按顺序解析出每个命令的结果。

**示例（使用管道）：**

执行 100 个 `SET` 命令：

1. 客户端将 100 个 `SET` 命令放入缓冲区。
2. 客户端一次性发送这 100 个命令到服务器。
3. 服务器逐个执行这 100 个命令。
4. 服务器将 100 个结果打包，一次性返回给客户端。
5. 客户端接收并解析这 100 个结果。

总共只需要 1 次 RTT。这极大地提高了每秒可以执行的命令数量（即吞吐量）。

### 管道的优势

- **减少网络往返时间 (RTT)：** 这是最主要的优势，可以显著提高命令的吞吐量。
- **减少系统调用开销：** 批量发送和接收数据可以减少客户端和服务器端的系统调用次数。
- **提高资源利用率：** 更有效地利用网络带宽和服务器处理能力。

### 管道的局限性/注意事项

1. **原子性：** 管道**不保证原子性**。管道中的命令是按顺序执行的，但如果 Redis 服务器在执行批处理的中间崩溃，那么部分命令可能已经执行，而另一部分没有。要保证原子性，需要使用 Redis 事务（`MULTI`/`EXEC`）。
2. **错误处理：** 如果管道中的某个命令执行失败，Redis 仍然会执行后续的命令，并在最终的响应中返回该命令的错误信息。客户端需要逐一检查每个命令的响应来判断是否成功。
3. **内存占用：** 客户端在发送所有命令之前，需要将它们全部缓冲在内存中。如果管道中的命令数量非常大，可能会占用较多的客户端内存。
4. **长连接：** 管道技术通常依赖于客户端与服务器之间的长连接。
5. **不适用于强实时性场景：** 如果你需要在每个命令执行后立即获得结果并根据结果决定下一个操作，那么管道就不适用。管道适用于需要一次性发送大量命令并等待所有结果的场景。

### 客户端库对管道的支持

几乎所有的 Redis 客户端库都支持管道功能，通常通过 `pipeline()` 或 `multi()` 等方法来实现。

**Python 示例 (使用 `redis-py` 库):**

```python
import redis

# 连接 Redis
r = redis.Redis(host='localhost', port=6379, db=0)

# 开启管道
pipe = r.pipeline()

# 将多个命令添加到管道中
pipe.set('mykey1', 'value1')
pipe.set('mykey2', 'value2')
pipe.get('mykey1')
pipe.incr('mycounter')
pipe.incr('mycounter')

# 执行管道中的所有命令，并获取所有结果
results = pipe.execute()

# 打印结果
print(results)
# 预期输出可能类似于: [True, True, b'value1', 1, 2]
# 注意：True 表示 SET 命令成功，b'value1' 是 GET 的结果，数字是 INCR 的结果
```

**总结来说：**

Redis 管道技术是提高 Redis 应用程序性能的关键优化手段之一。通过减少网络往返时间，它能够显著提升单位时间内处理的命令数量，非常适合需要批量操作 Redis 的场景，如数据导入、批量更新等。

要注意的是，管道技术本质上是 **客户端提供的功能**，而非 Redis 服务器端的功能。

## 二十一、Redis 事务

Redis 事务是一组命令的集合，它允许你将多个 Redis 命令打包起来，一次性地、顺序地、排他地执行。尽管它被称为“事务”，但与传统关系型数据库（如 MySQL）中的事务有所不同，Redis 事务不具备完全的 ACID 特性。

### Redis 事务的特性

1. **原子性（Atomicity）**：
   - **命令提交阶段**：**Redis 事务不保证原子性。**如果在事务执行过程中，某个命令出错（例如，对字符串类型执行列表操作），**只有报错的命令不会执行**，其他命令会正常执行。
   - **命令组队阶段**：如果在事务组队过程中（即在 `MULTI` 和 `EXEC` 之间）有语法错误，那么整个事务队列中的所有命令都不会被执行。
   - **无回滚机制**：Redis 事务没有回滚机制。一旦事务开始执行，即使有命令执行失败，Redis 也不会撤销之前已经执行成功的命令。这是与关系型数据库事务最大的区别。
2. **一致性（Consistency）**：
   - Redis 事务通常不直接提供关系型数据库中那种严格的约束和回滚机制来保证数据一致性。
   - 由于 Redis 是单线程的，在事务执行期间，不会有其他客户端的命令插入到事务中间执行，这在一定程度上保证了事务内操作的顺序性和隔离性，从而间接维护了数据在事务执行期间的可见性。
3. **持久性（Durability）**：
   - Redis 本身是内存数据库，数据存储在内存中。事务本身与持久化机制没有直接关系。
   - Redis 的持久化（RDB 快照或 AOF 日志）是独立于事务的，它们负责将内存中的数据定期或异步地写入磁盘，以防止数据丢失。
4. **隔离性（Isolation）**：
   - Redis 是单线程模型，所有命令都是“串行”执行的。这意味着在一个事务中的所有命令在 `EXEC` 命令执行后，会按照它们被放入队列的顺序依次执行，并且在整个事务执行过程中，不会被其他客户端的命令打断。
   - 但是，Redis 事务没有隔离级别的概念。在事务执行之前，客户端可以看到所有已提交的数据。在事务执行期间，事务内的操作在 `EXEC` 之前并不会真正执行，所以其他客户端看不到事务内的中间状态，直到 `EXEC` 命令执行完毕，所有修改才会对外可见。

> Redis 为什么不支持事务回滚？
>
> Redis 官方文档解释如下：
>
> ![back](https://github.com/QaQOwOQaQ/picx-images-hosting/raw/master/image.32i7zulpcs.png)
>
> 大概的意思是，作者不支持事务回滚的原因有以下两个：
>
> - 他认为 Redis 事务的执行时，错误通常都是编程错误造成的，这种错误通常只会出现在开发环境中，而很少会在实际的生产环境中出现，所以他认为没有必要为 Redis 开发事务回滚功能；
> - 不支持事务回滚是因为这种复杂的功能和 Redis 追求的简单高效的设计主旨不符合。
>
> 这里不支持事务回滚，指的是不支持事务运行时错误的事务回滚。

### Redis 事务的命令

Redis 事务主要通过以下四个命令来控制：

- **`MULTI`**：用于标记一个事务的开始。在此命令之后，所有客户端发送的命令都会被放入一个命令队列中，而不是立即执行。
  - 示例：`MULTI`
- **`EXEC`**：用于执行所有在 `MULTI` 命令之后入队的命令。一旦 `EXEC` 被调用，队列中的所有命令会按顺序执行。
  - 示例：`EXEC`
- **`DISCARD`**：用于取消一个事务。如果在 `EXEC` 之前调用 `DISCARD`，那么所有在 `MULTI` 之后入队的命令都会被清空，事务被取消。
  - 示例：`DISCARD`
- **`WATCH [key [key ...]]`**：用于监控一个或多个键。如果在 `EXEC` 命令执行之前，任何被 `WATCH` 的键被其他客户端修改了，那么当前事务将会被取消，`EXEC` 命令会返回一个空列表（nil）。这被称为乐观锁机制，用于防止竞争条件。
  - 示例：`WATCH mykey`
- **`UNWATCH`**：用于取消所有对键的监控。通常在事务被 `EXEC` 或 `DISCARD` 之后会自动执行 `UNWATCH`，但你也可以手动调用它来取消监控。
  - 示例：`UNWATCH`

### Redis 事务的工作流程

1. **开启事务**：客户端发送 `MULTI` 命令，Redis 返回 `OK`。
2. **命令入队**：客户端发送一系列命令，这些命令不会立即执行，而是被添加到事务队列中。对于每个成功入队的命令，Redis 返回 `QUEUED`。
3. 执行事务或取消事务：
   - **执行**：客户端发送 `EXEC` 命令。Redis 会按顺序执行事务队列中的所有命令，并返回一个包含所有命令执行结果的列表。
   - **取消**：客户端发送 `DISCARD` 命令。事务队列被清空，事务被取消。

### 示例

**成功的事务：**

代码段

```shell
MULTI
SET key1 "value1"
LPUSH mylist "item1"
INCR counter
EXEC
```

- `EXEC` 命令会返回一个包含 `SET`、`LPUSH` 和 `INCR` 命令执行结果的列表。

**带有 `WATCH` 的事务（乐观锁）：**

代码段

```shell
WATCH balance # 监控 balance 键
GET balance   # 获取当前余额，假设为 100
# 在这里，如果另一个客户端修改了 balance 的值，比如扣款
MULTI
DECRBY balance 10 # 扣除 10
INCRBY total_expense 10 # 增加总支出
EXEC
```

- 如果 `WATCH` 的 `balance` 键在 `EXEC` 之前没有被其他客户端修改，那么 `DECRBY` 和 `INCRBY` 会被执行。
- 如果 `balance` 键在 `EXEC` 之前被修改了，`EXEC` 会返回 `(nil)`，表示事务执行失败，需要客户端重新尝试。

**命令组队阶段错误：**

代码段

```shell
MULTI
SET mykey "hello"
LPOP mykey # 错误：对字符串类型执行列表操作
EXEC
```

- 在这种情况下，`LPOP mykey` 在入队时就会被 Redis 识别为错误（尽管返回 `QUEUED`），但在 `EXEC` 时，整个事务队列中的所有命令都不会被执行。

**命令执行阶段错误：**

代码段

```
MULTI
SET mykey "hello"
RPUSH mykey "item" # 错误：对字符串类型执行列表操作，但是此命令在 EXEC 时才报错
INCR counter
EXEC
```

- 在这种情况下，`SET mykey "hello"` 会成功执行，但 `RPUSH mykey "item"` 会执行失败，`INCR counter` 会继续执行成功。Redis 返回的结果列表中会显示 `RPUSH` 命令的错误信息，但不会影响其他命令的执行。

### 总结

Redis 事务提供了一种将多个命令打包执行的机制，确保这些命令在执行期间不会被其他客户端的命令中断，从而实现一种原子性的操作序列（在执行阶段）。然而，它不提供关系型数据库那样严格的事务回滚机制，因此在设计使用 Redis 事务的应用程序时，需要充分理解其特性，并结合业务逻辑进行适当的错误处理。`WATCH` 命令提供了一种乐观锁的机制，可以用于处理并发场景下数据一致性的问题。

















































































